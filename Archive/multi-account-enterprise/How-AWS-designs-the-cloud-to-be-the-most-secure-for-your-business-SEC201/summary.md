# AWS re:Inforce 2025 - How AWS designs the cloud to be the most secure for your business (SEC201)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=zEEBB6ZR8Is)

## Video Information
- **Author:** AWS Events
- **Duration:** 55.2 minutes
- **Word Count:** 9,069 words
- **Publish Date:** 20250619
- **Video ID:** zEEBB6ZR8Is

## Summary
This foundational session explained AWS's approach to building secure cloud infrastructure, presented by Eric Brandwine (VP Distinguished Engineer, Security) and Colm McCarthy (VP Distinguished Engineer, EC2 Networking). Using the metaphor of a castle built on solid rock, they detailed AWS's responsibility in the shared security model—providing the foundation that customers can trust. The presentation emphasized operational excellence, continuous verification of security promises, and the critical importance of selecting a long-term cloud partner based on proven security practices rather than just features.

## Key Points
- - **Castle Foundation Metaphor**: AWS provides the unshakeable security foundation that customers build upon
- **Shared Responsibility Clarity**: Clear delineation between AWS infrastructure security and customer application security
- **Trust-Based Business Model**: AWS success depends entirely on earning and maintaining customer trust with sensitive data
- **Operational Excellence**: Building services correctly is necessary but not sufficient—continuous operation is critical
- **Promise Verification**: Every security promise must be verifiable every day, not just at launch
- **Long-Term Partnership**: Cloud provider selection should be based on sustained trustworthiness over years
- **Due Diligence Framework**: Customers should ask hard questions and verify security claims before committing
- **Continuous Monitoring**: Internal systems continuously verify that security controls are working as promised
- **Regulatory Compliance**: Services designed to delight customers from startups to highly regulated industries
- **Engineering Maturity**: 15+ years of security engineering experience building and operating cloud services at scale

## Technical Details
- - **VPC Foundation**: Virtual Private Cloud networking layer provides isolated, secure network infrastructure for all services
- **Internal Encryption Controls**: Continuous verification systems ensure encryption promises are maintained operationally
- **Promise Monitoring**: Automated systems detect when security commitments might be failing even if services appear functional
- **Service Integration**: Security controls built into fundamental AWS services (EC2, S3, networking) rather than added afterward
- **Operational Verification**: Real-time monitoring that security controls work correctly every hour of every day
- **Customer API Security**: Security built into customer-facing APIs with continuous operational validation
- **Infrastructure Isolation**: Network and compute isolation mechanisms protecting customer workloads from each other
- **Compliance Architecture**: Services designed from inception to meet requirements of most regulated industries
- **Scaling Security**: Security architecture that maintains effectiveness across millions of customers and billions of requests
- **Engineering Practices**: Security-first development methodologies with operational feedback loops for continuous improvement

## Full Transcript

>> HI, EVERYONE. MY NAME IS ERIC
BRANDWINE, AND I'M A VICE PRESIDENT AND DISTINGUISHED
ENGINEER WITH THE AMAZON SECURITY TEAM. WHEN I JOINED
AMAZON, I WAS WORKING ON VPC VIRTUAL PRIVATE CLOUD, THE
NETWORKING LAYER THAT RUNS UNDERNEATH ALL OUR SERVICES. BUT
A FEW YEARS INTO MY TIME AT AMAZON, WE FORMED THE NEW AWS
SECURITY TEAM. AT THE TIME, ANDY JASSY UNDERSTOOD SOMETHING THAT
I DIDN'T YET UNDERSTAND. AWS IS A TRUST BASED BUSINESS. WE'RE
ASKING OUR CUSTOMERS TO TRUST US WITH THEIR MOST SENSITIVE DATA
AND WITH THE WORKLOADS ON THAT DATA, I FIGURED I'D SPEND A YEAR
OR TWO GETTING THE SECURITY TEAM GOING AND THEN GO BACK TO MY DAY
JOB BUILDING SERVICES INSTEAD. I SPENT THE PAST 15 YEARS IN
SECURITY AT AMAZON. IT'S GIVEN ME AN INCREDIBLY PRIVILEGED
POSITION FROM WHICH TO WATCH AWS GROW AND TO GET INVOLVED ACROSS
EVERYTHING. FOR THE MAJORITY OF THOSE 15 YEARS, I'VE BEEN
WORKING WITH COLM MCCARTHY, WHO'S ALSO A VICE PRESIDENT AND
DISTINGUISHED ENGINEER, BUT HE'S AN EC2 NETWORKING. IN THIS TALK,
WE'LL TELL YOU ABOUT SOME OF THE THINGS THAT WE DO TO EARN YOUR
TRUST AND TO MAINTAIN IT. OVER THE YEARS, WE'VE TALKED A LOT
ABOUT THE SHARED RESPONSIBILITY MODEL IN VARIOUS FORA. IN ALL
HONESTY, WHENEVER SOMEONE SAYS SHARED RESPONSIBILITY MODEL IN
MY HEAD, A PICTURE OF A CASTLE IMMEDIATELY APPEARS. THERE'S A
TON OF CONTENT OUT THERE. HOW TO BUILD SECURELY IN AWS, HOW TO
UPHOLD YOUR SIDE OF THE SHARED RESPONSIBILITY MODEL. THIS IS SO
IMPORTANT TO US THAT WE'VE GOT AN ENTIRE CONFERENCE DEDICATED
TO SECURITY IN AWS. AND BY THE WAY, THANK YOU FOR JOINING US
HERE IN PHILADELPHIA. HOWEVER, THAT'S NOT THIS TALK. THE
STRONGEST CASTLE WILL COLLAPSE IF IT DOESN'T HAVE A GOOD
FOUNDATION. THE MOST ROBUST CASTLE BUILT ON SAND OR PERHAPS
IN A SWAMP, WILL NOT STAND. A CASTLE BUILT ON SOLID ROCK WILL
DELIVER THE FULL STRENGTH OF THAT CASTLE. AND SO THIS PART OF
THE CASTLE IS YOURS TO BUILD. YOU GET TO MAKE ALL SORTS OF
DECISIONS, DETERMINE HOW THINGS ARE CONFIGURED, HOW MUCH RISK
YOU'RE WILLING TO ACCEPT IF THERE'S SOMETHING YOU DON'T LIKE
IN THIS PART OF THE CASTLE, YOU CAN FIX IT. THIS PART OF THE
CASTLE IS OURS. IF THERE'S SOMETHING YOU DON'T LIKE DOWN
HERE, YOU CAN'T FIX IT. YOU HAVE TO RELY ON US. WE HAVE TO DECIDE
HOW TO BUILD IT. AND WE'RE KEENLY AWARE THAT WE'RE
SUPPORTING THE AGGREGATE TRUST THAT YOU ALL HAVE PLACED IN US.
WE HAVE TO BUILD SERVICES THAT DELIGHT ALL OF OUR CUSTOMERS,
FROM THOSE JUST GETTING STARTED THROUGH THE MOST REGULATED AND
SECURITY CONSCIOUS. THAT'S THIS TALK. WE'RE GOING TO GIVE YOU
SOME INSIGHT INTO HOW WE BUILD, HOW WE THINK ABOUT BUILDING, AND
GIVE YOU SOME ACTIONABLE ADVICE FOR SELECTING A CLOUD PROVIDER,
PICKING AN INFRASTRUCTURE SERVICES PROVIDER IS THE START
OF A LONG TERM RELATIONSHIP. THIS IS A DECISION THAT YOU HAVE
TO MAKE WITH CARE. YOUR GOAL IS TO DELIVER FOR YOUR CUSTOMERS.
YOUR TIME IS BEST SPENT GROWING YOUR OFFERINGS AND DELIGHTING
YOUR CUSTOMERS, NOT ON A SEEMINGLY ENDLESS SERIES OF
MIGRATIONS FROM ONE PROVIDER TO ANOTHER. THE BEST POSSIBLE STATE
HERE IS ONE WHERE YOU FOUND A LONG TERM PARTNER, A PROVIDER
THAT YOU CAN TRUST NOW AND CAN CONTINUE TO TRUST FOR THE
FUTURE. DO YOUR HOMEWORK. ASK HARD QUESTIONS. MAKE SURE THAT
YOUR TRUST IS WELL PLACED. IF YOU TAKE ONE THING AWAY FROM
THIS TALK, IT SHOULD BE THE TWO QUESTIONS THAT I'M GOING TO
INTRODUCE ON THIS SLIDE. I'M A TENURED SENIOR ENGINEER, WHICH
IS JUST A POLITE WAY OF SAYING THAT I'VE PERSONALLY MADE ALL
THE COMMON MISTAKES AND A FEW OF THE UNCOMMON ONES. I'VE LEARNED
THAT IT'S NECESSARY TO BUILD YOUR SERVICE WELL, BUT JUST
DOING THAT IS FAR FROM SUFFICIENT. WHAT REALLY MAKES
THE DIFFERENCE IS HOW YOU OPERATE IT. FOR ALL THE WEEKS
AND MONTHS AND YEARS THAT CUSTOMERS ARE GOING TO BE USING
IT, ALL OF OUR SERVICES MAKE SOME SET OF PROMISES TO OUR
CUSTOMERS. SOMETIMES FAILURES IN THOSE PROMISES ARE OBVIOUS. IF
YOU ATTEMPT TO LAUNCH AN EC2 INSTANCE AND NO INSTANCE GETS
LAUNCHED, THEN IT'S CLEAR TO EVERYONE THAT SOMETHING WENT
WRONG. HOWEVER, SOMETIMES THESE PROMISES ARE NOT AS OBVIOUS FOR
THINGS LIKE OUR INTERNAL ENCRYPTION CONTROLS. WE COULD
STILL RESPOND TO QUERIES AND LAUNCH INSTANCES AND RESPOND TO
CUSTOMER APIS, EVEN IF WE WERE FAILING TO ENCRYPT CORRECTLY,
THE SERVICE WOULD STILL BE WORKING, BUT WE'D BE BREAKING A
CUSTOMER PROMISE THAT'S NOT OKAY. IF WE'RE GOING TO LIVE UP
TO THE TRUST THAT OUR CUSTOMERS HAVE PLACED IN US, IT'S NOT
SUFFICIENT TO BUILD A SERVICE THAT FULFILLS THESE PROMISES.
SURE, WE'D KNOW ON LAUNCH DAY THAT WE GOT IT RIGHT, BUT WE
NEED TO KNOW EVERY DAY, EVERY HOUR FROM THE DAY OF LAUNCH
UNTIL THE DAY THE LAST CUSTOMER MOVES OFF THAT SERVICE, THAT
IT'S STILL RIGHT. CLEARLY, YOU'RE GOING TO WANT TO SELECT A
SERVICE PROVIDER THAT HAS WORLD CLASS SECURITY SERVICES AND
FEATURES AND PARTNERS. BUT AGAIN, THAT'S NOT GOOD ENOUGH.
IT DOESN'T MATTER HOW AWESOMELY THEY THINK IT WORKS. IT HAS TO
ACTUALLY BE THAT AWESOME TODAY AND TOMORROW. THAT GIVES US OUR
FIRST QUESTION YOU SHOULD ASK HOW DOES AWS KNOW THEY'RE
MEETING ALL THE CUSTOMER PROMISES THEY MAKE? ASK YOUR
PROSPECTIVE PROVIDERS. ASK YOUR CURRENT PROVIDER. UNDERSTAND HOW
THEY'RE THINKING ABOUT ALL OF THE DAYS AFTER LAUNCH DAY. A
GOOD PARTNER WILL HAVE A WEB OF INTERLOCKING MECHANISMS TO HELP
TO PREVENT, DETECT, AND RESPOND TO FAILURES. I LOVE WORKING ON
SECURITY IN AWS AND I LOVE TALKING ABOUT IT, BUT WHY SHOULD
YOU BELIEVE ME? THE BLUNT REALITY IS THAT I WORK FOR AWS,
AND OUR BUSINESS DOES BETTER WHEN MORE PEOPLE USE OUR
SERVICES. I AM A BIASED PARTICIPANT IN THIS
CONVERSATION. YOU SHOULD REQUIRE EVIDENCE. AND THAT BRINGS US TO
THE SECOND QUESTION. HOW CAN A CUSTOMER KNOW THAT AWS IS
MEETING ITS CUSTOMER PROMISES? THERE ARE TWO PRIMARY WAYS THAT
YOU CAN VERIFY THAT AWS DOES WHAT IT SAYS IT DOES. THE FIRST
IS OUR OPEN SOURCE CONTRIBUTIONS, THINGS LIKE THE
FIRECRACKER HYPERVISOR AND THE S N TLS LIBRARY ARE FULLY OPEN
SOURCE. YOU CAN DOWNLOAD THEM, READ THE CODE, READ WHAT OTHERS
HAVE WRITTEN ABOUT THEM, AND COME TO YOUR OWN CONCLUSIONS.
THE OTHER IS OUR DEEP INVESTMENT IN ASSURANCE AND COMPLIANCE. AWS
SUPPORTS 143 STANDARDS AND COMPLIANCE CERTIFICATES
WORLDWIDE. OUR COMPLIANCE REPORTS AND ATTESTATION
DOCUMENTS ARE AVAILABLE SELF-SERVICE VIA OUR ARTIFACT
SERVICE. AND SO IN THIS TALK, WE'LL PRESENT SOME OF THE THINGS
THAT WE DO TO MAINTAIN CUSTOMER TRUST. AND WE'LL ANSWER THESE
TWO QUESTIONS FOR EACH OF THEM. AND TO START WITH THAT, I'D LIKE
TO BRING CALLUM ON STAGE. >> THANK YOU ERIC. SO I'VE
WORKED AT AWS FOR 17 YEARS AND I WANT TO TAKE YOU BACK TO 2009 TO
SOMETHING CALLED THE PIZZA ATTACK. YOU PROBABLY DON'T
REMEMBER OR HAVEN'T HEARD OF THE PIZZA ATTACK, BUT IT WAS A
VULNERABILITY FOUND BY MARSH RAY IN NOVEMBER 2009, AND HE CALLED
IT THE PIZZA ATTACK BECAUSE IN HIS DEMO FOR THE VULNERABILITY,
HE WAS ABLE TO ORDER A PIZZA THAT HE HADN'T PAID FOR, WHICH
IS REALLY COOL. NOW, AT THE TIME, WE CLASSIFIED THIS ATTACK
AS LOW RISK AND LOW IMPACT FOR AWS AND FOR AMAZON, IT REQUIRED
A LOT OF ESOTERIC CONDITIONS TO EXPLOIT THAT DIDN'T REALLY APPLY
TO OUR SYSTEMS. IN FACT, WE THOUGHT WE DON'T HAVE ANYTHING
THAT'S AT RISK OR VULNERABLE TO THIS ATTACK. BUT NEVERTHELESS,
YOU DON'T WANT TO LEAVE. THINGS LIE. YOU WANT TO HAVE MITIGATION
WHENEVER YOU CAN, AND YOU NEVER KNOW WHAT ELSE MIGHT SHOW UP IN
A NEW AREA OF INTEREST. SO WE DECIDED WE WOULD HAVE TO UPDATE
ALL OF OUR SYSTEMS TO MITIGATE FOR THIS ISSUE ANYWAY. AND WHAT
THAT LOOKED LIKE WAS WE HAD A TIGHT TEAM OF EXPERTS WHO WERE
CHARGED WITH DOING EVERYTHING FROM UPDATING ALL OF OUR CODE,
ALL OF OUR SYSTEMS, AND EVEN GOING ON-PREMISES WITH OUR
VENDORS AND MAKING SURE THAT THEY WERE MITIGATING THIS
CORRECTLY, AND THEN UPDATING ALL OF OUR SYSTEMS. AND WE ACTUALLY
HAD TO DO THIS DURING THE WEEK OF THANKSGIVING IN NOVEMBER
2009, WHICH IS TRADITIONALLY AMAZON'S BUSIEST SALES WEEK.
THAT WEEK AND THE WEEK AFTER, AND AT THE TIME WAS THE BUSIEST
WEEK AT AWS. BUT WE DECIDED WE STILL HAD TO DO THIS. OUR CEO,
JEFF BEZOS, WAS PERSONALLY BRIEFED ON THIS ISSUE, KEPT IN
THE LOOP THROUGHOUT THE WHOLE PROCESS. AND THAT WAS THE FIRST
TIME I GOT A REAL VIEW OF JUST HOW DEEP OUR CULTURE OF SECURITY
RUNS AT AWS. AND IN ALL THE YEARS SINCE, I'VE GOTTEN MORE
AND MORE SENSE OF THAT, AND I BREAK IT DOWN INTO A FEW
DIFFERENT THINGS AND HOW I SEE US APPROACH THAT SECURITY. NOW,
WHENEVER YOU'VE GOT A FUNCTION THAT REQUIRES EXPERTISE AT A
COMPANY, YOU'VE GOT TWO MAIN CHOICES FOR HOW THAT SHOULD BE
ORGANIZED. IF YOU SAY, GOT A FINANCE TEAM OR HR TEAM, YOU CAN
SAY, WELL, WE WANT TO EMBED THAT IN EVERY SINGLE TEAM. WE WANT TO
HAVE AN EMBEDDED FINANCE PERSON IN EVERY TEAM SO THAT THE
FINANCE EXPERTISE IS RIGHT THERE WHERE WE NEED IT. OR YOU CAN
HAVE A DEDICATED SEPARATE ORG AND YOU CAN PUT ALL THE EXPERTS
TOGETHER. YOU CAN HAVE A FINANCE ORG AND ALL THE FINANCE PEOPLE
ARE IN THAT ORG. BUT WHEN IT COMES TO SECURITY, THE ANSWER
FOR WHAT WE'D LIKE TO DO IN THIS CASE IS ACTUALLY TO DO BOTH. AT
AWS, WE INTEGRATE SECURITY AND SECURITY EXPERTS DIRECTLY INTO
OUR SERVICE TEAMS, AND WE HAVE AN INDEPENDENT SECURITY ORG TO
KEEP US ACCOUNTABLE AND TO ACT AS A CHECK AND BALANCE. WHAT
THAT LOOKS LIKE IS THAT PEOPLE LIKE ME, WHO ARE BUILDING
SERVICES AND SHIPPING NEW FEATURES, ARE EXPECTED TO
MAINTAIN OUR OWN EXPERTISE IN SECURITY. WE ALSO HAVE EMBEDDED
SECURITY ENGINEERS, SECURITY CHAMPIONS, SECURITY GUARDIANS
WHO ARE DOING NOTHING ELSE EXCEPT PAYING ATTENTION TO
SECURITY FOR OUR SERVICE, OUR FEATURES, OUR PRODUCTS. AND THEN
WE ALSO WORK CLOSELY WITH THAT INDEPENDENT AWS SECURITY ORG,
EVERYTHING FROM COLLABORATING IN WHITEBOARDS TO DOING OUR PEN
TESTS AND SO ON. WE DO BOTH. THE NEXT IS THAT WE EXPECT OUR
LEADERS TO PAY A LOT OF PERSONAL ATTENTION TO SECURITY. EVERY
WEEK AT AWS, WE HAVE A SECURITY MEETING WITH OUR LEADERSHIP
TEAM, INCLUDING OUR CEO. THEY ARE PUTTING THE TIME ASIDE TO
DIVE DEEP AND DRILL INTO OUR SECURITY RESPONSE AND OUR
SECURITY POSTURE. IF WE EVER HAVE AN URGENT SECURITY ISSUE OR
SOMETHING THAT REQUIRES INVESTIGATION, WE ARE BRIEFING
THESE SAME PEOPLE AND THESE ARE THE PEOPLE YOU'LL SEE DOING
KEYNOTES AT RE:INFORCE OR RE:INVENT. WE BRIEF THEM WITHIN
MINUTES, AND I'VE NEVER SEEN THEM NOT MAKE THE TIME. WE'RE
ABLE TO PAGE THEM AND ENGAGE THEM IF WE NEED THEM. IT'S
PRETTY AMAZING. NEXT, SECURITY ISN'T OPTIONAL. IT'S INTEGRATED
INTO OUR DEVELOPMENT PROCESS AND HOW WE SHIP FEATURES. WE CANNOT
SHIP A NEW SERVICE OR A NEW FEATURE UNLESS IT MEETS OUR
SECURITY BAR, AND WE WILL NOT COMPROMISE ON THAT. WE WILL
DELAY A FEATURE OR SERVICE IF NECESSARY, BECAUSE ULTIMATELY WE
KNOW FEATURE. WE KNOW THAT SECURITY IS THE FEATURE
CUSTOMERS CARE MOST ABOUT. EVEN IF A SERVICE OR FEATURE IS
SOMETHING CUSTOMERS HAVE BEEN TELLING US, THEY'RE EAGERLY
AWAITING IT. THEY'RE REALLY KEEN AND EXCITED TO GET IT IN THEIR
HANDS. WE ARE TOO. WE STILL WON'T COMPROMISE ON THIS BECAUSE
IT'S A CORE CULTURAL VALUE FOR US. AND THEN LASTLY, AT OUR
SCALE, WE CAN'T JUST PREACH ABOUT SECURITY. IT'S NOT JUST
ABOUT PROSELYTIZING. AND WE CAN'T SIMPLY ASK PEOPLE TO TRY
HARDER ON SECURITY. EVERYBODY'S TRYING THEIR BEST NO MATTER
WHAT. WE HAVE TO MECHANIZE AND AUTOMATE SECURITY, AND THAT
MEANS BUILDING IT INTO OUR TOOLS, LIBRARIES, FRAMEWORKS AND
TEMPLATES SO THAT WHEN DEVELOPERS BUILDING SOMETHING
NEW, IT'S SECURE OUT OF THE BOX. THE GOLDEN PATH IS FULL OF GREAT
DEFAULTS, AND ACROSS ALL OF THIS, MY EXPERIENCE IS THAT WE
HAVE AN ENORMOUS FOCUS ON DEFENSE IN DEPTH. UNLIKE WHAT
I'VE EXPERIENCED ANYWHERE ELSE. WE WANT TO ENSURE THAT WE BUILD
SECURE SYSTEMS, BUT WE ALSO ANTICIPATE THAT OUR SECURITY
SYSTEMS WILL FAIL. AND ONE ALONE IS NOT ENOUGH. WE ALWAYS WANT
MULTIPLE LAYERS OF SECURITY, AND IDEALLY FOR ONE OR MORE OF THOSE
LAYERS, TO BE VERY GENERAL AND CAPABLE OF CATCHING BROAD AND
WIDE CLASSES OF ISSUES. NOW, THIS SOUNDS JUST LIKE GOOD,
RESPONSIBLE ENGINEERING. REMINDS ME A LOT OF RESILIENT AND HIGHLY
AVAILABLE SYSTEMS WHERE YOU ALWAYS WANT REDUNDANCY. IF ONE
SYSTEM FAILS, ANOTHER TAKES OVER, AND SO ON, AND YOU
CONTINUE GOOD OPERATIONS. BUT IN SECURITY, MY EXPERIENCE IS IT'S
ACTUALLY A LITTLE BIT DIFFERENT AND STRONGER THAN THAT TOO, IN
THAT THIS DEFENSE AND DEPTH AND LAYERING ALSO ACTS AS CULTURAL
REINFORCEMENT FOR US. IF WE HAVE A KINK IN ONE OF OUR LAYERS, OR
EVEN JUST A SUSPECTED ISSUE OR A KINK IN ONE OF OUR LAYERS, WE
RUN OUR FULL ROOT CAUSE ROOT CAUSE ANALYSIS PROCESS, DO A
FULL, THOROUGH INVESTIGATION, AND ALL OF THOSE DETAILS, SUPER
FINE GRAINED DETAILS WILL BE PRESENTED AT THAT WEEKLY
SECURITY MEETING WITH THE EYES OF OUR LEADERS AND EVEN OUR CEO.
WE DON'T WAIT FOR AN INCIDENT OR AN ISSUE THAT ACTUALLY EXPOSES
DATA WHERE MANY LAYERS HAVE TO HAVE FAILED. FOR THAT TO
TRIGGER, WE TRIGGER IT JUST ON ONE OR EVEN A SUSPECTED ISSUE IN
ANY ONE OF THOSE LAYERS, WHICH KEEPS US ON OUR TOES AND LETS US
KNOW HOW TO STAY PARANOID. NOW I WANT TO COVER AN AREA WHERE WE
HAVE A LOT OF THIS DEFENSE IN DEPTH, AND HOW IT'S EVOLVED OVER
THE YEARS, AND WHY, JUST TO SERVE AS AN EXAMPLE, WHICH IS
HOW WE DO NETWORK ENCRYPTION. SO AS YOU HEARD AT THE KEYNOTE, IF
YOU'VE EVER LEARNED ABOUT NETWORKING, YOU'LL CERTAINLY
HAVE ENCOUNTERED THE OSI LAYER MODEL WHERE IT HAS LOW LEVEL
LAYERS LIKE THE PHYSICAL LAYER, COPPER OR FIBER CABLE, ALL THE
WAY UP TO HIGH LEVEL LAYERS LIKE THE APPLICATION LAYER PROTOCOLS,
SAY HTTP FOR THE WEB. AND THIS IS A REALLY USEFUL LEARNING
TOOL, BUT IT'S NOT REALLY HOW REAL WORLD NETWORKS WORK. YOU
KNOW, STARTING EVEN 20 YEARS AGO, IT BECAME COMMON FOR
NETWORKS AND CUSTOMERS TO USE TLS AND SSL AND TO ENCRYPT
TRAFFIC AND TO HAVE THIS NEW ENCRYPTION LAYER IN THE MIDDLE
OF NETWORKING. AND TLS AND SSL ARE GREAT. THEY DO PROVIDE END
TO END SECURITY. THEY DO PROVIDE CONFIDENTIALITY, THEY DO PROVIDE
ENDPOINT AUTHENTICATION. ALL OF THESE REALLY IMPORTANT SECURITY
PROPERTIES THAT WE'RE FAMILIAR WITH. BUT THERE'S SOME THINGS
THAT TLS AND SSL DON'T DO. TLS AND SLA IS NOT GREAT AT
ANONYMITY. FOR EXAMPLE, IT DOESN'T HIDE WHOSE TRAFFIC IS
WHOSE OR WHAT VOLUME OF TRAFFIC IS MOVING AROUND. SO AS WE BUILT
OUR VIRTUAL NETWORKING STACK AND ADDED MORE KINDS OF ENCRYPTION
FOR CUSTOMERS, WE'VE TRIED TO ADD SECURITY PROPERTIES IN THOSE
LAYERS SO THAT THE SECURITY WE'RE GETTING AND THE DEFENSE IN
DEPTH CAN BE COMPLEMENTARY TO WHAT WE KNOW CUSTOMERS ARE
ALREADY DOING. AND I'LL TALK A LITTLE BIT ABOUT THAT. THE. NONE
OF THIS WOULD BE POSSIBLE. WE WOULD NOT BE ABLE TO ENCRYPT ALL
TRAFFIC AT SCALE IF WE DID NOT OWN OUR OWN HIGHLY OPTIMIZED
IMPLEMENTATIONS OF CRYPTOGRAPHY, AND WE HAVE OPEN SOURCE
IMPLEMENTATIONS OF GENERAL PURPOSE CRYPTOGRAPHY LIBRARIES,
AS WELL AS IMPLEMENTATIONS OF TLS, QUIC, A BIG NUMBER LIBRARY.
AND IMPORTANTLY, WE ALSO HAVE OUR OWN OPEN SOURCE BENCHMARKING
SUITE, WHICH MEANS WE'RE CONSTANTLY MEASURING THE
PERFORMANCE AND OPTIMIZATION OF THESE IMPLEMENTATIONS TO MAKE
SURE THEY'RE AS TIGHT AS POSSIBLE. AND I WANT TO GIVE
JUST ONE EXAMPLE. MY FAVORITE ONE OF THIS WORK, WHICH IS
MODULAR INVERSE. SO THE MODULAR INVERSE ALGORITHM IS JUST A
MATHEMATICAL ALGORITHM THAT'S REALLY COMMON TO CERTAIN KINDS
OF CRYPTOGRAPHY. ALGORITHMS LIKE ECDSA AND ECDSA. AND BEFORE OUR
OPTIMIZATION WORK IT WOULD TAKE 40 TO 50 MICROSECONDS FOR ONE OF
THESE OPERATIONS TO OCCUR. IT'S ACTUALLY QUITE A LONG TIME. BUT
WE WENT IN THERE AND WE DECIDED WE WOULD OPTIMIZE THIS FOR
GRAVITON AND OTHER ARCHITECTURES AND SQUEEZE OUT EVERY DROP OF
PERFORMANCE THAT WE COULD. AND NOT JUST THAT, BUT TO MAKE THE
PERFORMANCE MORE CONSISTENT. AND THAT CONSISTENCY MATTERS. FOR
HIGH RELIABILITY, YOU WANT NICE, CLEAN, PREDICTABLE SYSTEMS, BUT
ALSO FOR SECURITY, YOU WANT TO MAKE SURE THAT THERE ARE NO SIDE
CHANNELS BEING REVEALED TO DIFFERENCES IN TIMING AND SO ON.
SO AFTER OUR WORK, WE'RE ABLE TO ACHIEVE AN ALMOST TEN X INCREASE
IN PERFORMANCE DOWN TO ABOUT FIVE MICROSECONDS FOR THIS
OPERATION, WHICH IS A HUGE SAVING. AND WE'RE ABLE TO MAKE
IT PERFECTLY CONSISTENT BECAUSE ALL OF THIS IS HAPPENING IN
CONSTANT TIME, WHICH IS PRETTY AMAZING. THIS KIND OF WORK
TOGETHER WITH THINGS LIKE MOVING FROM THE RSA SIGNATURE ALGORITHM
TO THE ECDSA SIGNATURE ALGORITHM, MEAN WE'VE BEEN ABLE
TO REDUCE OUR ENERGY USAGE, FLEET SIZES AND HELP ACHIEVE OUR
CLIMATE CHANGE GOAL. THIS STUFF REALLY CAN MOVE THE NEEDLE AT
SCALE. SO LET'S TAKE A LOOK AT VPC ENCRYPTION AND HOW ALL OF
THIS FEEDS IN THERE. SO WITH VPC ENCRYPTION WE NATIVELY ENCRYPT
IN HARDWARE ALL TRAFFIC BETWEEN EC2 NITRO INSTANCES, WHETHER
THAT'S BETWEEN TWO INSTANCES THAT ARE OWNED BY THE SAME
CUSTOMER OR BETWEEN DIFFERENT CUSTOMERS, OR EVEN IF THE
TRAFFIC IS GOING BETWEEN REGIONS WHEN THE CUSTOMER IS USING
CROSS-REGION PEERING. THIS IS HAPPENING IN REAL TIME AT
ENORMOUS PERFORMANCE RATES. AND AS I MENTIONED EARLIER, TLS AND
SSL DON'T PROVIDE ANONYMITY, BUT VPC ENCRYPTION DOES. IF YOU WERE
TO TAP IN AND LOOK AT THE ACTUAL TRAFFIC ON THE WIRE, YOU WOULD
NOT BE ABLE TO SEE WHO'S TRAFFIC IS WHO'S, WHICH CAN PROTECT
CUSTOMERS FROM VOLUMETRIC ANALYSIS, SEEING WHO'S HAVING A
BUSY DAY, SEEING WHO'S SPINNING UP FOR ACTIVITY, AND SO ON,
WHICH IS AN INTERESTING THREAT MODEL. AND THEN BELOW VPC
ENCRYPTION, WE ALSO HAVE OUR LEVER NETWORK LINK ENCRYPTION.
AND OUR LEVER NETWORK LINK ENCRYPTION IS ENCRYPTING EVERY
PHYSICAL LINK BETWEEN ANY TWO AWS DATA CENTERS, INCLUDING THE
ENTIRE AWS BACKBONE. IT'S A HUGE SYSTEM ENCRYPTING VERY LARGE
VOLUMES OF TRAFFIC. AND THIS SYSTEM, TOO, WAS ARCHITECTED
FROM DAY ONE TO PROVIDE COMPLEMENTARY KINDS OF SECURITY.
IT ALSO PROVIDES ANONYMITY, AND IT ALSO PROVIDES MEASURES OF
POST-QUANTUM SECURITY. SO LET'S LOOK AT THAT IN MORE DETAIL ON
WHAT POST-QUANTUM SECURITY IS REALLY ABOUT. SO THIS IS OUR
OSCILLATE QUANTUM CHIP WHICH IS BUILT ON CAT QUBITS. QUANTUM
ERROR CORRECTION AND ADVANCES IN MANUFACTURING THAT MEAN WE HAVE
A REAL WORLD QUANTUM CHIP THAT CAN ACTUALLY DO QUANTUM
COMPUTATIONS IN THE REAL WORLD. NOW, THESE SYSTEMS ARE STILL
EARLY DAYS AND EXPERIMENTAL, BUT AS THESE SYSTEMS SCALE, THEY'RE
LIKELY TO GET TO THE SCALE WHERE THEY'LL BE CAPABLE OF ANALYZING
AND BREAKING CERTAIN ENCRYPTION ALGORITHMS. AND SO THAT RAISES A
RISK THAT TODAY SOMEBODY COULD BE CAPTURING CUSTOMER TRAFFIC,
KEEPING IT ASIDE AND SAYING, YOU KNOW, SOMEDAY WE'RE GOING TO TRY
TO CRACK THAT. WHEN A QUANTUM COMPUTER EXISTS. NOW, HOW THAT
ACTUALLY WORKS IS THAT IF YOU LOOK INSIDE A NETWORK ENCRYPTION
PROTOCOL, IT'S SPLIT UP INTO SEVERAL PHASES INVOLVING
DIFFERENT ALGORITHMS. AND AT THE HIGH LEVEL, THERE'S A HANDSHAKE
PHASE AND THERE'S A DATA ENCRYPTION PHASE. IN THE
HANDSHAKE PHASE, EVERYTHING'S AUTHENTICATED. YOU MAKE SURE
YOU'RE TALKING TO THE RIGHT PEER, AND THEN YOU ESTABLISH A
KEY THAT'S USED BY THE BULK DATA ENCRYPTION PHASE, WHICH IS WHERE
ALL THE DATA IS ACTUALLY EXCHANGED. WELL, THE GOOD NEWS
IS THAT THE DATA ENCRYPTION PHASE IS LARGELY QUANTUM SAFE.
WITH TODAY'S ENCRYPTION ALGORITHMS, QUANTUM COMPUTERS DO
REDUCE BY HALF THE SECURITY STRENGTH OF THESE ALGORITHMS.
AND HALF SOUNDS LIKE A LOT, BUT IT'S NOT. THERE ARE MANY ORDERS
OF MAGNITUDE OF SAFETY BUILT INTO THESE ALGORITHMS, SO MERELY
HAVING THAT SECURITY STRENGTH IS NOT SIGNIFICANT. IT'S STILL VERY
SAFE IN THE FACE OF A QUANTUM COMPUTING THREAT. BUT WITHIN THE
HANDSHAKE, THE KEY AGREEMENT ALGORITHMS IN PARTICULAR ARE
VULNERABLE TO QUANTUM COMPUTING ANALYSIS. SO SOMEBODY COULD BE
CAPTURING THOSE KEY AGREEMENTS AND OVER TIME, KEEPING A RECORD
OF ALL THE TRAFFIC, ALL OF THE KEYS AND TRYING TO DECRYPT IT
LATER. SO WHEN WE DESIGNED VPC ENCRYPTION AND OUR LEVER NETWORK
ENCRYPTION, WE WANT TO MAKE SURE THAT WE WERE RESILIENT TO THIS
LONG TERM THREAT. AND SO WHEN VPC ENCRYPTION, WE DON'T USE A
TRADITIONAL KEY AGREEMENT PROTOCOL. WE ACTUALLY USE
PRE-SHARED KEYS. AND WE HAVE A CONTROL PLANE THAT'S CONSTANTLY
DISTRIBUTING AND ROTATING THESE PRE-SHARED KEYS AMONGST ALL OF
THE SENDERS AND RECEIVERS. WE'RE ACTUALLY AT SUCH A SCALE. OUR
CUSTOMERS SEND SO MUCH TRAFFIC, AND THERE ARE SO MANY SENDERS
AND RECEIVERS ON VPC THAT IF WE WERE TO DO THIS NAIVELY, WE
WOULD ACTUALLY EXCEED THE SAFETY LIMITS AND SCALE THAT AS ITSELF
WAS DESIGNED FOR THE BULK DATA ENCRYPTION ALGORITHM. SO WE'RE
VERY INTENTIONAL ABOUT SHARDING THESE KEYS AND MAKING SURE WE
STAY WELL AWAY FROM THOSE SAFETY LIMITS. BUT THE BENEFIT OF USING
THESE PRE-SHARED KEYS IS THAT THEY'RE SIMPLY NOT VULNERABLE TO
THAT KIND OF ANALYSIS BY A QUANTUM COMPUTING, BY A QUANTUM
COMPUTER NATIVELY. AND ON LEVER, OUR PHYSICAL NETWORK LINK
ENCRYPTION, WE DID SOMETHING JUST A LITTLE DIFFERENT, WHICH
IS WE TOOK A HYBRID APPROACH WHERE WE USED THE TRADITIONAL
KEY KEY AGREEMENT ALGORITHM AND COMBINED THAT WITH PRE-SHARED
KEYS SO THAT WE GET THE BEST OF BOTH WORLDS. SO WE DIDN'T HAVE
TO BUILD A COMPLICATED CONTROL PLANE THAT SPANNED MULTIPLE AWS
REGIONS. THAT'S NOT SOMETHING WE LIKE TO DO FOR RELIABILITY AND
AVAILABILITY REASONS. SO WE COULD WE COULD STILL USE A
TRADITIONAL KEY AGREEMENT PROTOCOL, BUT ALSO MIX IN
PRE-SHARED KEYS SO THAT WE GET THAT SECURITY AGAINST QUANTUM
COMPUTERS. AND AS IF THAT WEREN'T ENOUGH, WE GO FURTHER
AND WE DO SOMETHING CALLED RATCHETING, WHICH IS WHEN A LINK
IS FIRST BROUGHT UP. WE DO THAT FIRST HANDSHAKE AND THAT
ESTABLISHES A KEY, AND THEN WE START ENCRYPTING DATA WITH THAT
KEY. WELL, NOT TOO LONG LATER WE WANT TO ROTATE THAT KEY. BUT
WHEN WE DO THE NEXT HANDSHAKE THAT'S ENCRYPTED BY THE FIRST
KEY AND SO ON. THE SECOND HANDSHAKE IS ENCRYPTED BY THE
FIRST AND THE THIRD IS ENCRYPTED BY THE SECOND, AND SO ON. AND
WHAT THAT MEANS IS, IF AN ATTACKER REALLY DID WANT TO BE
ABLE TO TARGET ANY CRYPTOGRAPHIC VULNERABILITIES IN THESE
ALGORITHMS, THEY'D MOST LIKELY HAVE TO KEEP ALL OF THE TRAFFIC
THAT WAS EVER SENT ON THE LINK FROM THE VERY BEGINNING, FROM
WHEN IT WAS BROUGHT UP, TO WHATEVER TIME THEY'RE INTERESTED
IN DECRYPTING, YOU KNOW? SO IF IT'S A MILLION KEYS LATER,
THEY'RE GOING TO HAVE CAPPED, THEY'RE GOING TO HAVE KEPT A
COPY OF THE 999,000 KEY AND THE 999,998 KEY, AND SO ON, ALL THE
WAY BACK TO THE FIRST KEY. THAT'S THE ONLY WAY THEY WOULD
BE ABLE TO DECRYPT EVERYTHING. AND WHEN YOU DO THE MATH, THESE
LINKS SEND SO MUCH TRAFFIC THAT THERE REALLY JUST ISN'T ENOUGH
STORAGE OUT THERE THAT COULD ACTUALLY STORE THOSE KINDS OF
VOLUMES OF TRAFFIC. SO IT'S A VERY DEEP, ROBUST KIND OF
PROTECTION THAT YOU'RE GETTING. IT'S SUPER INTERESTING. AND LAST
THING WE'RE DOING, AND THE LATEST THING WE'RE DOING IS THAT
WE'RE NOW ALSO DEPLOYING NATIVE POST-QUANTUM SECURITY TO THE TLS
SSL LAYER. AND WE'RE DOING THAT BY REPLACING THE LEGACY KEY
AGREEMENT ALGORITHMS WITH NEW ONES LIKE MXM THAT ARE DESIGNED
TO BE RESILIENT AGAINST QUANTUM COMPUTING ANALYSIS FROM DAY ONE.
AND WE'RE SHIPPING THIS IF YOU USE THE AWS KMS SERVICE, SECRETS
MANAGER, CERTIFICATE MANAGER AND OTHER SERVICES TODAY FROM
CLIENTS SUCH AS THE AWS SDK, THIS IS HAPPENING NATIVELY. SO
YOU'RE NOW GETTING POST-QUANTUM SECURITY AT THREE OR MORE LAYERS
ALL AT THE SAME TIME. HOW DO YOU KNOW WE'RE DOING ALL THIS? WELL,
THIS IS MY FAVORITE ANSWER TO THIS FROM ERIC'S SELECTION. ALL
OF THIS WORK IS OPEN SOURCE. WE DO THIS WORK NATIVELY IN GITHUB.
WE TRACK IT WITH GITHUB ISSUES. WE HAVE THIRD PARTIES WHO ARE
CONSTANTLY LOOKING AT THIS CODE AS WELL, HELPING US DO
OPTIMIZATIONS, HELPING US DO SECURITY RESEARCH AS WELL. AND
IT'S ALL DONE IN THE OPEN FOR EVERYBODY TO SEE. IF YOU'RE
INTERESTED, I ENCOURAGE YOU TO TAKE A LOOK. AND WITH THAT, I'M
GOING TO HAND YOU BACK TO ERIC, WHO'S GOING TO TALK ABOUT
SECURITY AND OPERATIONS AT AWS. THANK YOU.
>> HELLO AGAIN EVERYONE. HUMANS AND DATA DON'T MIX. THIS IS ONE
OF THOSE GLORIOUS TIMES WHERE EVERYONE'S INTERESTS ALIGN.
OBVIOUSLY, FROM A SECURITY PERSPECTIVE, RESTRICTING ACCESS
TO SYSTEMS AND DATA IS A GOOD THING. JUST AS OBVIOUSLY OUR
CUSTOMERS WANT TO LIMIT OUR ACCESS TO THEIR DATA, IDEALLY TO
ZERO. HOWEVER, WHAT MAKES THIS GLORIOUS IS THAT REDUCING HUMAN
ACCESS TO SYSTEMS AND DATA IS AN AVAILABILITY WIN. OUR SERVICES
WANT THEIR OPERATORS INTERACTING WITH THE HOSTS AS INFREQUENTLY
AS POSSIBLE, IDEALLY NEVER. THE PROBLEM WITH THIS IS THAT IT'S
HARD. THE REASON THAT WE HAVE OPERATORS IS TO OPERATE THE
SERVICES. THERE'S A BUSINESS REASON EVERY TIME THEY GO TO
INTERACT WITH THOSE SERVERS, THERE'S A BUSINESS REASON FOR
THAT ACCESS. AND SO IN ORDER TO ELIMINATE THOSE ACCESSES, YOU
HAVE TO AUTOMATE TO BUILD TOOLING AND TO ELIMINATE THE
REASONS FOR THOSE INTERACTIONS. SO ZERO OPERATOR ACCESS IS OUR
GOLD STANDARD. NOT ALL OF OUR SERVICES HAVE GOTTEN THERE, AND
NOT ALL OF OUR SERVICES ARE GOING TO GET THERE. FOR EXAMPLE,
OUR CUSTOMERS OF AWS MANAGED SERVICES EXPECT OUR OPERATORS TO
BE IN THERE DEBUGGING, CONFIGURING, TROUBLESHOOTING,
HELPING CUSTOMERS RUN THEIR AWS ESTATES. AND SO THAT SERVICE IS
NOT GOING TO GET TO ZERO OPERATOR ACCESS. SO LET'S DIG IN
TO A COUPLE OF THE SERVICES ON THIS LIST. ZERO OPERATOR ACCESS
DOESN'T MEAN THAT THERE WAS A DAY ON WHICH THERE WAS NO
OPERATOR ACCESS. IT MEANS THAT THERE'S NO WAY THAT AN OPERATOR
COULD GET ACCESS, NOT THAT WE DESIGNED IT THAT WAY, NOT THAT
WE LAUNCHED IT THAT WAY, BUT THAT STILL THAT WAY. DESPITE THE
FACT THAT WE'RE CONSTANTLY WRITING MORE SOFTWARE, LAUNCHING
NEW FEATURES, AND BRINGING NEW PEOPLE ONTO OUR TEAMS. SO KMS IS
OUR KEY MANAGEMENT SERVICE. CUSTOMERS CAN CREATE AND IMPORT
KEYS, MANAGE ACCESS TO THEM. MOST IMPORTANTLY, KMS IS
INTEGRATED ACROSS OUR SERVICES AND IS THE FOUNDATION OF THE
MANY ENCRYPTION FEATURES THAT WE OFFER. IF YOU HAD TO SELECT ONE
SERVICE TO GET TO ZERO OPERATOR ACCESS, I EXPECT YOU'D PICK KMS
BIT FOR BIT ENCRYPTION. KEYS ARE THE MOST SENSITIVE DATA THAT WE
HAVE, AND KMS WAS BUILT WITH ZERO OPERATOR ACCESS FROM THE
GROUND UP. SO THE BOXES THERE ON THE BOTTOM ARE HSMS HARDWARE
SECURITY MODULES. THEY ARE PURPOSE BUILT HOSTS FROM THE
SHEET METAL IN THAT WE DESIGNED AND BUILT OURSELVES SPECIFICALLY
TO PERFORM THIS ROLE IN KMS. AND THEY'VE BEEN CERTIFIED BY AN
EXTERNAL LAB TO FIPS 143 LEVEL THREE, WHICH INCLUDES A VERIFIED
LACK OF HUMAN ACCESS TO KEY MATERIAL. THIS MEANS THAT THE
ONLY WAY TO INTERACT WITH THESE HOSTS IS THROUGH AN API, AND THE
ONLY OPERATIONS THAT YOU CAN PERFORM ARE THE OPERATIONS THAT
ARE OFFERED BY THAT API. AND SO KMS OFFERS APIS LIKE ENCRYPT AND
DECRYPT AND CREATE KEY. BUT MOST IMPORTANTLY, THERE'S NO GET KEY.
THERE'S NO WAY TO GET A KEY OUT OF KMS. BUILDING A SCALABLE,
DURABLE, PERFORMANT AND COMPLIANT KEY MANAGEMENT SERVICE
IS A BIG JOB, AND WE'VE BEEN AT THIS FOR WELL OVER A DECADE. KMS
MAKES ONE PRIMARY PROMISE TO OUR CUSTOMERS NO HUMAN, WHETHER THEY
WORK FOR AWS OR NOT, CAN EVER GET A KEY OUT OF KMS. THE DESIGN
OF KMS WITH KEYS EXISTING IN CLEAR TEXT ONLY ON THESE
DEDICATED PURPOSE BUILT HARDWARE BOXES THAT WERE DESIGNED TO HAVE
ZERO OPERATOR ACCESS FROM THE START IS CORE TO DELIVERING ON
THAT CUSTOMER PROMISE. SO ONE OF THE MOST CRITICAL THINGS IN KMS
IS THAT WE TRUST ONLY THESE HSMS THAT HAVE BEEN CORRECTLY ADDED
TO THE DOMAIN, RUNNING THE CORRECT TRUSTED SOFTWARE. WITH
THE RIGHT SECURE CONFIGURATION, WE HAVE A FORMAL MACHINE
VERIFIABLE PROOF THAT THE PROTOCOL FOR USING WHAT WE
MANAGE THE DOMAIN, WHAT WE CALL THE DOMAIN MANAGEMENT DOMAIN
MEMBERSHIP IS CORRECT. THIS PROOF SHOWS THAT THE SECRECY OF
THE DOMAIN KEYS, WHICH ARE THEN USED TO ENCRYPT CUSTOMER KEYS,
CANNOT BE VIOLATED EVEN AGAINST AN INTERNAL ADVERSARY WITH
OPERATOR CREDENTIALS. AND AS KOHL MENTIONED, AWS IS OUR OWN
CRYPTOGRAPHIC LIBRARY. IT'S SUCH A CORE FUNCTION FOR US THAT WE
KNEW WE NEEDED TO OWN THIS. WE CAN'T FULFILL OUR KMS PROMISE IF
OUR CRYPTOGRAPHIC BUILDING BLOCKS AREN'T CORRECT. AND SO
AWS LOCK ITSELF WAS BUILT WITH CARE WITH A STRONG FOCUS ON
CORRECTNESS, INCLUDING A DEEP INVESTMENT IN FORMAL PROOFS. WE
HAVE MACHINE VERIFIABLE PROOFS OF THE CORRECTNESS OF THE
CRYPTOGRAPHIC PRIMITIVES AND MANY OTHER PROPERTIES OF THIS
LIBRARY, AND THESE PROOFS RUN AT BUILD TIME. IF ANY OF THE PROOFS
FAIL ON ANY BUILD, THE BUILD FAILS AND THE SOFTWARE DOESN'T
GET PUSHED TO PRODUCTION UNTIL SOMEONE COMES IN AND FIXES THE
UNDERLYING PROBLEM WITH THE SOFTWARE AND ALLOWS THE PROOF TO
SUCCEED. AND GIVEN THE PROOFS ABOVE, KMS SHOULD ALWAYS WORK
CORRECTLY. BUT IT'S NOT JUST BUILT RIGHT. WITH EVERY SOFTWARE
CHANGE, WE'VE VERIFIED THAT IT'S STILL RIGHT. EVEN SO, WE STILL
VALIDATE THE BEHAVIOR OF THE RUNNING SYSTEM, AND WE HAVE
AUDITORS THAT CHECK THE MEMBERSHIP OF THE PRODUCTION
DOMAIN, AND IT MAKES SURE THAT EACH HOST HAS THE SAME VIEW OF
THE PRODUCTION DOMAIN. IT GETS THE CONFIGURATION OFF OF EACH
HOST AND MAKES SURE IT MATCHES WHAT SHOULD BE IN THE PRODUCTION
DOMAIN, AND WE'RE CONSTANTLY VERIFYING THIS. WE'VE PUBLISHED
A PAPER THAT WE'VE DONE ON THE WORK FOR THIS DOMAIN MANAGEMENT
PROOF. SO THIS IS PUBLICLY AVAILABLE. YOU'RE WELCOME TO
CHECK IT OUT. LIKEWISE AWS ELK IS OPEN SOURCE. AND WE'VE
PUBLISHED MUCH OF THE FORMAL VERIFICATION WORK THAT WE'VE
DONE ON IT. AND OF COURSE, WE HAVE COMPLIANCE CONTROLS TO
SPEAK TO THIS. BOTH FIPS AND SOC2 CONTROLS. AND SO THIS IS
EVIDENCE THAT AWS IS DELIVERING ON THIS CUSTOMER PROMISE. THIS
IS A DIAGRAM OF THE EC2 NITRO ARCHITECTURE. EC2 IS A SYSTEM
THAT WE HAD TO BRING UP TO THE ZERO OPERATOR ACCESS BAR. EC2 IS
OLD ENOUGH THAT WHEN WE BUILT IT, ZERO OPERATOR ACCESS WASN'T
EVEN A TERM THAT PEOPLE WERE USING, AND IT'S ALSO ONE OF OUR
MOST FOUNDATIONAL SERVICES. IF YOU RUN A DATABASE IN AWS OR A
LAMBDA FUNCTION, OR USE ANY OF OUR AI AND MACHINE LEARNING
SERVICES, THEY'RE RUNNING ON EC2 INSTANCES, IT'S ABSOLUTELY
CRUCIAL THAT WE GET THE SECURITY RIGHT HERE. SO THE NITRO CARD,
THE BLUE BOX ON THE BOTTOM IS WHERE WE RUN OUR SOFTWARE. THIS
IS A SEPARATE PHYSICAL CARD WITH A PROCESSOR THAT WE MADE
OURSELVES. AND THIS PROVIDES A DEEP, CLEAR SEPARATION BETWEEN
AWS AND CUSTOMER WORKLOADS. AND THIS ISN'T AN HSM. WE DON'T HAVE
THE FIPS REQUIREMENTS TO ELIMINATE HUMAN ACCESS, BUT WE
STILL TOOK THE CHOICE TO BUILD NITRO FROM THE BEGINNING WITH
ZERO OPERATOR ACCESS IN PRODUCTION. AND WITH NITRO, WE
HAD THIS FUNDAMENTAL CHANGE ROLLING OUT THROUGH THE FLEET
AND IT WAS AN EXPENSIVE CHANGE. HOWEVER, EVERYONE WANTED IT.
NITRO GAVE US BETTER PERFORMANCE, IT GAVE US BETTER
AVAILABILITY, IT GAVE US BETTER FLEET OPERATIONS, AND IT ALSO
GAVE US BETTER SECURITY. IT WASN'T CHEAP, BUT IT WAS TOTALLY
WORTH IT. SO AS AN ENGINEER, WHENEVER YOU CAN COUPLE SECURITY
VALUE TO SOMETHING THAT THE TEAM ALREADY WANTS TO DELIVER, DRIVE
HARD. AND SO EARLIER I SAID WITHOUT HUMAN ACCESS IN
PRODUCTION, THAT'S AN IMPORTANT CAVEAT. WE HAVE A PACKAGE CALLED
THE SDK, THE NETWORK DEVELOPMENT KIT, AND IT ENABLES REMOTE
ACCESS AND OUR BUILDERS INSTALL IT WHEN THEY'RE TROUBLESHOOTING
OR DEBUGGING. AND SO WITHOUT IT, OUR DEVELOPMENT OF NITRO WOULD
SLOW TO A CRAWL. OUR DEVELOPERS WOULD HAVE TO DO ALL OF THIS
DEBUGGING AND TROUBLESHOOTING THROUGH APIS THAT ARE
INTENTIONALLY DESIGNED TO CONSTRAIN THEIR ACCESS. AND SO
WE EXPECT THE SDK TO BE INSTALLED ON NON-PRODUCTION
HOSTS WHEN OUR DEVELOPERS ARE ENGAGED THERE. HOW DO WE ENSURE
THAT THE SDK IS NEVER INSTALLED ON A PRODUCTION HOST THAT HAS
CUSTOMER DATA? SO AS WITH ALL SOFTWARE SHOPS, WE HAVE SOURCE
CODE REPOSITORY WHERE ALL OF OUR CODE IS COMMITTED AND ON COMMIT
WE AUTOMATICALLY KICK OFF BUILDS. BUT THESE ARE
DEVELOPMENT BUILDS. COMMIT LEADS TO DEVELOPMENT BUILDS. ON NITRO
WE DO 100% CODE SIGNING EVERY SINGLE ONE OF THE PACKAGES
INSTALLED ON NITRO HOST IS CRYPTOGRAPHICALLY SIGNED. SO WE
NEED A SIGNING KEY. SO WE GET THE DEVELOPMENT KEY SIGN THE
BUILD AND THE RESULT OF THIS IS A PACKAGE SIGNED BY THE
DEVELOPMENT KEY IN THE DEVELOPMENT PACKAGE REPOSITORY.
AND EVENTUALLY THIS PACKAGE WILL GET INSTALLED IN A
NON-PRODUCTION HOST. NOW WHEN THE TEAM DETERMINES THAT THE
SOFTWARE IS READY FOR RELEASE TO THE FLEET, WE KICK OFF A
PRODUCTION BUILD. THIS IS ENTIRELY ANALOGOUS TO THE
DEVELOPMENT BUILD, BUT WE USE THE PRODUCTION SIGNING KEY. AND
IN THIS FLEET, PRODUCTION IS A FORMALLY DEFINED STATE AND ONLY
HOSTS IN A PRODUCTION STATE HOST OR COULD HOST CUSTOMER
WORKLOADS. SO WE DO A FULL SECURE BOOT ON NITRO. AND THUS
WE HAVE CRYPTOGRAPHIC ASSURANCE THAT ONLY CORRECTLY SIGNED
PACKAGES ARE INSTALLED AND RUNNING. ONLY UNSIGNED CODE
CANNOT BE INSTALLED. OUR PRODUCTION HOSTS ONLY TRUST THE
PRODUCTION KEY. SO IF SOMEONE ATTEMPTS TO INSTALL A PACKAGE
SIGNED BY THE DEVELOPMENT KEY, IT FAILS AND WE CUT A MAJOR
TICKET. OUR AUTOMATION WATCHES THE BUILD SYSTEM. IF SOMEONE
SUBMITS THE SDK AS A PRODUCTION BUILD, THE BUILD FAILS AND WE
CUT A MAJOR TICKET. IF SOMEHOW THE SDK WERE BUILT USING THE
PRODUCTION KEY, WE WATCHED THE PACKAGE REPOSITORIES. IF A COPY
OF THE SDK IS SIGNED BY THE PRODUCTION KEY, WE REMOVE IT AND
WE CUT A MAJOR TICKET. WE HAVE AN AUDITOR THAT CONSTANTLY WALKS
THE FLEET. IT VERIFIES THAT EVERY HOST IN A PRODUCTION STATE
ONLY TRUSTS THE PRODUCTION SIGNING KEY. IT ALSO VERIFIES
THAT ALL OF THE CODE INSTALLED ON THAT HOST IS SIGNED BY THE
PRODUCTION KEY. AND AGAIN, IF WE HAVE ANY EXCEPTIONS, WE CUT A
MAJOR TICKET. AND EVERY TIME WE SAY THIS. WE CUT A MAJOR TICKET.
THAT'S A SUB TWO TICKET, A MAJOR TICKET. WE LITERALLY PAGE
SOMEONE SYNCHRONOUSLY AND WITH A 15 MINUTE RESPONSE. AND WE ALSO
ENGAGE THE SECURITY TEAM. AND THESE MECHANISMS THAT I'VE
DESCRIBED ARE OWNED BY DIFFERENT TEAMS IN EC2. AND SO SUPPRESSING
OR BYPASSING THESE CONTROLS WOULD REQUIRE CHANGES ACROSS
MULTIPLE TEAMS SPREAD ACROSS OUR ORGANIZATION. AND WE'VE
STRUCTURED THEM THAT WAY INTENTIONALLY. SO WE'VE NOT JUST
BUILT A SYSTEM WHERE HUMAN ACCESS ISN'T POSSIBLE ON LAUNCH
DAY. WE'VE BUILT A NETWORK OF CONTROLS THAT ENSURE THAT HUMAN
ACCESS CONTINUES TO BE IMPOSSIBLE FOR THE LIFE OF THIS
SERVICE. SO HOW DO WE KNOW WE HAVE ALL OF THE THINGS THAT WE
JUST WENT THROUGH? WE'RE AT EVERY STAGE. WE'RE CHECKING TO
MAKE SURE THAT THE SYSTEM IS WORKING THE WAY THAT WE EXPECT
IT TO WORK. HOW DO YOU KNOW WE HAD A RESPECTED EXTERNAL
SECURITY FIRM DO A DEEP DIVE IN THE NITRO SYSTEM, AND I
ENCOURAGE YOU TO DOWNLOAD THE REPORT AND REVIEW WHAT THEY
FOUND. SO ZERO IS THE BEST NUMBER, BUT IF YOU'RE NOT THERE,
THERE'S STILL GREAT VALUE IN DRIVING DOWN THE RATE AT WHICH
YOUR OPERATORS ACCESS HOSTS. YOU CAN DRIVE TO ZERO, AND THAT
MAKES THINGS SIMPLE. BUT THERE'S ANOTHER MAGICAL POINT. AND
THAT'S WHEN YOU DRIVE THE RATE OF ACCESSES DOWN TO THE POINT
WHERE YOU CAN REVIEW EVERY SINGLE ONE. THAT'S WHEN YOU CAN
DRIVE THE OPERABILITY, THE SECURITY, AND THE AVAILABILITY
OF YOUR SERVICE UP. SO WE ALL HAVE OPERATORS THERE AT THEIR
LAPTOPS, AND AT LEAST OCCASIONALLY THEY HAVE TO ACCESS
SOME PRODUCTION. HOST, AS I'M SURE YOU ALL DO, WE COLLECT THE
LOGS FROM THESE HOSTS AND THEY GET SENT TO A STORAGE SYSTEM. WE
USE S3 OF COURSE, AND THEN ON TO SOME ANALYTICAL SYSTEM WHERE WE
ANALYZE THEM FOR ABNORMALITIES, THINGS THAT WE DON'T WANT TO
SEE. ONE CHALLENGE HERE IS THAT FOR THE TYPICAL LINUX SYSTEM,
THESE ARE THE AUTH LOGS. YOU'VE GOT THINGS LIKE SSH ACCESSES WHO
USED SUDO THINGS LIKE THAT. BUT THERE'S JUST NOT THAT MUCH DATA
IN THEM. YOU CAN SPOT SOME PROBLEMS IN THEM. BUT BASED ON
THESE LOGS YOU CAN'T KNOW THAT YOUR SYSTEMS ARE OPERATING IN AN
ACCEPTABLE FASHION. AND SO TO ADDRESS THIS, WE HAVE AN
OPERATOR MONITORING SYSTEM THAT USES EBPF AND AUDIT HOOKS IN THE
KERNEL TO MONITOR AND LOG ALL OF THE ACTIVITY ON THESE SERVERS,
ON ALL OF THE SERVERS IN THE COMPANY. AND SO IMPORTANTLY, WE
GET A RECORD OF EVERY SINGLE PROCESS INVOCATION FROM EVERY
HOST. AND WE CAN TIE THIS BACK TO AN INDIVIDUAL HARDWARE MFA
AUTHENTICATED HUMAN. SO NOW WE KNOW WHO'S LOGGING IN AND
EVERYTHING THEY DID. THIS IS A GOLDMINE. NOW WE CAN DO THE
ANALYSIS AND UNDERSTAND WHAT THE MOST FREQUENT REASONS ARE FOR
HOST ACCESS. OUR ANALYTICAL SYSTEMS ARE WAY MORE VALUABLE
WITH THIS ADDITIONAL DATA. AND IF YOU HAVE A MATURE SYSTEM
THAT'S BEEN RUNNING AT SCALE FOR YEARS WITH NO BACK PRESSURE,
YOU'RE GOING TO HAVE HUNDREDS OR THOUSANDS OR MILLIONS OF
ACCESSES PER MONTH. AND A LOT OF THIS IS GOING TO BE SCRAPPY
TOOLING BUILT BY YOUR YOUR DEVELOPERS. IF YOU NEED TO GET
DISK I/O METRICS ACROSS THE ENTIRE FLEET, IT'S WAY EASIER TO
JUST WRITE A QUICK SCRIPT, LOG INTO EACH BOX, RUN THE COMMAND,
PARSE THE OUTPUT. IT'S QUICK AND EASY FROM AN EFFICIENCY
PERSPECTIVE, BUT THAT DEVELOPER CONNECTED TO THAT HOST WITH A
FULL SHELL, AND THE ONLY THING THEY DID WAS LOOK FOR DISK
METRICS. BUT THEY COULD HAVE RUN ANY COMMAND, EVEN IF THEY ONLY
NEEDED TO DO ONE THING. THEY HAD ACCESS TO DO EVERYTHING. SO NOW
THAT WE HAVE THIS DATA, WE CAN USE IT TO DETERMINE THE MOST
COMMON REASONS THAT OPERATORS ARE ACCESSING HOSTS. THERE ARE
THINGS LIKE RESTART A PROCESS. LOOK AT THE LOGS. WE COULD TURN
THOSE INTO TOOLS, AUTOMATING AND CONSTRAINING THEIR ACTIVITY. BUT
HOW DO YOU DO THAT? TURNING EVERYTHING INTO AN API WOULD BE
GREAT, BUT THAT SOUNDS LIKE WE'VE GOT THE API TEAM, THIS
TEAM THAT BUILDS IT. NOW WE'VE GOT THE WHOLE COMPANY BLOCKED ON
ONE TEAM. THAT'S A BAD IDEA. AND THESE TEAMS ALREADY HAVE ALL OF
THESE OPERATIONAL TOOLS, SHELL SCRIPTS AND WHATEVER ELSE THAT
THEY'VE BUILT OVER THE YEARS. CAN WE REUSE THAT. AND SO WE NOT
ONLY NEED TO BUILD IT, BUT WE NEED TO GET IT ROLLED OUT NOT
JUST ACROSS ALL OF THE SERVERS, BUT ACROSS ALL OF THE OPERATORS
AS WELL. THE HUMANS HAVE TO USE THE TOOL. AND SO WE BUILT A
CONSTRAINED OPERATIONS SYSTEM. IT'S GOT A CLIENT COMPONENT THAT
RUNS ON OUR CLIENT DEVICES, AND IT'S BOTH COMMAND LINE AND WEB
BASED. WHATEVER THE DEVELOPERS USED TO IN THAT SITUATION. AND
OUR OPERATORS INVOKE IT THERE. AND THEN IT CALLS OUT TO A
SERVER COMPONENT AND IT INVOKES VERBS. SO EACH OF THESE
OPERATIONS GETS WRAPPED UP IN A VERB. AND USING THE OPERATOR
MONITORING TELEMETRY, WE CAN OFTEN SUGGEST THE VERBS THAT THE
TEAMS NEED TO BUILD TO DRIVE THE RATE OF ACCESSES DOWN THE MOST.
AND SO NOW THAT WE'VE GOT THIS LIBRARY FULL OF VERBS, THINGS
LIKE START A PROCESS, LOOK AT THE LOGS, GET THE METRICS, WE
RANK THEM BY HOW SAFE THEY ARE, BOTH OPERATIONALLY AND FROM A
SECURITY PERSPECTIVE. AND SO SOMETHING LIKE GETTING
STATISTICS IS VERY SAFE. WE'RE GOING TO ALLOW PEOPLE TO DO THAT
WITH NO APPROVALS, RESTARTING A PROCESS THAT'S A LITTLE BIT MORE
DANGEROUS. MAYBE THERE'S SOME APPROVALS THERE RUNNING
ARBITRARY UNIX COMMANDS. THAT'S GOING TO REQUIRE A SIGNIFICANTLY
HIGHER SET OF APPROVALS. AND SO NOW WHEN WE GIVE SOMEONE ACCESS
TO RUN ONE OF THESE VERBS, THAT'S WAY EASIER TO GRANT FROM
A SECURITY PERSPECTIVE. WE'VE TOLD THEM HERE, YOU CAN GO DO
THIS THING RATHER THAN YOU CAN DO ANYTHING. PLEASE ONLY DO THIS
THING. AND SO ONCE WE RANK THESE VERBS, WE CATEGORIZE THEM. AND
AGAIN, WE'VE GOT THE THINGS WHERE WE ALLOW PEOPLE TO DO THEM
FREELY WITH NO APPROVALS, ALL THE WAY UP THROUGH A MUCH MORE
ARDUOUS SET OF APPROVALS. AND SO HOW DO WE DO THAT, THOUGH? I'VE
BEEN SKIPPING A STEP IN HOW OUR OPERATORS GET ACCESS TO HOST IN
AMAZON, AUTHORIZATION IS THE PROCESS OF DETERMINING IF A
PRINCIPAL SHOULD BE ALLOWED TO PERFORM AN ACTION. AND WHEN
GRANTING ACCESS TO OUR SERVERS, WE HAVE TO AUTHORIZE THESE
COLORS. SO IN REALITY, IF I WANT TO ACCESS A HOST, I ACTUALLY
CALL OUT TO AN AUTHENTICATION SYSTEM AND I SAY, HEY, I WOULD
LIKE TO LOG INTO THIS HOST AND AUTHORIZATION SYSTEMS LIKE,
WELL, LIKE THIS IS ALLOWED. HERE'S A KEY THAT WILL ALLOW YOU
TO DO THAT. AND THEN I CAN USE THAT KEY TO START THAT SESSION
INTERNALLY. THIS IS ALL DONE USING SSH CERTIFICATES AND A
BUNCH OF SOFTWARE THAT WE'VE WRITTEN IN THE DEFAULT MODE OF
THIS SYSTEM. THIS IS A STATIC LIST OF USERS. OVER TIME, THESE
LISTS TEND TO GET QUITE LONG. YOU KNOW, THERE'S A LARGE SET OF
EMPLOYEES THAT MAY NEED TO HAVE AN MAY HAVE A BUSINESS NEED TO
ACCESS THE SERVERS, BUT THEY DON'T HAVE A NEED ON THAT DAY.
AND EVERY SINGLE ONE OF THOSE PEOPLE THAT'S ON THAT LIST IS A
RISK THAT YOU CARRY EVERY DAY, EVEN IF THEY DON'T NEED THAT
ACCESS. THIS IS THE DESIGN POINT FOR MOST SYSTEMS, BECAUSE IT'S
WHAT'S EASY TO DO IF YOU'VE GOT A DIRECTORY, ACTIVE DIRECTORY,
LDAP, SOMETHING LIKE THIS. MAKING GROUPS OF USERS IS THE
EASY THING TO DO. BUT BECAUSE WE HAVE OUR OWN AUTHORIZATION
SYSTEM IN THE MIDDLE OF THIS TRANSACTION, WE CAN DO A BETTER
JOB OF REDUCING ACCESS WHILE STILL ENABLING OUR OPERATORS. WE
CALL BEING SMARTER ABOUT THIS CONTINGENT AUTHORIZATION YOUR
ACCESS TO A HOST OR SERVICE. YOUR AUTHORIZATION IS CONTINGENT
ON EXACTLY WHAT YOU'RE TRYING TO DO AND WHY YOU'RE TRYING TO DO
IT. SO NOW WHEN I QUERY THE AUTHORIZATION SERVICE, I HAVE TO
TELL IT WHAT I'M TRYING TO DO RUN THIS VERB AND WHY I'M TRYING
TO DO IT. AND IN THIS CASE, IT'S A TROUBLE TICKET. AND MAYBE IT'S
A CHANGE MANAGEMENT OR CHANGE MANAGEMENT GO THROUGH AN
APPROVALS PROCESS. MAYBE IT'S A CUSTOMER SERVICE CASE. AND IN
MANY CASES, FOR EXAMPLE, WITH CUSTOMER SERVICE CASES, OUR
EMPLOYEES DON'T EVEN NOTICE THE PIVOT HERE. IT'S ALL AUTOMATED
COMPLETELY. I'M WORKING ON BEHALF OF THIS CUSTOMER. I WOULD
LIKE TO GET THIS METADATA. AND IT JUST SEAMLESSLY HAPPENS. AND
SO IF I'M ALLOWED NOW I GET A RESPONSE BACK FROM THE
AUTHORIZATION SERVICE TELLING ME ERIC IS ALLOWED TO DO THIS
THING. AND EVEN IF WE DIDN'T TAKE ANY EXTRA AUTHORIZATION
STEPS HERE, NOW WE KNOW WHAT I'M TRYING TO DO AND WHY I'M TRYING
TO DO IT. AND THAT IS AN INCREDIBLY RICH ANALYTICAL DATA
STREAM. SO NOW I CAN USE THIS SIGNED KEY TO AUTHENTICATE TO
THE SERVER, BUT ONLY TO PERFORM THIS ONE OPERATION INTERNALLY.
WE'VE DONE THIS BY ADDING FORCED COMMANDS TO SSH CERTIFICATES AND
A BUNCH MORE SOFTWARE THAT WE'VE WRITTEN. WE CAN CHECK TO MAKE
SURE THAT I'M CURRENTLY ON CALL, THAT MY CONNECTION IS COMING
FROM AN EXPECTED LOCATION, ETC. IF WE CAN'T PROGRAMMATICALLY
VERIFY THAT MY ACCESS IS APPROPRIATE, WE CAN REQUIRE A
PEER OR A MANAGER TO APPROVE MY ACCESS. AND THIS GETS US AGAIN,
ANOTHER ROBUST LOG STREAM THAT'S AN ABSOLUTE GOLD MINE. WE
PROCESS THESE REPORTS FOR OUR MANAGERS ALL THE WAY UP THROUGH
MATT GARMAN. WE ALSO RUN A SERIES OF ANOMALY DETECTORS
ACROSS THESE LOGS LOOKING FOR UNUSUAL ACTIVITY. THE
JUSTIFICATIONS PROVIDED BY EMPLOYEES, COMBINED WITH THE
DETAILED TRANSCRIPTS OF THE COMMANDS THEY ACTUALLY RAN, IS A
RICH FIELD FOR THE APPLICATION OF GENERATIVE AI. AND SO USING
THIS FEEDBACK LOOP OF RECORDING IN DETAIL WHAT HAPPENED,
AUTOMATING COMMON OPERATIONS AND PUSHING BACK ON UNNECESSARY
ACCESSES REPEATED WEEK AFTER WEEK, MONTH AFTER MONTH, DRIVES
CULTURAL CHANGE AND GREATLY LOWERS THE NOISE. FLOOR
OPERATORS GET BETTER TOOLS, COMMON ISSUES ARE AUTOMATED
AWAY, AND ACCESS BECOMES LESS FREQUENT. AND SO THAT ALLOWS US
TO PUT MORE SCRUTINY ON THE REMAINING ACCESS AND TO REQUIRE
TIGHTER JUSTIFICATIONS ON THE REMAINING ONES, LEADING TO A
VIRTUOUS CYCLE. OUR SERVICES ARE ON THIS JOURNEY, AND SOME OF
THEM, LIKE FARGATE AND LAMBDA, HAVE REACHED THE END. WE'VE
ELIMINATED ALL INTERACTIVE HUMAN ACCESS TO THESE HOSTS, INCLUDING
THE ABILITY TO RUN ARBITRARY UNIX COMMANDS VIA OUR
CONSTRAINED OPERATOR TOOLS. SO HOW DO WE KNOW? AS I MENTIONED,
WE HAVE ALL OF THIS TELEMETRY COVERAGE, VISIBILITY AND THE
CLOSED LOOP ANALYSIS ALL THE WAY UP THROUGH OUR CEO. WE ALSO HAVE
A NUMBER OF COMPLIANCE CONTROLS. WE HAVE SOC2 CONTROLS. BSI IS A
GERMAN STANDARD AND FINMA IS A SWISS STANDARD. AGAIN, ALL OF
THESE ARE ALL AVAILABLE FOR SELF-SERVICE DOWNLOAD ON THE
ARTIFACT SERVICE. AND NOW I'D LIKE TO BRING CALM BACK.
>> THANK YOU ERIC. SO I WORK WITH CUSTOMERS WHO ARE MIGRATING
OFTEN FROM ON-PREMISES AND OTHER LEGACY ENVIRONMENTS DIRECTLY
INTO THE AWS CLOUD, AND IT'S STILL NEVER CEASES TO AMAZE ME
HOW THE BIGGEST IMPROVEMENT THEY GET THE MOST QUICKLY IS MOVING
AND USING THE AWS IDENTITY AND ACCESS MANAGEMENT SERVICE. OFTEN
THESE CUSTOMERS ARE MOVING FROM AN ENVIRONMENT WHERE THEY HAVE
SHARED TEAM ACCOUNTS, AND NO ONE REALLY KNOWS WHO DID WHAT. IT'S
NOT SO TRACEABLE, AND THEY OFTEN EVEN HAVE A LITERAL PASSWORD
BOOK WITH PASSWORDS WRITTEN DOWN IN A DESK DRAWER SOMEWHERE.
WELL, THE IDENTITY AND ACCESS MANAGEMENT SERVICE AUTOMATES ALL
THAT AWAY. MAKES IT EASIER THAN EVER TO HAVE SUPER FINE GRAINED
PERMISSIONS AND TRACEABILITY. IT'S ONE OF THE CORE PILLARS OF
SECURITY ON AWS, BUT ALL OF THAT WOULD BE FOR NOTHING IF I AM
WERE SIMPLY DOING THE WRONG THING. IF WE'RE LETTING THE
WRONG PEOPLE ACCESS THE WRONG RESOURCES OR PERFORM THE WRONG
ACTIONS, IT WOULD BE MEANINGLESS. IT WOULD ALSO BE
MEANINGLESS IF IAM WERE TOO HARD TO USE. IF CUSTOMERS WERE
CONSTANTLY CREATING MISCONFIGURATIONS THAT CREATED
EITHER OVERLY BROAD OR TOO PERMISSIVE OR TOO RESTRICTIVE AN
ACCESS POLICY, BOTH WOULD KILL AN ORGANIZATION. AND SO WE FACE
A TREMENDOUS AMOUNT OF FOCUS ON MAKING SURE THAT I AM IS CORRECT
IN ITS IMPLEMENTATION, AND SO THAT IT'S EASY FOR CUSTOMERS TO
USE IT CORRECTLY. AND THE FIRST PILLAR OF HOW WE DO THIS IS OUR
APPROACH WITH OPENNESS AND TRANSPARENCY. WE USE IAM
OURSELVES INTERNALLY PERVASIVELY. WHEN ONE SERVICE
CALLS ANOTHER SERVICE ON A CUSTOMER'S BEHALF, WE'RE USING
THE SAME IAM CALLS AND APIS THE CUSTOMERS CAN USE AND WE USE PER
CUSTOMER SERVICE LINKED ROLES. WE LOG THOSE EVENTS, CUSTOMERS
CAN SEE THEM. CUSTOMERS CAN EVEN BREAK THEM AND DENY THOSE
ACTIONS IF THEY WANT TO. AND WE PUBLISH THE POLICIES AND
PERMISSIONS THAT WE GRANT TO THOSE ROLES. THEY'RE IN THE AWS
DOCUMENTATION, AND WE KNOW THAT THIRD PARTIES AND SOME AWS
HEROES PAY PRETTY KEEN ATTENTION TO THOSE POLICIES AND CONSTANTLY
VET THAT WE'RE NOT MAKING THEM OVERLY BROAD OR ALSO TOO
RESTRICTIVE. BUT WE ALSO CONSTANTLY WANT TO MAKE SURE
THAT THE IMPLEMENTATION OF IAM, THE ACTUAL CODE AND BUSINESS
LOGIC THAT'S CHECKING ONLY THIS PERSON SHOULD HAVE ACCESS TO
THAT AND SO ON IS ACTUALLY CORRECT. THAT'S ONE OF THE MOST
CRITICAL, CRITICAL LAYERS TO GET RIGHT. AND TO DO THAT, WE USE
AUTOMATED REASONING AND FORMAL METHODS. THE FIRST
IMPLEMENTATION OF IAM WHEN WE FIRST BUILT THE SERVICE WAS
CALLED ASPEN. OVER TIME, AS WE GREW IN SCALE, WE REALIZED WE
WANTED TO BUILD A MUCH MORE LIGHTWEIGHT AND PERFORMANT AND
HIGHLY OPTIMIZED IMPLEMENTATION. WE CALL THAT BALSA. AND WHEN WE
BUILT BALSA, WE DECIDED FROM DAY ONE WE WOULD USE AUTOMATED
REASONING AND FORMAL VALIDATION TO ENSURE THAT IT WAS CORRECT
AND REALLY GETTING THE RIGHT ANSWERS. WE ALSO APPLIED THIS
SAME APPROACH TO CEDAR, OUR OPEN SOURCE POLICY LANGUAGE, WHICH
YOU CAN USE IN YOUR OWN APPLICATIONS. AND YOU CAN SEE
HOW WE DO THESE TECHNIQUES. AND BY USING AUTOMATED REASONING,
WE'RE RELYING ON ADVANCED SIMULATION TECHNIQUES WHERE
WE'RE ABLE TO GENERALIZE AND SUMMARIZE HUGE COMBINATIONS OF
ALL POSSIBLE INPUTS AND DISTILL THEM DOWN TO A FEW CASES THAT
THEN HAVE TO BE MODELED MATHEMATICALLY THROUGH THE
SYSTEM. AND THEN CHECK THAT SIMPLE INVARIANTS HOLD SIMPLE
INVARIANTS LIKE, WELL, ONLY THE RIGHT PEOPLE SHOULD ACTUALLY
HAVE ACCESS TO THE RIGHT THINGS, AND SO ON. LET'S MAKE SURE THAT
THE CODE TRULY RESPECTS THAT. BUT ONE OF MY FAVORITE THINGS
ABOUT WORKING AT AWS IS WHEN WE APPROACH THIS. WE DIDN'T JUST
SAY, WELL, WE'RE JUST GOING TO PROVE THIS MATHEMATICALLY, AND
WE'RE GOING TO RUN THE FORMAL PROOFS. AT THE END OF IT, WE GET
A BINARY RESULT. TRUE OR FALSE? IT'S PROVED OR NOT, THAT IS
HUGELY VALUABLE. THE MAIN REASON WE'RE DOING THIS IS TO PROVE
THAT THESE SYSTEMS ARE CORRECT. BUT WE WANTED TO GET EVEN MORE
VALUE OUT OF THIS. WE WANTED THESE SAME TECHNIQUES TO BE ABLE
TO TELL CUSTOMERS WHAT THESE GENERALIZATIONS AND SUMMARIES
ARE, SO THAT WE COULD HELP PEOPLE UNDERSTAND COMPLEX SETS
OF POLICIES AND RULES. AND THIS IS WHAT POWERS IAM ACCESS
ANALYZER. ACCESS ANALYZER IS ACTUALLY USING THE SAME
AUTOMATED REASONING AND FORMAL METHODS UNDER THE HOOD. IT'S
DOING THESE GENERALIZATIONS AND IT'S PROVIDING THOSE
GENERALIZATIONS AS INSIGHTS TO YOU. SO YOU CAN GIVE IT LARGE,
COMPLICATED POLICIES AND RULE SETS. AND IT WILL TELL YOU IN
SIMPLE SUMMARIES, HERE'S WHO HAS ACCESS TO WHAT AND WHY. AND
WE'VE INTEGRATED THIS DEEPLY INTO OUR OWN PROCESSES WHEN WE
CREATE MANAGED POLICIES AND THOSE OTHER RULE SETS THAT WE
PUBLISH AND SHOW YOU WHAT OUR PERMISSION SETS ARE, THE FIRST
THING WE'RE DOING WHENEVER WE CREATE A NEW ONE OF THOSE RULE
SETS, OR MAKE A CHANGE, IS ACTUALLY RUN A TRUE ACCESS
ANALYZER BEFORE WE EVEN DO HUMAN REVIEW, BEFORE WE EVEN WASTE A
SECURITY ENGINEER'S TIME, WE'RE HAVING ACCESS ANALYZER TELL US
AND CATCH ANYTHING THAT WOULD BE OVERLY BROAD OR OVERLY
RESTRICTIVE. AND IT'S REALLY TIGHTLY INTEGRATED AND VERY,
VERY POWERFUL IN MY EXPERIENCE. HOW DO YOU KNOW WE'RE DOING
THIS? YOU CAN LOOK UP OUR FEDRAMP DOCUMENTATION. THE
REFERENCES ARE ON THIS SLIDE. NOW, AT THIS POINT WHEN I'M
EXPLAINING, I AM AND OUR CORRECTNESS AND THE FACT THAT WE
FORMALLY VALIDATED THE ACTUAL IMPLEMENTATIONS, IF THERE'S A
SECURITY ENGINEER IN THE ROOM, THEY OFTEN ASK ME, OKAY, BUT
WHAT IF THE IAM SERVICE ITSELF WERE COMPROMISED? WHAT IF THERE
WAS, YOU KNOW, YOU'VE PROVEN ALL THIS BUSINESS LOGIC, BUT WHAT
HAPPENS IF IT FELL INTO THE HANDS OF A MALICIOUS ACTOR WHO
SIMPLY OVERRIDES THAT LOGIC? WELL, IT'S NOT SO SIMPLE. THERE
ARE A LOT OF LAYERS OF DEFENSE IN FRONT OF THE IAM SERVICE. AS
YOU CAN IMAGINE, IT'S ONE OF OUR MOST HEAVILY DEFENDED SERVICES.
THERE ARE MANY LAYERS OF ENCRYPTION, MANY LAYERS OF
OPERATOR ACCESS CONTROL, MANY, MANY OTHER LAYERS OF ATTESTATION
AND VALIDATION, AND SO ON TO. BUT STILL, THIS KIND OF MOVIE
PLOT THREAT IS A QUESTION WORTH ASKING. AND IT'S A REALLY
INTERESTING EXAMPLE OF HOW OUR APPROACH TO CHECKS AND BALANCES
AND INDEPENDENCE AND SEPARATION OF CONCERNS COMES OUT, BECAUSE
THE WAY WE THINK ABOUT IT IS EVEN IN THIS KIND OF CRAZY MOVIE
PLOT, WORST CASE SCENARIO, WHERE A CORE AUTHORIZATION SYSTEM WERE
COMPROMISED, WE STILL WANT TO ENSURE THAT ALL OF OUR DETECTIVE
CONTROLS, ALL OF OUR MONITORING, EVERYTHING ELSE WOULD STILL
CATCH THAT WOULD STILL KNOW INSTANTLY. AND SO IF YOU LOOK AT
CLOUDTRAIL, FOR EXAMPLE, OUR DETECTIVE CONTROL OUR LOGGING
SYSTEM THAT SHOWS CUSTOMERS THE ACCESS ATTEMPTS AND ACCESSES ON
THEIR RESOURCES, YOU'D SEE THAT IT'S MAINTAINED BY A SEPARATE
TEAM IN A SEPARATE ORG. THAT'S INTENTIONAL. IT IS A SEPARATE,
DEDICATED PROCESS ON EVERY MACHINE. THAT'S ALSO
INTENTIONAL, BY THE WAY. THAT'S A LITTLE INEFFICIENT AND
UNOPTIMIZED. IT WOULD BE BETTER PERFORMANCE IF WE JUST HAD ONE
TIGHT PIECE OF CODE THAT AUTHORIZED AND DID ACCESS
CONTROL, AND THEN IMMEDIATELY LOGGED THE EVENT. THAT'S NOT HOW
IT WORKS. WE INTENTIONALLY HAVE SEPARATE PROCESSES THAT ARE KEPT
INDEPENDENT, DIFFERENT CODE PATHS, DIFFERENT EVERYTHING AS
MUCH AS POSSIBLE, AND SO THAT EVEN IN THIS EVENT, WE HAVE AN
INDEPENDENT STREAM OF WHAT'S GOING ON THAT WOULD MAKE THESE
KINDS OF MISCONFIGURATIONS APPARENT. THE CUSTOMERS WOULD
STILL SEE THAT THINGS ARE HAPPENING. AND THIS IS A REALLY
GOOD EXAMPLE. I THINK, OF HOW THAT SEPARATION OF CONCERNS AND
COMPENSATING CONTROLS WORKS OUT IN THE REAL WORLD. IT'S NOT JUST
ABOUT TECHNICAL ISOLATION, BUT ABOUT ORGANIZATIONAL ISOLATION
AS WELL. NOW, THROUGHOUT THIS TALK, WE'VE COVERED A LOT ABOUT
OUR CULTURE OF SECURITY HERE AT AWS, AND WE'VE GIVEN YOU
REFERENCES THAT YOU CAN LOOK UP TO VERIFY THE STATEMENTS THAT
WE'VE MADE ON STAGE. BUT I HOPE WE'VE ALSO GIVEN YOU A FIRST
PERSON SENSE OF JUST HOW DEEPLY WE DO CARE ABOUT SECURITY
DATABASE, AND HOW IT REALLY IS OUR NUMBER ONE PRIORITY FOR US,
AND NOT A CULTURAL VALUE THAT WE WOULD COMPROMISE ON. BUT THAT
SAID, WE ARE JUST ALWAYS HUMBLED BY OUR CUSTOMERS. WE KNOW THAT
WE'RE BUILDING THAT INFRASTRUCTURAL, FOUNDATIONAL
PLUMBING LAYER. IT IS OUR CUSTOMERS WHO ARE ULTIMATELY
BUILDING THE HOUSES, HOTELS, OFFICES AND CASTLES THAT ARE
BUILT ON TOP OF THAT FOUNDATION AND ACTUALLY DELIVER THOSE WORLD
CHANGING EXPERIENCES TO YOUR END USERS, TO YOUR CUSTOMERS AND TO
CITIZENS. AND SO WE'RE JUST ALWAYS EAGER AND LOOKING FORWARD
TO SEEING WHAT YOU BUILD ON TOP OF AWS AND APPLY SECURITY
PATTERNS IN HOW YOU HOW YOU DO THAT, TOO. SO ALL OF THOSE END
USERS ARE PROTECTED AS, AS POSSIBLE. WITH THAT, THANK YOU
VERY MUCH FOR COMING TO OUR TALK ON BEHALF OF MYSELF AND ERIC,
AND ENJOY THE REST OF RE:INFORCE.
