# AWS re:Inforce 2025 - Best practices for managing governance, risk, and compliance globally (GRC301)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=pCNIpnb9tvE)

## Video Information
- **Author:** AWS Events
- **Duration:** 52.5 minutes
- **Word Count:** 6,906 words
- **Publish Date:** 20250620
- **Video ID:** pCNIpnb9tvE

## Summary
This comprehensive GRC session features three speakers covering global governance, risk, and compliance best practices. Navas Doriraj (AWS Cloud Governance) discusses people and process fundamentals, Akash Grover (Meta) shares Meta's multi-account governance strategy managing 1000+ AWS accounts, and Aaron Kuo (AWS Control Tower) explains control strategies. The session covers Meta's approach using AWS Organizations, service gating through SCPs, infrastructure-as-code requirements, and RCPs for data perimeters. Key topics include three control types (preventive, proactive, detective), AWS Control Tower's 750+ managed controls mapped to 10 compliance frameworks, and data resilience strategies including AWS Backup's logically air-gapped vaults and new multi-party approval features.

## Key Points
- **GRC Criticality**: Cost of non-compliance often exceeds compliance maintenance costs; proper GRC reduces security incidents and enables cost optimization
- **Meta's Scale**: 4 billion monthly users, 1000+ AWS accounts, using AWS Organizations for logical grouping and policy enforcement
- **Pre-Deployment Reviews**: Meta requires finance, privacy, legal, network security, and third-party access reviews before any cloud deployment
- **Infrastructure as Code**: Meta mandates 100% Terraform deployment with secure-by-default modules and TfLint/TfCompliance integration
- **Three Control Types**: Preventive (SCPs, RCPs, declarative policies), proactive (CloudFormation hooks), and detective (Config rules)
- **Service Control Policies**: Maximum permissions for identities, useful for data sovereignty, cost control, and security restrictions
- **Resource Control Policies**: Maximum API actions on resources, ideal for data perimeter and network boundary enforcement
- **AWS Control Tower**: 750+ managed controls mapped to 10 compliance frameworks including FedRAMP and CIS
- **Data Resilience Strategy**: Define RTOs/RPOs, implement least privilege, determine retention periods, enable encryption, validate through testing
- **Backup Protection**: AWS Backup's logically air-gapped vaults with service-owned keys and new multi-party approval for data retrieval

## Technical Details
- **Meta's Organization Structure**: Hierarchical AWS Organizations with specialized OUs for incident response, DMZ experimentation, and ephemeral sandbox accounts
- **Service Gating Implementation**: Dynamic SCPs based on use case approval, 40-45 critical service whitelisting, DDU hashing to avoid SCP limits
- **Error Handling System**: CloudTrail monitoring for access denied messages with custom binary providing real-time user guidance
- **Secure-by-Default Modules**: Terraform modules for S3, EC2, EKS, VPCs with abstracted security controls and automated compliance checks
- **Log Aggregation Pipeline**: S3 bucket aggregation with SQS integration consuming billions of logs daily from Config, GuardDuty, CloudTrail
- **SCP vs RCP Distinction**: SCPs control principal permissions, RCPs control resource access - often used together for comprehensive boundary definition
- **Declarative Policies**: Currently limited to EC2 services (EBS, VPC) with automatic configuration enforcement across all accounts/regions
- **CloudFormation Hooks**: Lambda functions or Guard DSL for proactive scanning during deployment pipelines
- **Config Rules Implementation**: Configuration change recording with rule evaluation, CloudWatch events, and SNS alerting capabilities
- **Backup Architecture**: Tag-based policies, cross-account/region support, audit manager reporting, logically air-gapped vaults with AWS service isolation

## Full Transcript

Welcome, everyone. Thank you so much for joining us. This is GRC 301, best practices for managing governance, risk, and compliance globally. So my name is Navas Doriraj. I'm part of our cloud governance team and we support our services like Control Tower organizations and config. I'm joined by Aaron Kuo, who is the leader for AWS Control Tower, and that's our secure landing zone service for customers, and Akash Grover, who is one of our lead production engineers for Meta. Just to highlight why GRC is so important to organizations. We're starting to see more and more workloads being moved to the cloud, and in the past it would be test work workloads which meant that GRC could be possibly optional. Now no more, it's a must for organizations. And this stat sometimes surprises a few folks. The cost of non-compliance can be higher than maintaining compliance in cloud environments. And so if we were to implement GRC properly, Then organizations would experience fewer security incidents, as well as benefit from cost optimizations. So hopefully this gives you an idea of why GRC is so critical to organizations. But there are challenges in implementing. Governance risk and compliance. A lot of our customers are always dealing with new or updated regulatory environments. This is changing across geographies, it's changing across industries. We see it in healthcare, we see it in public sector, we see it in financial sector. Your environment has to be able to adapt to all of these changes. And this means your tools, your processes and rules. And then, data, data usage is increasing across all of our customers. More customers, organizations are exploring generative AI. MLAI workloads, analytics, and so on. So data is becoming incredibly more valuable, but then at the same time, we have to consider data privacy, sovereignty, and it's resiliency and protection. And with all of this, this other challenge is you also have to balance your cost versus the risk management solutions that you implement across your environment. So That's what we're gonna talk about today. We're gonna talk about how you can implement GRC across your environments globally. And so our agenda for today is, I'll first talk a little bit about the people and process aspects because it has a huge impact on GRC's effectiveness across your multi-count environment. Aka will share how meta thinks about governance and how meta implements governance within their multi-account environment. Aaron will talk to us about how to implement a control strategy, the different types of controls, and how you can set it up in a multi-count environment. And finally, I'll round it off by talking about data resilience at scale. So the people and process. This is quite basic, but I think it's incredibly critical. And it applies to a lot of initiatives, not just GRC, but start with your why, and it means aligning with your business objectives. So, for example, um, you might be an organization that is building a mobile application that has a payment processing system. That means you're dealing with PCI or personal credit card information, or PII data, but that means that you will have to meet certain kinds of regulatory financial frameworks, security standards, and so on. And then the data itself has to be governed, it has to be protected, and you may also want to consider who has access to this kind of sensitive data sets, and you can take this further when you think about who is using these data sets, example, redacting certain uh certain fields and phrases. And this is all about managing the risk and ensuring compliance. Second, Assess your existing processes. We're not saying that you need to start from scratch. You probably already are implementing GRC processes rules within your existing organization. But Understand where you are in this journey, and here we have a few types of questions that you can ask yourselves to figure out what you have currently running, what's existing, and then consider how you can improve upon them. It's not meant to be revolutionary. We're trying to evolve your existing processes. And third, um, this is a, a strong recommendation, align with your stakeholders. You have leaders who are gonna play a key role in implementing the GRC program and its initiatives across your organization. They have to understand why GRC policies are so critical and how it can help them make better decisions for the organization. And then your teams, your teams may consist of hundreds to thousands of development teams. These teams are dealing with individual applications. These applications will have different components, different resources, different resource configurations, different data sets. Some might be public, some might be private. These applications are going to require. And have a different set of compliance requirements and so that means your individual teams your development teams also have to be well aware of the governance risk and compliance requirements as well as the organizations. And so, hopefully, this gives you a good idea of why the people and process aspects are so critical to implementing GRC. And with that, I'm going to invite Akash to talk to us about Mehta's governance story. Hello everyone, thank you Nvas, um. My name is Akan Grover. Um, I, I work in Meda's Cloud Foundation team. Uh, at Meta, uh, we serve 4 billion monthly active users, 3 billion daily active users. At our scale, we provide services to people across the globe. Um, we have to comply with the standards across the globe. Um, this is the primary reason why building a robust GRC story is very important for us. Um You might know at Mera we own our own data centers. We run our own data centers. We have one of the largest infrastructure backbone in the world. Um, our own infra enables us to Provide services at a massive scale reliability to our users. Um, however, we still leverage AWS for our infra needs. Uh, some factors which make us use AWS. Um, latency, sometimes you want to be closer to your end user. Um, experimentation, AWS has a lot of services, more than 200 services. Some of these services help our developers do POCs, uh, move fast, build features for our users, um, specialized capabilities. So sometimes, uh, we don't have the right type of compute, right type of services within our data centers, so we'll leverage AWS to fulfill that gap. Uh, compliance, like I mentioned before, we run our services across the world. So we have to um comply with standards across the world. Some of these standards are very strict based on geolocation laws and things like that. So AWS fills those gaps for us too. Um, at this point, we have more than 1000 AWS accounts, um, growing every day. Serving different needs, serving different compliance use cases and things like that. Cloud compliance, uh, in meta starts before any part of the infra is deployed. Uh, we make sure every use case, uh, which goes to cloud goes through different reviews related to finance, privacy, legal network security, third party access, things like that. Um, some of these are very obvious finance, because we want to have strict budget controls. Third party access, if a use case is going to work with a third party, we want them to go through third party reviews, uh, to make sure we're not sharing data with a with a vulnerable partner or something like that. Uh, privacy reviews at our scale, we need to do privacy reviews so every developer team understands the privacy requirements, uh. Deletion control for similar reasons. We don't want to hold on to user data for more than more time than we have to. Um, these reviews help us gain visibility into our use cases even before we we let anything being deployed in cloud. And this lets us get ahead of the problem in the long run. In Mera, uh, we, uh, we use AWS for very different workloads. All of these workloads are very different from each other. Some of them are. Really large HPC clusters. Some of them are really small third party use cases. Um, at our scale we need to logically group these accounts, AWS accounts, apply codified policies, uh, to manage our requirements, to manage our compliance. Um, AWS organization is the way we have went forward to codify these policies. As you can see, this is a very high level simplified diagram of our organization tree in in Meta. Uh, This lets us group accounts logically according to their use case um the structure enables us to scale deploy preventive controls reliably, um, and it just lets us scale and work at our level. um, some special use cases which are enabled via this structure, um, incident response. So if we, if we notice a malicious event in a certain account, we can move that account to our incident response so you lock it down. So threat engineers, threat detection people can go in and investigate the problem. Uh, DMZ is our experimentation. Um, this is the only part of our organization tree where we allow root to be used, for example. So it serves very, very different use cases, but that's the, that's the way we. Removed usage of root, but still have a way to get back as route if you need to. Uh, sandbox is very special, um, that lets us create ephemeral accounts with higher, higher controls or actually low controls, but some restrictions, um. If an account is created in sandbox, we make sure it's gone and within 2 weeks. This allows us to enable our developers to do experimentation, move fast, um, do POCs and things like that. So the other guardrails which we have codified um are something like service gating. Service gating is a special compliance thing. Um, this makes sure we don't let use cases um use resources to store data which they are not explicitly approved for. For example, if your use case should not be using S3, we won't let you use S3. Um, this is done via SEPs. We create dynamic SEPs based on your use case. Uh, we have selected 4045 services which are critical to us. Um, based on the use case we'll generate an SEP for your account. Um, we do make sure we don't run into SEP limits by doing Ddu hashing, and all those other algorithms we can use, um. This lets us comply with some special requirements on our side. Uh, we are very serious about infrastructure as code. Uh, we've ordered also codified policies for infrastructure as code. Uh, this makes sure every, every part of our infrastructure is managed by terraform. Uh, this enables us to build controls into terraform. This helps lets us build more compliance controls into CICD pipelines and things like that. Um, we use RCPs. Uh, RCP is a new feature. Uh, this was released by Amazon last year. We've already started using it to create data parameters around our sensitive workloads. Uh, we keep gonna build more RCPs, keep gonna build more data parameters, um, but we've already codified some of these policies. Uh, one issue you might think you might be thinking if you have some experience with SEPs or RCPs you might be thinking about is um bad user experience with all these policies user will get access denied messages, and one feature which SEPs, in my opinion, lack is dynamic error messaging for every error. The way we solve this or we try to solve this is by looking at tailing crowd trail for all these errors. Uh, if we see an access denied because of one of our codified policies, we'll immediately let the user know why why their API core failed, what we want them to do. If they're trying to create an S3 bucket in console, we'll block them, we'll tell them how, how we want them to create an S3 bucket and for example, and things like that. Um, this helps us keep the user experience sane. Um, this is a very simplified diagram how this works. We consume cloud trail from all the accounts. We filter out all the access denied messages, and we have our custom binary which keeps tailing these messages and notifying users about these errors and these problems. This lets us build more codified policies while keeping the user experience manageable. I said I've said it before, but infrastructure scored is very important for us, um. We strive to make sure 100% of our code is deployed via terraform. Uh, my team provides a CLI called Cloud CLI to, to our customers, to our developers within Meta. Cloud CLI is a wrapper around terraform. It has integrations for with, uh, internal systems, internal CICD pipelines, and things like that. Um, so we want everyone to use Terraform. We want everyone to write terraform to manage their infrastructure. Uh, this makes all the changes go through code reviews, uh, which is a requirement for us. Uh, this also lets us build small secure secure by default building blocks. What, what do I mean by that? Uh, if you notice a lot of people using S3, we'll write a module for it, abstract all the security controls in the module, and we'll ask users to use our module. The thinking behind it, behind it is if you use our module, you're always secure by default. Um, you're doing the right thing as for the data you're storing in your S3 bucket. We can abstract the encryption control, access controls, and all that, uh, and users don't have to figure that out all the time. It just. Takes care of all the problems for you. Uh, we have followed the same process in EC2, EKS, VPCs, and other modules. If we see some resource being utilized a lot in our infrastructure, we will write a module for it. We will try to abstract all the security controls for it. Um, what it enables you, uh, as a developer, you can pick one of our smaller building blocks, integrate this with your infrastructure, and build a larger piece of infrastructure within your account. You're choosing all this secure by default building blocks, and our hope is your larger part of your infrastructure will be secured by default. Uh, we have also integrations for TF Linds, TF Comply. These are both open source projects, um. We we use regular rules to detect problems in your code, um, making sure we can we can warn you, we can block you from deploying dangerous configurations, um, this helps us shift left, uh, and stop you from making dangerous configuration changes in AWS. This is uh the high level. Um, set up we use to, to create visibility into our AWS environment. Um, this lets us consume, uh, as you can see, this lets us consume, uh, logs from AWS managed services like Config, Guardy, Cloudril, um, Cloudwatch. Uh, if there's an AWS managed service, we'll, we'll consume the logs in a similar way. We'll aggregate these logs into an S3 bucket, integrate this with SQS, and just start bringing these logs back to meta so that we can analyze them better, so we can store them better. Um, this has helped us scale our, our AWS adoption in the last 5 years. Um, it's the same model we use to bring billions of logs every day back to meta and store them long term to satisfy our compliance requirements, to do security analysis, to do more analytics, to build, to take more data centric decisions on our infrastructure. I want to specially shout out to AWS config. Um, AWS config, we used to do, uh, we collect snapshots from AWS config across all the accounts, all the regions which we operate in. Um, we consume these snapshots, bring them back. This has helped us take a lot of data centric decisions. For example, AWS config can tell you. Um, which resource is being utilized by your team most and this helps us, um, figure out which which resource we should write a module for and things like that. Um, this also helps other downstream teams like capacity management, finance, even, even cloud users trying to deploy stuff in their account, um, evaluate their own infra, take better decisions and things like that. Uh, and same, same goes for Wiz. Wiz is a third party integration we've recently built. Uh, we use Wiz sensors on our compute. We use Wiz Wiz outpost, um, and this helps our security teams, uh, triage security incidents, um, keep an eye on our infra all the time, um, keep the security incidents manageable, um. And this has enabled us to deliver security at scale. Um, as the was pointed out earlier, you need to figure out your GRC goals before you build a GRC story. And me, we think visibility monitoring and prevention are our top-level goals for GRC. Um, AWS as a provider will provide multiple paths, multiple options for you to hit these goals. But, but there are so many, so many ways you can build a story around this. Uh, there you can, you can do everything using manage AW service or you can build your own thing. Uh, end of the day, this is gonna be a choice, um, of, of, of the, of the team managing your infra. Um, And with that, I'm gonna hand it over to Aaron to talk about control strategies you can adopt in AWS. Good afternoon. Uh, as Navas introduced earlier, my name is Aaron Ku. I am the senior manager for AWS Control Tower. I want to start by thanking everybody for being here on the last day of Reinforce for the absolutely riveting topic of GRC. Hope you all, uh, hope I'm able to carry your wakefulness until the the end of the hour. Um. The cornerstone of a governance risk and compliance strategy has to be a comprehensive set of controls that help you audit your applications and resources for adherence to those policies or even better guarantee that uh those policies are not violated in the first place. Um, we're gonna. Start by taking a look at um the GLC challenges uh reviewing the GLC challenges that the VA put up earlier. Um, data sovereignty for uh regulatory reasons is usually top of many enterprises list of concerns. Uh, you also have data perimeter for access control, uh, and data resiliency or protection, uh, particularly from ransomware. Beyond just security, uh, you also tell us that, uh, in many cases operational concerns such as application availability and cost management also form part of the uh GRC objectives in your organizations. Before I dive into um. The governance controls proper when call out that AWS actually provides a very extensive list of services that you can use to help uh manage your uh GRC objectives. So for example, uh, guard duty provides intelligent threat detection through AI Cloud trail, of course, uh, I'm sure most of you are familiar with. You can use it to audit your API, the API actions that happen within your AWS environment. An audit manager uh collects evidence that can be used for compliance assessments. Uh, you can enable these services individually or in whatever combination makes sense for your needs. Obviously there are way too many of these to go through, uh, in a deep dive at a session like this, but we encourage you to, um, have immersion days for any uh um services that you might be interested in. Governance controls encapsulate GRC policies. They are a tool that can be used to either prevent a violation from happening or audit that a violation has not occurred. There are three categories of such controls. Preventive controls will prevent policy violations through hard enforcement, um. They are designed such that users cannot create resources that would violate the policy in the first place or uh are prevented from updating resources in a way that would cause the policy to be violated um preventive controls are particularly useful for central IT administrators or security teams to use in a way that um enforces a blanket uh policy across the entire organization. On the other hand, uh, proactive controls are designed to scan um the configurations of resources within uh a deployment or provisioning pipelines such as terraform or cloud formation. Earlier you heard I can talk about how meta uses terraform and they have a set of such controls um in the pipeline to validate that uh any resources being deployed adhere to the policies and a little later I'll talk I'll show an example of how you can do a similar thing in a cloud formation pipeline. Finally, detective controls um are designed to audit the environment or applications and resources to make sure that they don't violate the policies these uh controls do not perform any sort of blocking actions so they are always safe to enable they're just there to scan existing resources for any violations. um, detective controls are useful for um. Compliance officers or auditors who might want a report uh to show that no such policy violations have occurred in the environment they are often also used as a secondary line of defense together with preventive or proactive controls at the same time. Let's deep dive into uh each of these control types, starting with uh preventive controls. Preventive controls are implemented as AWS organizations policies um they disallow any actions defined in them from being taken and they often are used to enforce these absolute boundaries uh in your AWS usage, um. there are 3 types of um such organization policies, service control, service control policies, or SEPs, resource control policies or RCPs, and declarative policies. uh RCPs and declarative policies are relatively new. Um, SEPs, uh, are designed to set the maximum allowed, uh, permissions for identities or principles, um, within your organization. Uh, you can prevent or restrict identities from performing, uh, any API actions that you deem uh never uh allowable or restrict those, uh, actions to a limited set of individuals, for example, a security team. Uh, RCPs on the other hand, uh, control the maximum allowed, uh, API actions that can be performed on a resource. So these are often used, uh, for data perimeter scenarios as we will see in an example. And finally, declarative policies are used um where you can define a uh specific configuration for an attribute for a resource uh within an AWS service. Once you've declared this configuration. in a specific way, AWS takes care of ensuring that all resources of this type within the organization will absolutely have this configuration value so uh it cannot be overridden. Start by taking a look at uh some SEP examples. SEPs are similar to IM policies but they don't grant any permissions rather they specify the maximum allowable permissions. You can attach these policies to an organization route, organization unit or at account level um. These, uh, if you attach them to an organization root or OU, um, we take care of ensuring that all the member accounts that are under that hierarchy are also inherit the policy. So let's take a look at some uh specific examples starting with uh one of our favorites which is a data sovereignty one. This particular policy will ensure that uh services and uh resources are limited to a specific AWS region in this particular case, uh, AP Southeast too. Another example is a policy that limits uh the usage of EC2 instances to a specific EC2 instance like T2 micros in this case, and, um, such policies can be used for either application availability concerns or cost management uh concerns. Uh, another example is a security one, unsurprisingly, um, you can use a policy to deny, uh, certain APIs, uh, from being used, uh, uh, or being called for, uh, security or logging or networking services, uh, in to, to make sure that nobody changes any settings either accidentally or maliciously. Another common uh policy example is uh the limitation of uh the creation of new IAM users or access key creations. These examples are available in uh a repository that is uh publicly available we will provide a link to uh that repository at the end of the presentation so you can take a look at it, uh, use the examples either as inspiration or directly in your own environments. Now, let's take a look at some uh LCP examples. Remember the LCPs define the maximum allowable API actions uh on resources. First, uh, there is, uh, this is a policy that will restrict, um, actions that are taken on, uh, some, a set of resources to be, uh, from identities or users within my own organization only you cannot um an actor from external to the organization uh cannot uh take any API actions uh on those resources. Similarly, uh, this particular policy defines a networking, uh, perimeter where any API actions have to be, uh, initiated from within the corporate network or VPC, and these two examples, of course, uh again, uh, data perimeter examples which are often a GRC concern. So RCPs and SEPs are two different types of controls. They, it is not an either or. You can always use them in conjunction with each other. SEPs operate over principles, RCPs operate over resources as I've said, and. It is often easier to express your objectives in one or the other depending on what you're trying to do, so you should use the appropriate uh control type, uh, in your environment. Earlier, again, you heard a country talk about how meta actually uses uh both RCPs and SEPs in their environment. There are some, uh, use cases, uh, additional use case examples I've got on there, but I'm not gonna go through them one by one and, uh, put you to sleep there. So I'll, I'll give you a specific example. Top half of the slide is an RCP which defines a data perimeter around uh resources within your environment, the same policy we saw earlier, such that um only users from within your corporate environment can access uh resources within that organization, external actors cannot do so. The bottom half of the slide shows an SCP which uh restricts those same corporate users from accessing resources outside the organizational boundary. So working in conjunction, you have a very clearly defined boundary around the, the data that you care about. Let's talk about declarative policies. Uh, remember these are policies that can define uh specific configuration values uh for an AWS service. Currently decorative policies are only supported for the ECT suite of services, uh, which include EBS and VPC. Uh, for the purposes of this particular example, let's say I want to ensure that uh my EBS snapshots can never be shared, uh, publicly, and this includes both existing and future snapshots. To do this, I would define a declarative policy. And attach that policy to an organizational unit within my organization once attached. The policy is uh inherited by all member accounts within uh that organizational unit and the ECT control plane respecting the declarative policy will ensure that all uh. Snapshots within both the accounts and all regions uh will be governed by this policy and the attribute will be configured to block all sharing. Next, uh, let's take a look at proactive controls. Uh, reminder proactive controls are used, uh, to ensure that no uh incorrectly configured, uh, resources are deployed through a provisioning system. Um, Cloud formation defines a has a feature called cloud formation hooks. These hooks can be attached to your cloud formation uh pipeline to validate uh any resources, the configurations of any resources that are being deployed through the pipeline. In this case, let's start with a simple template that creates in S3 bucket. The S3 bucket uh has no attributes attached to it. Now, as part of my cloud formation pipeline, I have a set of cloud formation hooks attached to it. One of the hooks happens to validate that the uh any S3 buckets are being deployed through the provisioning pipeline has to be encrypted. So when I tried to deploy this particular template. The hook will execute and it will uh cause a failure to be generated because there is no encryption defined on this S3 bucket uh it cause a rollback of the deployment and uh the application developer will get an appropriate error message and they have a chance to remedy uh the template before attempting uh the deployment again. Cloud formation hooks uh can be defined in a number of different ways, uh, including lambda functions. So you can use a lambda function to define a hook or a domain specific language like uh called uh guard that is supported by uh cloud formation. We have again, examples of these uh hooks inside a registry that is publicly accessible. We will share that link uh at the end of the talk so you can take a look at what might be appropriate for you. Finally, let's talk about detective controls, the, uh, so additional line of defense uh for auditing your environment and making sure uh nothing is violated. Uh, detective controls are implemented as uh AWS config rules. Uh, remember they don't actively prevent any actions or changes, so they, they can always be enabled safely. Very often what we see customers do is before, uh, a preventive or proactive control might be enabled, they actually enable detective controls first. To understand what violations might already be present in existing applications or resources within the environment, make sure that everything's fixed correctly before enabling the preventive or proactive controls, and this is done to ensure that no uh unintentional breakages happen if you enable uh the preventive or proactive controls too soon. When um Config is enabled in AWS config is enabled in your environment. One of the things it does is record all uh configurations that configuration changes that happen, uh, in your, in your environment. So concrete example, let's say I have an EC2 instance and I add a new tag to it. This additional tag causes a new configuration to be created which is captured by the AWS config uh recorder. The configuration change is then sent to a config rule which would then evaluate the configuration uh for any violations uh that might be present if the configuration is uh valid, it will um indicate as such otherwise it will return that the resource in question is noncompliant with the policy it encapsulates uh you can retrieve this noncompliant state either through an SDK. Um, or through a console, or you can be alerted to it through a cloudwatch event or an SMS topic. Um, as we've discussed, there are 3 different kinds of these controls, uh, preventive, proactive, detective. Um, you can obviously implement and deploy these controls on your own that whatever suits your needs, but one thing we'll call out is AWS actually. Uh, provides uh a set of managed controls that are already available that you can just turn on. These controls are managed by us and they represent the best practices that we believe, uh, make the most sensible for most customers. Um, you can discover these controls through the control catalog, uh, in Control Tower. Uh, there are over 750 controls available now and we're always adding more. You can search for these controls uh within the catalog and all of them have a consistent name space as well as a set of consistent metadata like the domain, uh, like an objective, for example, encryption or common control uh definitions such as encrypt data at rest. Um, we also map, uh, these controls to a set of common compliance frameworks. Uh, last week we just, um. Uh, released an update to the control catalog where we now have mappings for 10 compliance frameworks including uh FedRAM, um, CIS V8, and, uh, one of the, uh, a few of the NIS frameworks. I can never remember the numbers. I'm sorry, they're very long. Um, but once you've discovered the appropriate controls in the uh catalog that you uh need. You can simply use the enablement APIs within Control Tower to deploy these at an organization unit uh within your organization, make it very convenient to uh fulfill any objectives that you might have um uh the GRC. So quick takeaways at the end, um, so controls help you achieve your GLC objectives. They are really critical to uh to achieving them. There are 3 types of controls preventive, proactive, and detective and finally there are a set of uh managed controls that you can easily discover and on many of these controls we are actually part we do uh release the source code as open source as well in the repository, um, again links at the end of this, uh, presentation. Next, I'm gonna have uh Navas come back and talk about data resiliency. Data resilience at scale, so we're gonna switch gears a little. Akash talked to us about the meta-governance story, Aaron, about controls, and now we're gonna talk about data resilience, so data aspects. The first is Data has value, and you may have already heard of this phrase, data is a new oil. It's been shared with several of our AWS presentations, but the main point here is that with data, we can do and accomplish a lot of different things. Organizations are using it to. Build operational efficiency, improve the customer experience for products, as well as innovate with many different things. So data is extremely valuable. And it needs protection, resilience, and governance, depending on the type of data, and sometimes we may tier data into different data sets, sensitive data sets, private data sets, public, and so on. The second, and this is something to keep in mind, is that Data is growing and it's growing at an exponential. Pace We're adding more and more data sources to feed into our analytics, into our machine learning models, and more. So if you actually take a look at this chart, you will see that in 2010, we had two zettabytes and 1 zettabyte is equivalent to 1 trillion gigabytes. So we had 2 zettabytes in 2010. And in 2028, we expect to nearly go about 200 times more. So that's a lot of data. Um, it's very hard to visualize, but the main, the key point here is it's exponential. So what this means then is that we really need to protect this data and build it into proper resilience standards. And that's a challenge. Um, that's a challenge because we're working with a multi-count environment. You have multiple accounts, you have multiple teams. They all have their own applications. But how do we standardize and ensure that The data, the applications are backed up and are meeting your compliance requirements. And so we, we start with backup because it's one of the primary ways of meeting. Your data resiliency and protection goals. The first recommendation is, understand your recovery recovery time objectives and the recovery point objectives for your applications. Your applications as shared before, are going to be different. Uh, you may have an application that's a test application that's dealing with a public data set versus an application that is. In production dealing with PCI data. And it's important to unders like review the use cases, understand what the individual RTOs and RPOs are, and group the applications accordingly. The second is implement least privileged policies, and and this is very similar to ensuring that You understand who has access to the data. Not everybody needs access to the PCI data sets as an example. Third, Determine your backup retention period. What do I mean by this? Um, there's 3 types of backups. Incremental, differential, and full, but with incremental, you're taking a backup um since the last change. And with differential, you're taking a backup since the last full backup and then a full backup is just everything altogether. But this again is going to depend on your application, your use case, and the compliance requirements. 4, enable encryption strategies for the data that's being backed up. And number 5. Actually, this is something that applies to everything that we do, even the controls that we apply across a multi-count environments. Validate it so here we're talking about data policies, but it also applies to the controls that you're applying validate it through continuous testing and auditing, setting up reporting and ensuring that the controls that you have applied across your environment are doing what you expect them to do. And so how do we accomplish this on AWS? The key service to do this is AWS backup. And AWS backup supports a variety of services. On the compute side, it supports EC to container workloads, even VMware. You can use AWS backup to back up on-premise VMware data. To the cloud Supports storage in the form of E um EFS and EBS databases that range everything from Dynamo DB, Aurora, RDS and TimeStream and more. Um, so you can set up backup plans. And you can set this up across your organization. And you can set up multiple backup plans depending on. Your goals for each application group. The second is the 3rd actually is setting up the notifications. Notifications are very important because you need to know who's accessing your backed up data, and you can use cloudwatch, you can use cloudril as as well as SMS. Some customers may even set up Slack notifications. Um, but it's important to know who's accessing the backup data. And then of course, this works across your multi-count environment, both across organizations and control tower. You have IAM controls, and this is also important, backup audit manager. This allows you to create backup reports. And it helps you answer the questions of have I backed up all of the important resources across my environment? Have I encrypted my backup? And number 3, have I met my compliance requirements? So by setting up reports and you can set this up on a continuous or daily or like anything that you'd like um. It it gives you a good report of where your backups are. Again, you can access this through the console, through the API and SDK like several of our services. Uh, the last, the third one is the most important and key. We've seen a lot of customers use this, but it's the tag-based approach to set up your backup policy and so. Organizations may tag their applications as prod, and that will apply appropriate backup policy to the prod-based applications, and then you can do something similar for test and so on. Now, there is a challenge that takes place here. Um, you can do everything right. You can set up your backup policies. And it's working across the organization, it's working across all of your thousands of applications. But what if, for some unfortunate reasons, someone gets access to your management account? In that case, that entity could potentially corrupt your backup data or even delete it, and that's the risk. And so we introduced. AWS backup logically air gapped vault. And this simply means that The backup data is within the AWS service accounts, so it's containerized from the customer's AWS accounts. And so if somebody gets access to those AWS accounts, the management account. Um, this is still safe. And so this isolates the data using service own keys, ensures that the data is immutable, and also allows you to recover your data quickly using AWS RAM from AWS organizations. Now, um, yesterday, we actually added to this feature. And the new feature is backup integration with multi-party approval. So think of this as simply you're giving a group of individuals the ability to approve. Back up, um, data retrieval actions. And so you can do this within an AWS organization's environment. Um, and, and this helps because now you can set up a team of 4 or 5 individuals that have to approve a certain action before the data is retrieved from. The um, the lag data backups. OK, so I'd like to uh quickly summarize the data resilience piece of things, um, one review your applications, develop a backup strategy for each of your applications, and take advantage of the lag and the multi-party approval for your teams to provide greater governance for your data. Then, in conclusion. Um, from Aaron's talk, we talked a lot about controls, and these are examples of SEPs, RCPs, and cloud formation guard rules that you can review and get started with using to build your own custom rules. The other recommendation I'd make, uh, we would make is, um, take a look at AWS control tower. It has a whole host of managed controls that should give you a good starting point. That concludes our presentation. Thank you so much for joining us.
