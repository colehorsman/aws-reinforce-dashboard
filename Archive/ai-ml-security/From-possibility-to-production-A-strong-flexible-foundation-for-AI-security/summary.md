# AWS re:Inforce 2025 - From possibility to production: A strong, flexible foundation for AI security

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=jlrJVbu9I-U)

## Video Information
- **Author:** AWS Events
- **Duration:** 63.0 minutes
- **Word Count:** 9,246 words
- **Publish Date:** 20250619
- **Video ID:** jlrJVbu9I-U

## Summary
This session provided a comprehensive framework for building secure AI systems from proof of concept to enterprise production. AWS VP Hart Rossman and VP Becky Weiss outlined a three-stage approach: bootstrapping ideas with AI-powered development, scaling implementations with flexible controls, and organization-wide deployment with an AI-first mindset. The presentation emphasized "living in the future" by implementing tomorrow's security capabilities today, treating generative AI as the connective tissue of modern enterprise architecture that interfaces with every workload from compute to IoT devices.

## Key Points
- - **Three-Stage AI Security Framework**: Bootstrap ideas → Scale implementations → Organization-wide AI-first deployment
- **"Living in the Future" Philosophy**: Implement advanced security capabilities today for tomorrow's AI landscape
- **AI as Connective Tissue**: Generative AI interfaces with virtually every enterprise workload and technology stack
- **Defense in Depth**: Security controls must work across entire distributed systems, not just individual LLMs
- **Secure by Design**: Thoughtful AI security implementation raises the security posture of entire organizations
- **Bootstrap with AI**: Use generative AI to build generative AI applications and security controls
- **Working Backwards**: Start from customer data requirements and implement flexible controls for innovation
- **Full Stack Deployment**: Enterprise-wide AI implementation requires rethinking human-computer interaction
- **Economic Impact**: Properly secured AI drives substantial productivity gains and profitability increases
- **Planetary Scale Architecture**: Building globally distributed systems requires end-to-end security architectures

## Technical Details
- - **Foundation Services**: Built on core AWS services (EC2, S3, etc.) with AI-specific security layers
- **Multi-Stage Architecture**: Proof of concept → Pilot scaling → Enterprise production deployment patterns
- **Integration Points**: Security controls across compute, containers, databases, analytics, edge devices, and IoT
- **Identity and Access Management**: Advanced IAM integration for AI workloads with Becky Weiss's identity expertise
- **Distributed Systems Design**: Global deployment capabilities with regional security consistency
- **Automation Integration**: AI-powered security automation built into development and operations workflows
- **Technology Stack Coverage**: Security spans from infrastructure layer through application and data layers
- **Flexible Control Framework**: Adaptive security policies that scale with AI adoption maturity
- **Customer Data Protection**: Work-backwards methodology starting from data sensitivity and access requirements
- **Future-Proofing Architecture**: Extensible security design accommodating rapid AI technology evolution

## Full Transcript

>> HELLO, EVERYBODY. THANKS FOR
COMING TO THIS TALK. WE HAVE ON FROM POSSIBILITY TO PRODUCTION.
BUILDING A STRONG, FLEXIBLE FOUNDATION FOR AI SECURITY.
IMAGINE BUILDING THE NEXT BREAKTHROUGH AI APPLICATION, ONE
THAT COULD TRANSFORM YOUR BUSINESS, REVOLUTIONIZE YOUR
INDUSTRY, RESHAPE HOW WE INTERACT WITH THAT TECHNOLOGY.
AND NOW IMAGINE DOING IT WITH COMPLETE CONFIDENCE IN YOUR
SECURITY FOUNDATION. MY NAME IS HART ROSSMAN, VICE PRESIDENT OF
SECURITY AT AWS. AND JOINING ME LATER TODAY ON THE STAGE IS
BECKY WEISS, VICE PRESIDENT AND DISTINGUISHED ENGINEER, WHO
FOCUSES ON AWS IDENTITY SERVICES. AND WE'RE EXCITED TO
TAKE SOME TIME TODAY TO TALK ABOUT HOW YOU CAN BUILD A
STRONG, FLEXIBLE FOUNDATION STARTING FROM WHEREVER YOU ARE
IN YOUR AI JOURNEY. NOW, JUST A FEW YEARS AGO, GENERATIVE AI
BURST ONTO THE SCENE AND ORGANIZATIONS FACED A CRITICAL
QUESTION HOW DO WE INNOVATE RAPIDLY WHILE MAINTAINING
SECURITY? NOW, TODAY, BECKY AND I ARE GOING TO SHOW YOU HOW AWS
AND SOME OF OUR CUSTOMERS HAVE ANSWERED THAT QUESTION. AND
WE'LL SHOW YOU HOW A STRONG, FLEXIBLE FOUNDATION CAN TAKE US
INTO THE NEXT ERA OF AI INNOVATION. NOW WE'VE SEEN
REMARKABLE EVOLUTION IN HOW ORGANIZATIONS APPROACH AI
SECURITY FROM PROOF OF CONCEPT ALL THE WAY THROUGH TO
PRODUCTION. THOSE DEPLOYMENTS ARE JUST FANTASTIC. AND AS WE
EXAMINE THE EVOLUTION OF AI SECURITY, IT'S CRUCIAL THAT WE
TAKE ON THIS PERSONA OF LIVING IN THE FUTURE, RIGHT? IT'S NOT
REALLY AN ASPIRATIONAL STATEMENT, RIGHT? WE CAN SEE
WHERE AI IS GOING. WE CAN LOOK AROUND CORNERS AND THINK AHEAD
TO THE SECURITY CAPABILITIES WE'LL NEED IN THE FUTURE, AND WE
CAN START IMPLEMENTING THEM TODAY. SO NO MATTER WHAT STAGE
YOUR ORGANIZATION IS CURRENTLY AT, YOUR SECURITY REQUIRES THAT
YOU OPERATE TODAY AS THE INDUSTRY WILL OPERATE SEVERAL
YEARS FROM NOW, RIGHT? IT'S NO REASON TO WAIT. WE MUST PIONEER
GENERATIVE AI AND MACHINE LEARNING INTO EVERY ASPECT OF
OUR OPERATIONS. IT'S AN IMPERATIVE IN TODAY'S
MARKETPLACE. AT EACH STAGE, WE NEED TO FOCUS ON ANTICIPATING
AND SHAPING THE FUTURE OF SECURITY. NO MATTER WHERE YOU
ARE IN DEVELOPMENT, AWS CAN SUPPORT YOUR AI EVOLUTION. RIGHT
NOW. IF YOU LOOK AT THESE THREE STAGES FROM PROOF OF CONCEPT TO
ENTERPRISE PRODUCTION, RIGHT, WE ENCOURAGE TEAMS TO START WITH
BOOTSTRAPPING THEIR IDEAS, USING AI, BUILDING SECURITY IN USING
AWS CLOUD SERVICES, AND PILOTING IDEAS. RIGHT? THIS IDEA OF
BOOTSTRAPPING USE GENERATIVE AI TO BUILD GENERATIVE AI
APPLICATIONS, RIGHT? THEN WE MOVE INTO SCALING YOUR
IMPLEMENTATIONS. WE LOOK AT WORKING BACKWARDS FROM BOTH
CUSTOMER DATA AND IMPLEMENTING FLEXIBLE CONTROLS TO DRIVE BOTH
INCREMENTAL AND DISRUPTIVE INNOVATION. NOW, AS YOU BEGIN
YOUR ORGANIZATION WIDE IMPLEMENTATION, WE'RE SEEING
CUSTOMERS EMBRACE AI FIRST MINDSET AND HOW THEY ENVISION,
DESIGN, BUILD AND OPERATE THEIR MECHANISMS. AUTOMATION AND
TECHNOLOGY. IT'S A FULL STACK DEPLOYMENT USING GEN AI, AND
THIS APPROACH ALLOWS OUR CUSTOMERS TO NOT JUST OPTIMIZE
FOR TODAY, BUT REALLY TO LAY THE GROUNDWORK FOR FUTURE
DEPLOYMENTS WHILE PERPETUALLY INNOVATING. RIGHT NOW, THIS
ISN'T JUST A NEW WAVE OF TECHNOLOGICAL DEPLOYMENT AND
DEVELOPMENT, RIGHT? GENERATIVE AI IS ALLOWING US TO RETHINK
THAT HUMAN COMPUTER INTERACTION, RIGHT? AS GENERATIVE AI BECOMES
DEEPLY EMBEDDED ACROSS YOUR ORGANIZATION. IT'S DRIVING
SUBSTANTIAL ECONOMIC GAINS, INCREASING PRODUCTIVITY AS WELL
AS PROFITABILITY. NOW, CUSTOMERS ARE TELLING US THAT GENERATIVE
AI IS BECOMING THE CONNECTIVE TISSUE OF MODERN ENTERPRISE
ARCHITECTURE. IT INTERFACES WITH VIRTUALLY EVERY WORKLOAD, RIGHT
FROM COMPUTE AND CONTAINERS TO DATABASES AND ANALYTICS,
EXTENDING OUT TO EDGE DEVICES AND IOT. THIS INTEGRATION MEANS
THAT WE REALLY NEED SECURITY CONTROLS THAT WORK ACROSS THE
ENTIRE TECHNOLOGY STACK, RIGHT? IT'S IMPORTANT TO REMEMBER THE
FOCUS ISN'T JUST ON THE LLM, RIGHT? IT ISN'T JUST ON THE
CODING ASSISTANT. WE'RE BUILDING PLANETARY SCALE DISTRIBUTED
SYSTEMS, AND WE WANT SECURITY ARCHITECTURES THAT WORK END TO
END. AND GLOBALLY. RIGHT NOW, WHEN YOU IMPLEMENT SECURITY
THOUGHTFULLY FOR GENERATIVE AI, YOU RAISE THE SECURITY POSTURE
OF YOUR ENTIRE ORGANIZATION, RIGHT. BY TAKING A SECURE BY
DESIGN APPROACH, YOU'RE NOT JUST PROTECTING THE AI WORKLOAD, AS I
MENTIONED BEFORE, BUT YOU'RE REALLY STRENGTHENING SECURITY
ACROSS THAT ENTIRE DISTRIBUTED SYSTEM, RIGHT? NOW. THIS IS WHY
WE ADVOCATE FOR SOMETHING YOU MIGHT HAVE HEARD IN THE SECURITY
COMMUNITY BEFORE. DEFENSE IN DEPTH, RIGHT? SOMETHING THAT
EXTENDS ACROSS EVERY LAYER AND EVERY INTEGRATION POINT. SO YOU
HEARD YESTERDAY IN THE KEYNOTE, RIGHT? EVERYTHING STARTS WITH
SECURITY. AND SO IT'S NOT JUST ABOUT SECURING ONE APPLICATION
OR ONE WORKLOAD. IT'S REALLY ABOUT BUILDING THAT
COMPREHENSIVE SECURITY FOUNDATION THAT ENABLES
INNOVATION ACROSS THE ORGANIZATION. ALL RIGHT. SO
LET'S TALK ABOUT DEFENSE IN DEPTH FOR AI. RIGHT. YOU CAN
THINK OF IT IN SOME WAYS LIKE BUILDING A MEDIEVAL CASTLE
RIGHT. YOU DON'T JUST PUT UP WALLS AT THE PERIMETER AND CALL
IT A DAY. RIGHT. YOU WANT LAYERS OF APPROPRIATE PROTECTION GATES,
GUARDS, MOATS, EACH SERVING A DISTINCT PURPOSE. RIGHT. AND SO
NOW, WITH THAT MEDIEVAL CASTLE MENTAL MODEL IN PLACE, LET'S
DIVE A LITTLE BIT DEEPER IN HOW DEFENSE IN DEPTH CAN BE APPLIED
WITH CLOUD INFRASTRUCTURE AT THE BASE LAYER, YOU'RE GOING TO WANT
TO START THINKING ABOUT YOUR POLICIES AND PROCEDURES. AND HOW
DO YOU ONBOARD EMPLOYEES TO THIS NEW WAY OF THINKING, TRAINING
AND AWARENESS? RIGHT. WE WANT TO DEFINE THE SAFETY AND SECURITY
CAPABILITIES AND PRIORITIES FOR THE ORGANIZATION SO THAT WE'VE
GOT CLEAR DIRECTION. WE CAN UNDERSTAND HOW TO REASON THROUGH
AND THINK ABOUT THE CONTROLS THAT WE'RE GOING TO NEED, RIGHT.
THIS IS REALLY IMPORTANT BECAUSE GENERATIVE AI USE CASES OFTEN
ARE TRULY NOVEL. THEY'RE THINGS WE HAVEN'T CONSIDERED IN THE
PAST. AND SO YOU CAN'T JUST APPLY NECESSARILY THE PREVIOUS
POLICY OR PREVIOUS SECURITY CONTROL. RIGHT. AND SO NOW WE
HAVE THIS OPPORTUNITY RIGHT, TO CONSIDER INTERNAL AND EXTERNAL
USE CASES. RIGHT. HOW WE'RE GOING TO THINK ABOUT SENSITIVE
DATA IN THESE SYSTEMS. RIGHT. AND OTHER IMPORTANT DRIVERS THAT
YOUR BUSINESS MIGHT HAVE IN UPDATING YOUR POLICY,
MODERNIZING YOUR TRAINING AND CURRICULUM, AND BRINGING
AWARENESS AND FOCUS TO YOUR GENERATIVE AI STRATEGY AND HOW
SECURITY CAN DRIVE IT FORWARD FASTER. RIGHT. AND SO THE NEXT
LAYER WE TALK ABOUT IS IDENTITY AUTHORIZATION ACCESS. RIGHT. WE
WANT TO CONSIDER A VARIETY OF QUESTIONS HERE. RIGHT. SHOULD
EVERY API CALL HAVE A GUARDRAIL. RIGHT. WHICH AI MODELS CAN BE
APPLIED TO WHICH SPECIFIC APPLICATIONS AND WHICH ACCESS
RIGHTS. AND AS WE MOVE INTO THE AGENTIC SPACE, ARE WE THINKING
ABOUT AGENTS MORE AS EMPLOYEES OF THE ORGANIZATION OR MORE AS
SOPHISTICATED AUTOMATION? RIGHT. IT'S KIND OF EARLY DAYS, AND
WE'VE GOT TO REASON THROUGH THAT RIGHT NOW. I KNOW BECKY IS
COMING UP A LITTLE LATER, IS SUPER EXCITED ABOUT IDENTITY. SO
I'M NOT GOING TO SPEND A TON OF TIME HERE, BUT SHE'S GOING TO GO
INTO A COUPLE OF REALLY GREAT EXAMPLES ON HOW YOU IMPLEMENT
IDENTITY IN YOUR GENERATIVE AI STACK. SO WE'RE GOING TO MOVE UP
UP THE DEFENSE AND DEPTH STACK HERE AND ONTO INFRASTRUCTURE.
RIGHT. ON AWS YOU NEED TO BE THINKING ABOUT THAT
INFRASTRUCTURE PROTECTION AND STRATEGY. WITH WELL-ARCHITECTED.
YOU MAY HAVE SEEN WE HAVE SECURITY REFERENCE ARCHITECTURES
FOR GENERATIVE AI. RIGHT. AND SO ALL OF THOSE HELP YOU ESTABLISH
WHAT THAT INFRASTRUCTURE, WHAT THAT ARCHITECTURE STARTS TO LOOK
LIKE. AND THEN WE LAYER ON NETWORK AND EDGE PROTECTION.
RIGHT. SO WHAT TYPE OF WEB APPLICATION FIREWALL ARE YOU
GOING TO PUT IN A PERIMETER. RIGHT. DO YOU NEED PROXIES TO DO
ANY DATA HANDLING AND MANIPULATION. HOW ARE YOU
THINKING ABOUT RESOURCE MANAGEMENT. WHETHER IT'S TOKEN
EXHAUSTION OR DDOS ATTEMPTS ON YOUR APPLICATION. RIGHT. AND
WHAT OTHER TYPES OF NETWORK EDGE PROTECTION DO YOU WANT AS YOU
THINK ABOUT CONTENT DISTRIBUTION FROM THAT GENERATIVE AI WORKLOAD
OUT TO YOUR USER COMMUNITY? RIGHT. ALL OF THESE ARE GREAT
QUESTIONS TO CONSIDER AS YOU START THINKING ABOUT THE NETWORK
AND THE EDGE. NOW, IT'S NOT UNTIL YOU DO ALL THOSE THINGS
GET THAT FOUNDATION IN PLACE WHERE YOU START TO THINK ABOUT
HOW THE APPLICATION WILL HANDLE DATA, RIGHT, AND WHERE ARE WE
GOING TO APPLY THINGS LIKE GUARDRAILS? HOW ARE WE GOING TO
HANDLE SENSITIVE DATA, AND WHETHER WE'RE GOING TO CHOOSE TO
MAKE IT AVAILABLE FOR PROCESSING IN PLAIN TEXT OR FOR INSTANCE,
TOKENIZING OR ENCRYPTING IT? HOW DO WE THINK ABOUT SAFETY AND
APPROPRIATENESS AND HANDLING HALLUCINATIONS, IF THEY OCCUR AT
ALL, AND OTHER THINGS THAT MIGHT BE SPECIFIC TO THE AI MODEL THAT
YOU'VE CHOSEN, RIGHT, AND WHY? IT'S IMPORTANT TO NOT JUST
AGAIN, THINK ABOUT THE MODEL SECURITY, BUT THAT OVERALL END
TO END ARCHITECTURE AND THAT LOGICAL INFORMATION MODEL,
WHAT'S GOING TO BE PASSING IN AND OUT OF THE MODEL, AND HOW
SOME OF THOSE SUBSYSTEMS IN THE DISTRIBUTED SYSTEM WILL HANDLE
IT. RIGHT. THESE PROVIDE THAT SECURE FOUNDATION, THAT DEFENSE
IN DEPTH ARCHITECTURE THAT GIVES YOU THE CONFIDENCE, RIGHT, TO
LOAD CRITICAL DATA INTO THE SYSTEM. AND THEN THAT BRINGS US
TO OPERATIONS, WHICH INCLUDES THREAT DETECTION AND INCIDENT
RESPONSE. RIGHT. YOUR GUARD TOWER, IF YOU WILL, TO
CONTINUALLY MONITOR THE BEHAVIOR AND THE STATUS OF THE SYSTEM.
AND SO YOU MIGHT ASK QUESTIONS LIKE, NOW THAT YOU'VE BUILT OUT
YOUR APPLICATION, HOW ARE YOUR USERS USING THAT APPLICATION?
WHAT DOES THAT BASELINE OF ACTIVITY LOOK LIKE. AND WHEN DO
WE SEE ANOMALIES OR DEVIATIONS. ARE THEY MALICIOUS OR ARE THEY
JUST EXPERIMENTATION. RIGHT FROM A CUNNING AND EXCITED USER.
RIGHT. DO WE HAVE USERS TRYING TO DO THINGS LIKE PROMPT
INJECTION OR JAILBREAKS AND MALICIOUS ACTIVITY? AND IS THAT
YOUR PEN TESTING TEAM OR IS THAT AN UNWANTED PARTICIPANT IN YOUR
SYSTEM? RIGHT. AND IF YOU'RE BUILDING INTERNAL APPLICATIONS,
RIGHT, HOW ARE THEY USING THE APPLICATION AND WHAT SECURITY
METRICS HELP GET THEM THE BEST USER EXPERIENCE AND THE BEST
OUTCOME TO DRIVE INNOVATION WITHIN YOUR ORGANIZATION? RIGHT
NOW, THERE MAY BE CERTAIN AREAS OF CONTENT TYPES BASED ON YOUR
BRAND OR HOW YOU WANT TO INTERACT WITH YOUR USERS, YOUR
EMPLOYEES, YOUR CUSTOMERS. AND SO YOU MIGHT THINK ABOUT PUTTING
GUARDRAILS IN PLACE TO GIVE THE EXACT TYPE OF EXPERIENCE THE
VOICE OF YOUR TEAM OR THE VOICE OF YOUR ORGANIZATION AS YOU
WILL. RIGHT. AND SO, YOU KNOW, TO BE ABLE TO DO THAT, YOU'VE
GOT TO BE ABLE TO LOOK BOTH AT THE INPUT AND THE OUTPUT. YOU'RE
GOING TO BE EXAMINING, NOT JUST THE INFRASTRUCTURE LOGS LIKE
CLOUDTRAIL, FOR EXAMPLE, BUT YOU'RE ALSO GOING TO BE LOOKING
AT THE PROMPT LOGS, RIGHT? AND YOU'RE GOING TO BE LOOKING AT
HOW IS THAT CONVERSATION HAPPENING BETWEEN THE HUMAN AND
THE COMPUTER. RIGHT. AND THEN YOU'RE ALSO IN THERE DOING A
LITTLE BIT OF THREAT DETECTION, RIGHT. AND CORRECTIVE ACTIONS.
NOW LET'S BRING THESE DEFENSE AND DEPTH PRINCIPLES TO LIFE AND
SEE HOW ORGANIZATIONS ARE BUILDING SECURITY INTO EVERY
LAYER OF THEIR AI IMPLEMENTATION. WE HAVE THIS
REALLY COOL CUSTOMER TRELLIX RIGHT THERE, A SECURITY LEADER,
A CUSTOMER, AND A PARTNER OF AWS. AND THEY HAD A NUMBER OF
CUSTOMERS WHO WANTED TO ANALYZE THOUSANDS OF SECURITY ALERTS
DAILY. NOW THEY NEEDED A SOLUTION THAT CAN MAINTAIN THE
HIGHEST SECURITY STANDARDS WHILE DRAMATICALLY IMPROVING
OPERATIONAL EFFICIENCY FOR THEMSELVES AND FOR THEIR
CUSTOMERS. EXPERIENCE USING AMAZON, BEDROCK. AND THIS AWS
SECURITY FIRST FOUNDATIONAL MINDSET, THEY TRANSFORMED WHAT
USED TO BE THOUSANDS OF DAILY ALERTS INTO AUTOMATED ACTIONS
USING THEIR TRELLIX WISE PRODUCT AND AMBIENT AI AGENT. AND NOW
THEY DID THIS WHILE MAINTAINING RIGOROUS SECURITY CONTROLS AT
EVERY LAYER OF THAT DEFENSE AND DEPTH STACK. WHAT'S EVEN COOLER,
TO BE PERFECTLY HONEST, IS THAT THEY BUILT THIS IN JUST WEEKS.
THIS WASN'T LIKE A MULTI-PHASE MULTI-MONTH PROJECT, RIGHT? AND
THEY USED GENERATIVE AI TO WRITE MUCH OF THE CODE AND REPLACE
COMPLEX WORKFLOWS WITH SIMPLER IMPLEMENTATIONS AND OPERATIONS
AT EACH LAYER OF SECURITY, FROM THE INFRASTRUCTURE PROTECTION
ALL THE WAY THROUGH TO APPLICATION CONTROL. RIGHT. THEY
HAD THAT FOUNDATION IN PLACE, ALLOWING THEM TO REALLY JUST
FOCUS ON THE FEATURE SET THAT WAS GOING TO ALLOW THEIR
APPLICATION TO DO WHAT IT DOES BEST FOR THEIR CUSTOMERS, RIGHT.
AND ALERT MANAGEMENT. AND SO THIS IS EXACTLY WHAT WE MEAN
WHEN WE SAY THAT AWS REMOVES THE HEAVY LIFTING OF AI SECURITY,
THE UNDIFFERENTIATED HEAVY LIFTING, BY BUILDING ON OUR
SECURE FOUNDATION, TRELLIX WAS ABLE TO MAINTAIN THEIR HIGH
SECURITY STANDARDS WHILE INNOVATING AT SPEED FOR THEIR
CUSTOMERS. RIGHT? WEEKS, NOT MONTHS. AND THIS ISN'T JUST
ABOUT ONE PARTICULAR COMPANY DOING SOMETHING SUPER COOL WITH
AI TO IMPROVE THE SECURITY POSTURE OF THEIR CUSTOMERS AND
THEMSELVES. IT'S REALLY ABOUT THIS FUNDAMENTAL SHIFT IN HOW WE
THINK ABOUT AI AND SECURITY WORKING TOGETHER. RIGHT? AND SO
TO TACKLE GENERATIVE AI CHALLENGES, ORGANIZATIONS HAVE
THIS OPPORTUNITY TO FUNDAMENTALLY SHIFT THEIR
SECURITY MINDSET WHEN IT COMES TO THIS SPACE. RIGHT? IMAGINE
YOU'VE SPENT YEARS PERFECTING YOUR ORGANIZATION SECURITY,
RIGHT? YOU'VE GOT WELL UNDERSTOOD POLICIES. EVERYBODY'S
BEEN TRAINED. THE INFRASTRUCTURE IS IN PLACE. YOUR CONTROLS ARE
DOING WHAT THEY NEED TO. THE ALERTS ARE COMING IN. YOU'VE GOT
THAT SENSE AND RESPONSE GOING AND SECURITY OPERATIONS. AND NOW
ALL OF A SUDDEN YOU'RE ASKED TO INTEGRATE IN THIS NEW STACK OF
TECHNOLOGY, WHETHER IT'S A LANGUAGE MODEL OR WHETHER IT'S A
CODING ASSISTANT. RIGHT. AND SO NOW YOUR EXISTING SECURITY
INVESTMENTS ARE GOING TO HELP YOU, RIGHT? THERE ARE A FEW
ADDITIONAL THINGS. AS WE'VE BEEN TALKING ABOUT, YOU WANT TO TAKE
INTO CONSIDERATION AN AWS IS GOING TO HELP YOU THERE, RIGHT?
YOU'RE NOT ON YOUR OWN NOW. WE DON'T WANT TO THINK ABOUT THIS
AGAIN AS JUST ANOTHER COMPONENT IN THE SYSTEM. IT'S AN ENTITY
THAT CAN GENERATE, INTERPRET AND MANIPULATE INFORMATION IN WAYS
THAT TRADITIONAL SECURITY MODELS WEREN'T REALLY DESIGNED TO WORK
WITH. RIGHT. IT'S AKIN TO INTRODUCING SOMEBODY LIKE A NEW
EMPLOYEE OR AN INTERN WHO DOESN'T YET UNDERSTAND YOUR
POLICIES OR WAYS OF WORKING. RIGHT. AND THEY HAVE A POINT OF
VIEW ON HOW THEY WANT TO GET WORK DONE. AND NOW YOU'VE GOT TO
NEGOTIATE THAT YOU HAVE THE WAY YOU'VE BEEN USED TO DOING IT,
AND YOU HAVE THIS OPPORTUNITY TO LEARN RIGHT FROM A NEW
PERSPECTIVE AND A NEW EXPERIENCE, AND IN SOME WAYS
UPDATE THAT MENTAL MODEL AND RECRAFT THE RULES. RIGHT? AWS IS
NO EXCEPTION WHEN IT COMES TO LOOKING AT HOW WE WANT TO ADOPT
AND PROMULGATE THE USE OF GENERATIVE AI IN OUR
ORGANIZATION, RIGHT. AS YOU HEARD FROM AMY AND GEORGE
YESTERDAY, YOU KNOW, OUR TEAMS HAVE BEEN LEVERAGING THE SAME
INDUSTRY LEADING LMS THAT WE OFFER TO OUR CUSTOMERS THROUGH
BEDROCK, AND THAT OUR AWS SERVICES USE TO BUILD TOOLING
AND OFFER FEATURES, SOME OF WHICH WE'VE ANNOUNCED THIS WEEK
AT RE:INFORCE. RIGHT. AND THEY ALSO TALKED ABOUT ONE EXAMPLE
WHERE WE'RE NOW USING GENERATIVE SECURITY TESTS TO EXAMINE LARGE
PORTIONS OF THE AWS API. RIGHT. AND SO API LANDSCAPE. AND SO
LET'S TAKE A COUPLE OF MINUTES TO TALK ABOUT HOW AWS WAS ABLE
TO ENABLE OUR TEAMS VERY QUICKLY TO EMBRACE THIS NEW TECHNOLOGY
IN A SAFE, SECURE MANNER. RIGHT. ONE OF THE THINGS WE DID WAS WE
EARLY ON GOT A NUMBER OF DIFFERENT SECURITY STAKEHOLDERS
TOGETHER IN A ROOM WITH OUR BUILDERS, WITH OUR LEADERS, TO
DEEPLY UNDERSTAND THE KIND OF USE CASES THAT THEY THOUGHT
WOULD BE VALUABLE. AND FOR US TO REFLECT ON HOW CAN WE MATCH THAT
WITH INNOVATION AND SECURITY. AND AS WE BEGAN TO DO THAT
COLLABORATIVELY AND TOGETHER, WE HIT UPON THIS IDEA OF WHAT WE
CALL SECURE BUILD PATHS. RIGHT? IT'S THIS IDEA THAT FOR A SET OF
USE CASES, WE'VE GOT UPDATED POLICY AND GUIDANCE, WE'VE GOT
UPDATED TEMPLATES AND GUARDRAILS AND CONTROLS THAT IF TEAMS
FOLLOW, THEY CAN INNOVATE VERY QUICKLY IN A VERY, VERY SECURE
AND PERFORMANT MANNER. RIGHT. AND IT'S ALLOWED SOME OF THE
HISTORICAL MECHANISMS THAT WE USE, LIKE APPSEC AND OPERATIONAL
READINESS REVIEWS TO GO SO MUCH QUICKER. NOW, WHEN YOU'VE GOT A
GENERATIVE AI APPLICATION THAN WE MIGHT HAVE EVEN DONE WITH A
TRADITIONAL APPLICATION. IT'S SUPER EXCITING. AND SO EACH STEP
OF THAT SECURE BUILD PATHWAY SUPPORTS OUR TEAMS, RIGHT?
WHETHER WE'RE LOOKING AT USE CASE ASSESSMENT, MODEL
EVALUATION, ARCHITECTURAL DESIGN AND DEVELOPMENT ALL THE WAY
THROUGH TO DEPLOYMENT AND OPERATIONS. RIGHT. AND SO WE
WERE ABLE TO USE SECURITY AS AN ENABLER HERE TO REALLY HELP OUR
TEAMS ACROSS AWS BUILD QUICKLY AND BUILD SECURELY. AND WITH
THAT SECURITY FIRST MINDSET, WE ALSO NEEDED TO UNDERSTAND THE
PARADIGM SHIFT THAT WAS HAPPENING BETWEEN THAT
TRADITIONAL SECURITY WORKLOAD AND NOW THESE NEW GENERATIVE AI
SECURITY WORKLOADS. AND BECAUSE WE WORKED EARLY ON TO UNDERSTAND
EACH OTHER'S POINTS OF VIEW, RIGHT, AND LEVERAGE THE
FUNDAMENTAL WAYS WE WERE DOING SECURITY ALREADY, WE COULD JUST
FOCUS ON SOME OF THE DIFFERENCES AND SOME OF THE CHANGES AND
ENHANCEMENTS WE WANTED TO MAKE TO ENSURE THAT WE COULD BUILD
THESE SYSTEMS RIGHT, IN A WAY THAT IS COMFORTABLE FOR BOTH OUR
DEVELOPERS AND MEETS THE VERY HIGH SECURITY EXPECTATIONS OF
BOTH OUR INTERNAL AND OUR EXTERNAL CUSTOMERS. RIGHT. AND
THERE ARE THREE THINGS THAT WE KIND OF LEARNED THROUGH THAT
THAT PROCESS, THROUGH THAT ACTIVITY. AND I'D LIKE TO SHARE
WITH YOU THOSE RIGHT NOW. RIGHT. SO FIRST LET'S CONSIDER THE
OUTPUTS OF THE SYSTEM. NOW, WHILE TRADITIONAL APIS OPERATE
WITH PREDICTABLE FORMATS AND WELL DOCUMENTED I/O PATTERNS,
INPUT OUTPUT PATTERNS, GENERATIVE AI IS BASED ON
NATURAL LANGUAGE, RIGHT? WHICH MAKES IT VERY ACCESSIBLE. BUT IT
ALSO MEANS THAT USERS CAN PHRASE THEIR QUERIES IN COUNTLESS WAYS.
IT'S REALLY UNSTRUCTURED, WHICH ALSO RESULTS IN VARYING
RESPONSES DEPENDING ON THE QUESTION FORMAT AND THE CONTEXT
THAT YOU PROVIDE. ALONG WITH THAT NATURAL LANGUAGE PROMPT.
THE SECOND THING WE ENDED UP THINKING A LOT ABOUT WAS THAT
RESPONSES. WE'VE GOT DIFFERENT LEVELS OF PREDICTABILITY, RIGHT?
IN TRADITIONAL SYSTEMS. THEY GIVE US CONSISTENT DETERMINISTIC
RESPONSES FOR IDENTICAL QUERIES. RIGHT. YOU'RE GOING TO ALWAYS
GET THE SAME ANSWER UNLESS THE UNDERLYING DATA CHANGES. RIGHT.
BUT NOW WITH GENERATIVE AI, RESPONSES CAN VARY EVEN FOR THE
SAME QUESTION. AND SO THAT INTRODUCES SOME ADDITIONAL WAYS
OF THINKING ABOUT HOW DO WE WANT TO HANDLE THE OUTPUT. RIGHT.
FINALLY, THERE'S THE MATTER OF AUTHORIZATION AND DATA HANDLING.
RIGHT. TRADITIONAL SYSTEMS, AS I'M SURE MANY OF YOU ARE
FAMILIAR, USE ROLE BASED ACCESS OR ATTRIBUTE BASED ACCESS, RBAC
OR ABAC TO CONTROL THAT ACCESS TO THE DATA. WITH GENERATIVE AI
MODELS, THOUGH, IT'S A LITTLE BIT DIFFERENT BECAUSE YOU'RE
PROVIDING ACCESS TO THE MODEL ITSELF, NOT THE UNDERLYING DATA
THAT IT WAS TRAINED ON, REALLY. AND SO WHEN YOU'RE THINKING
ABOUT AUTHORIZATION, RIGHT, YOU'VE GOT TO CONSIDER THAT
THERE'S ALREADY A BUNCH OF DATA THAT'S IN THE SYSTEM, RIGHT, IN
THAT LLM THAT THE USER WILL NECESSARILY HAVE ACCESS TO. AND
SO NOW YOU'RE THINKING ABOUT THINGS LIKE HOW DO YOU HANDLE
MODEL CONTEXT PROTOCOL, HOW DO YOU HANDLE RAG RIGHT. THE INPUTS
AND OUTPUTS AND THE PROMPT AND THE USER. RIGHT. AND SO THESE
THREE DIFFERENCES REALLY PROVIDE A BIT OF THAT PARADIGM SHIFT
THAT YOU NEED TO THINK ABOUT AS YOU'RE BUILDING THE STRONG
DEFENSE IN DEPTH ARCHITECTURE FOR THOSE GENERATIVE AI
WORKLOADS. RIGHT. TO TACKLE THIS PARADIGM SHIFT AGAIN, BACK TO
THIS IDEA OF A TRUSTED FOUNDATION. YOU WANT TO START
BUILDING SECURITY IN FROM THE BEGINNING, RIGHT? AND THE AWS
NITRO SYSTEM IS PROBABLY THE BEST EXAMPLE OF AWS SECURITY
PHILOSOPHY IN ACTION, RIGHT? YOU DON'T GET MUCH MORE OF A
FOUNDATION THAN THE HARDWARE ITSELF. WITH NITRO, WE'VE BUILT
THAT SPECIALIZED HARDWARE THAT SITS OUTSIDE THE LINUX KERNEL,
FUNDAMENTALLY REDESIGNING HOW A HYPERVISOR OPERATES, RIGHT? IT
PROVIDES A LEVEL OF SECURITY THAT JUST ISN'T ACHIEVABLE WITH
TRADITIONAL SOFTWARE BASED HYPERVISORS. THIS INCLUDES A
VARIETY OF FEATURES THAT ENSURE HARDWARE BASED ISOLATION, SYSTEM
ATTESTATION, PASSIVE COMMUNICATION DESIGN AND NO
OPERATOR OR SSH ACCESS. AND ALL OF THIS IS BUILT TO PROVIDE THE
RIGHT LEVEL OF SECURITY, RIGHT FROM THE HARDWARE, ALL THE WAY
UP INTO THE APPLICATION STACK. RIGHT? WHICH IS PRETTY EXCITING.
THE BEAUTY OF THIS SYSTEM IS THAT IT PROVIDES THE
UNDERPINNING FOR INNOVATION. WHEN YOU KNOW YOU HAVE THAT
SECURE FOUNDATION, YOU CAN FOCUS ON PUSHING THE BOUNDARIES OF
WHATEVER YOUR BUSINESS HAS TO DO WITH GENERATIVE AI. AND AS WE
LOOK TO THE FUTURE OF AI, WHETHER THAT'S MORE
SOPHISTICATED LANGUAGE MODELS, AGENTIC, OR TECHNOLOGIES WE
HAVEN'T EVEN IMAGINED TODAY, THE SECURITY FIRST ARCHITECTURE
MEANS WE'RE READY FOR WHATEVER COMES NEXT. NOW, BUILDING ON TOP
OF NITRO, IT'S ALSO ABOUT HOW AWS HOSTS THE MODELS FOR OUR
CUSTOMERS WITH OUR MANAGED SERVICES. RIGHT? SO JUST LIKE WE
WANT TO HAVE STRONG FOUNDATION, STRONG POLICY AND PROCEDURE, WE
ALSO WANT TO UNDERSTAND HOW THOSE MODELS ARE BEING SELECTED
AND HOW THEY'RE BEING PROTECTED AS WE HOST THEM FOR OUR SERVICES
LIKE AMAZON BEDROCK. RIGHT NOW, AMAZON BEDROCK HOSTS A BROAD
SELECTION OF FULLY MANAGED MODELS, INCLUDING AMAZON, TITAN
AND NOVA MODELS. ANTHROPIC'S CLAUDE, META'S LLAMA, AND A
NUMBER OF OTHER FIRST JUST FANTASTIC MODELS, AS WELL AS THE
AMAZON BEDROCK MARKETPLACE, WHICH GIVES ACCESS TO MORE THAN
100 ADDITIONAL SPECIALIZED MODELS. SO WHAT GOES IN TO THE
APPROVAL PROCESS FOR A NEW MODEL ON BEDROCK? I'M GLAD YOU ASKED.
I'LL BE HAPPY TO TELL YOU. SO IT STARTS WITH AWS HAVING A STRICT
SET OF REQUIREMENTS FOR THE FORMAT OF THE SOFTWARE PACKAGE
FOR THE MODEL, AND THEN MODELS ARE HOSTED IN DEDICATED SERVICE
ACCOUNTS WITH NO EXTERNAL INTERNET ACCESS. WE IMPLEMENT
STRONG LOGGING FOR ALL MODELS TO VALIDATE WHAT IT'S DOING, BE
ABLE TO OPERATE IT EFFICIENTLY AND EFFECTIVELY. WE IMPLEMENT
STANDARD INPUT VALIDATION TO PREVENT SCRIPTS FROM BEING
TRANSLATED IN THE PARSER AND RUNNING ARBITRARY CODE, AND WE
HAVE IAM ROLES TO PREVENT UNAUTHORIZED ACCESS. NOW, ACROSS
ALL OF THIS, WE MAKE SURE THAT WE PUT SECURITY FIRST, AND WE
HAVE THE RIGHT SECURITY MINDSET IN PLAY. EACH LAYER OF THE STACK
TO PROVIDE THE CAPABILITIES THAT CUSTOMERS AND CUSTOMERS HAVE
ASKED FOR WITH MODEL HOSTING. NOW, WITH THAT SECURITY SPECIFIC
MINDSET IN MIND, RIGHT MODEL ONBOARDING EXTENDS TO INDUSTRY
SPECIFIC REQUIREMENTS. THAT'S WHY LAST WEEK WE WERE THRILLED
TO ANNOUNCE THAT AWS IS THE FIRST CLOUD PROVIDER TO ACHIEVE
FEDRAMP HIGH AND DEPARTMENT OF DEFENSE CLOUD COMPUTING SECURITY
REQUIREMENTS GUIDE IMPACT LEVEL FOUR AND FIVE AUTHORIZATION FOR
ANTHROPIC'S CLAUDE AND META LLAMA 2 FOUNDATIONAL MODELS IN
THE AWS GOVCLOUD REGIONS. THIS MILESTONE WILL TRANSFORM HOW OUR
US GOVERNMENT CUSTOMERS HARNESS THE POWER OF ARTIFICIAL
INTELLIGENCE FOR THEIR WORKLOADS. NOW, BEYOND THAT
MODEL, HOSTING AND ITS INHERENT SECURITY ORGANIZATIONS NEED TO
THINK ABOUT COMPREHENSIVE SAFEGUARDS FOR THEIR AI
APPLICATIONS, RIGHT? AWS PROVIDES THREE KEY CAPABILITIES
TO MAKE RESPONSIBLE DEPLOYMENT SAFE AND EASY, RIGHT? FIRST,
AMAZON BEDROCK GUARDRAILS IS A FANTASTIC CAPABILITY THAT ALLOWS
YOU TO EVALUATE PROMPTS AND MODEL RESPONSES. REMEMBER THAT
INPUT AND OUTPUT FROM EARLIER RIGHT TO LOOK AT UNDESIRABLE
CONTENT HELP YOU IDENTIFY AND GAIN FACTUAL CLAIMS, AND HELP
DEFINE TOPICS THAT MAYBE YOU WANT TO LIMIT. RIGHT OUR USER
ACCESS TO HELP REMOVE DATA TYPES THAT YOU DON'T WANT BEING
EMITTED, PERHAPS LIKE PERSONALLY IDENTIFIABLE INFORMATION. THEN
THERE'S VALIDATION AND A REALLY IMPORTANT SET OF CAPABILITIES.
HOW DO YOU THINK ABOUT PREVENTING MALICIOUS ACTORS FROM
DOING CROSS-SITE SCRIPTING OR SQL STYLE INJECTION ATTACKS? AWS
HAS CAPABILITIES AND SERVICES LIKE OUR WEB APPLICATION
FIREWALL, THAT ARE GOING TO SUPPORT THE PREVENTION OF THESE
TYPES OF ATTACKS, AND THEN WE HAVE AUTOMATED REASONING CHECKS.
ONE OF MY FAVORITE SET OF CAPABILITIES, TO BE PERFECTLY
HONEST, USING AUTOMATED REASONING CHECKS, WE CAN VERIFY
COMPLIANCE AGAINST FACTUAL CLAIMS USING LOGIC BASED
ALGORITHMS AND MATHEMATICAL VALIDATION. AMAZON BEDROCK
AUTOMATED REASONING VALIDATES THE LLM OUTPUTS AGAINST DOMAIN
KNOWLEDGE ENCODED IN POLICIES TO HELP PREVENT FACTUAL
INACCURACIES. YOU CAN THINK ABOUT AUTOMATED REASONING LIKE
YOUR AI APPLICATIONS. SECURITY MATHEMATICIAN. IT'S CONSTANTLY
WORKING TO PROVE THAT YOUR APPLICATION AND CONTROLS ARE
WORKING AS INTENDED AND EXPECTED. NOW, WHILE FILTERS AND
OTHER CHECKS WORK AT THE SYNTACTIC LEVEL, AUTOMATED
REASONING CHECKS WORK AT THE LOGICAL LEVEL BY VALIDATING
RESPONSES AGAINST FORMALIZED POLICY RULES. WHAT THAT MEANS IS
IT PROVIDES A MORE ROBUST FORM OF DEFENSE IN DEPTH FOR THE
ENTIRE SYSTEM. NOW, THIS THREE LAYERED APPROACH TO APPLICATION
SAFEGUARDS GIVES YOU GREATER CONFIDENCE TO INNOVATE WHILE
MAINTAINING STRICT SECURITY CONTROLS. LET'S TAKE A MINUTE TO
DIG IN A LITTLE MORE DEEPLY AND BRING THIS CONCEPT OF AUTOMATED
REASONING TO LIFE WITH A REAL WORLD EXAMPLE FROM ONE OF OUR
PARTNERS, PWC. NOW THEY'RE USING AMAZON BEDROCK AUTOMATED
REASONING CHECKS TO REVOLUTIONIZE WORKLOADS ACROSS A
NUMBER OF INDUSTRIES. TODAY, THOUGH, WHAT I'D REALLY LIKE TO
FOCUS ON IS HOW THEY'RE APPLYING IT TO PHARMACEUTICAL CONTENT
DEVELOPMENT. PWC HAS INTEGRATED AUTOMATED REASONING CHECKS FOR
MATHEMATICAL VERIFICATION OF CLAIMS, TACTICS AND REVIEW
PROCESSES, AND THEY'RE ABLE TO GENERATE POLICIES FOR MEDICAL,
LEGAL AND REGULATORY REVIEWS DIRECTLY FROM APPROVED LABELS
AND CREATE GUIDELINES BASED ON REGULATORY DOCUMENTS LIKE FDA
WARNING LETTERS. THEY'RE THEN ABLE TO TAKE THAT SYSTEM AND RUN
SECONDARY CHECKS ON AI PRODUCED CONTENT, MATHEMATICALLY
VERIFYING ITS COMPLIANCE AND VERACITY. BEDROCK AUTOMATED
REASONING ALSO VALIDATES NEW CLAIMS AGAINST AN APPROVED
CLAIMS LIBRARY, AND APPLIES A CHAIN OF VERIFICATION WORKLOAD
TO ENSURE THAT EACH CLAIM MEETS REGULATORY STANDARDS, SO THIS
ACTS AS A SECOND LINE OF DEFENSE TO SORT OF EVALUATE THE
EVALUATORS OR CHECK THE CHECKER KIND OF ACTIVITY. AND IT'S ALL
DONE AUTOMATICALLY WITHOUT THE NEED FOR A HUMAN IN THAT LOOP.
AND SO AUTOMATED REASONING IS STILL IN PREVIEW, BUT PWC IS
ALREADY SEEING THE DRAMATIC ACCELERATION IN THEIR CONTENT TO
MARKET TIMELINES WHILE VALIDATING REGULATORY
COMPLIANCE. IT'S SUPER COOL. AND SO IT USED TO TAKE MONTHS CAN
NOW BE DONE IN A MATTER OF WEEKS. THIS LEVEL OF ASSURANCE
IS GAME CHANGING. IT ALLOWS ORGANIZATIONS TO CONFIDENTLY
DEPLOY INNOVATIVE AI IN HIGHLY REGULATED ENVIRONMENTS,
ACCELERATING TIME TO MARKET WHILE REDUCING RISK. AND THIS IS
REALLY THE FUTURE OF AI SECURITY, RIGHT? IT'S WHERE
MATHEMATICAL CERTAINTY MEETS BUSINESS INNOVATION. AND IT'S
AVAILABLE IN PREVIEW TODAY ON AWS. SO NOW THAT WE'VE LAID OUT
THE GROUNDWORK, LET'S DO THAT DEEP DIVE INTO HOW WE IMPLEMENT
SOME OF THIS DEFENSE IN DEPTH ARCHITECTURE. I'D LIKE TO INVITE
MY COLLEAGUE BECKY TO DIVE DEEPER INTO HOW WE TRANSLATE
THESE CONCEPTS INTO ACTION. AND AS SHE COMES ON STAGE, YOU MIGHT
ASK THE QUESTION, DID WE USE AMAZON NOVA TO CHOOSE OUR
OUTFITS TODAY? AND I WILL LET YOU KNOW. THIS LOOK WAS LOVINGLY
HANDCRAFTED BY TWO FRIENDS IN HUMANS.
>> YEAH. SO IF YOU THOUGHT YOU WERE DONE STARING AT THESE
OVERALLS, I GOT NEWS FOR YOU. THANK YOU SO MUCH. HEART. SO IS
HEART EMPHASIZED THE FOUNDATION OF ANY SECURE AI IMPLEMENTATION
STARTS WITH THE RIGHT POLICIES, PROCEDURES, AND AWARENESS. THE
BEDROCK, IF YOU WILL, THAT'S REQUIRED TO BUILD ANYTHING WITH
GENERATIVE AI. YEAH, SORRY FOR THAT. SO THIS ISN'T JUST ABOUT
TECHNICAL CONTROLS IS THE POINT. IT'S ABOUT CREATING A CULTURE OF
SECURITY THAT PERMEATES EACH AND EVERY ASPECT OF YOUR AI
DEVELOPMENT AND DEPLOYMENT. SO POLICIES, PROCEDURES AND
AWARENESS POLICIES, THESE ARE YOUR GUIDING PRINCIPLES. IT'S
THEY DEFINE WHAT YOU'RE EVEN TRYING TO ACHIEVE WITH AI IN
YOUR ORGANIZATION, AND THEN SET THE BOUNDARIES FOR HOW YOU'RE
GOING TO ACHIEVE THAT SECURELY. PROCEDURES. THESE ARE WHAT YOU
THINK OF AS PLAYBOOKS. THEY OUTLINE STEP TWO STEP BY STEP
PROCESSES FOR IMPLEMENTING AI SECURELY FROM DATA, DATA
HANDLING AND ACCESS TO MODEL DEPLOYMENT. AND THEN FINALLY
AWARENESS. IT'S ABOUT EDUCATION AND CULTURE. IT ENSURES EVERYONE
IN YOUR ORGANIZATION UNDERSTANDS THE UNIQUE SECURITY CHALLENGES
OF AI AND EACH OF THEIR RESPECTIVE ROLES IN ADDRESSING
THEM. SO WE'RE GOING TO LOOK AT HOW YOU CAN PUT THESE TOGETHER
IN PRACTICE, BECAUSE I'M ACTUALLY GOING TO TALK ABOUT
AMAZON, MY EMPLOYER. WE'RE GOING TO TALK ABOUT HOW WE AT AMAZON
APPROACHED THE IMPLEMENTATION OF GENERATIVE AI IN OUR OWN
ORGANIZATION BECAUSE LIKE ALL OF YOU, WE STAND TO REAP THE
BENEFITS AS WELL. AND THERE'S NO BETTER EXAMPLE THAN OUR JOURNEY
WITH Q BUSINESS. OKAY. SO INTERNAL INTERNALLY, AWS AND
AMAZON INTRODUCED A FEW DIFFERENT GENERATIVE AI
APPLICATIONS BUILT ON AMAZON Q FOR BUSINESS WITH A SECURITY
FIRST IMPLEMENTATION. THESE APPLICATIONS, THEIR INTERNAL
GENERATIVE AI APPLICATIONS MEANT TO ENHANCE THE PRODUCTIVITY OF
OUR EMPLOYEES, DOING ALL THE DIFFERENT JOBS THAT THEY DO. AND
OUR GOAL HERE WAS TO ENHANCE EMPLOYEE PRODUCTIVITY WHILE
PROTECTING OUR HIGHLY CONFIDENTIAL DATA. SO WE WANTED
EMPLOYEES TO BE ABLE TO SUMMARIZE DOCUMENTS AND ASK
THEIR QUESTIONS ABOUT A VARIETY OF TOPICS. AND THEREFORE, YOU
KNOW, THE ONLY WAY YOU'RE GOING TO DO THAT IS EFFECTIVELY IS TO
INTEGRATE IT WITH YOUR INTERNAL DATA SOURCES. SO WE NEEDED TO
INTEGRATE Q BUSINESS WITH THOSE RESPECTIVE INTERNAL DATA
SOURCES. AND ON AWARENESS WE LAUNCHED COMPREHENSIVE EMPLOYEE
TRAINING PROGRAMS, PROVIDED CLEAR DOCUMENTATION, AND ALSO
IMPORTANTLY CREATED FEEDBACK LOOPS FOR CONTINUOUS
IMPROVEMENTS. NOW, THE ENABLEMENT OF AMAZON Q BUSINESS
FOR INTERNAL USE CASES HAS BEEN A JOINT COLLABORATION BETWEEN
AMAZON AND AWS. AND LET'S TALK ABOUT WHAT WE'VE BUILT. I'M
GOING TO GIVE YOU A FEW EXAMPLES OF WHAT WE BUILT AND ACTIVELY
USE ACROSS BOTH ORGANIZATIONS. AND I'M ACTUALLY GOING TO
BECAUSE WE HAVE A SECURITY BUILDER CROWD HERE. RE:INFORCE.
THESE EXAMPLES ARE DRAWN FROM GENERATIVE AI APPLICATIONS THAT
WE'VE BUILT TO ENHANCE THE PRODUCTIVITY OF OUR OWN SECURITY
BUILDERS. AND AT AMAZON. SO WE HAVE THE AMAZON. SO THESE ARE
INTERNAL APPLICATIONS. WE HAVE THE AMAZON SECURITY OPERATIONS
TRIAGE ASSISTANT. SO THAT IMPROVES THE EFFICIENCY OF THE
SECURITY RESPONSE PROCESS. IT HELPS DATA DRIVEN DECISION
MAKING. AND IT IT IT ASSISTS IN CONTINUOUS IMPROVEMENT OF OUR
DETECTIONS. ANOTHER EXAMPLE IS THE AMAZON SECURITY COMPANION.
SO THAT'S AN ENHANCED SEARCH FUNCTIONALITY AND STREAMLINED
APPROACH TO SUMMARIZING THE MOST PERTINENT INFORMATION FROM THE
RETRIEVED SEARCH RESULTS, SO THAT THAT EQUIPS BUILDERS WITH A
HEAD START IN ADDRESSING QUERIES AND MINIMIZES TIME SPENT ON, YOU
KNOW, THE KIND OF RESEARCH THAT YOU HAVE TO DO TO GET STARTED ON
ANY ON ANY SECURITY ISSUE. AND THEN FINALLY, THE CCNA GURU. SO
THAT ANALYZES CVS AND PROVIDES THINGS LIKE CSS SCORING AND
METADATA AND EXPLANATIONS FOR SECURITY ENGINEERS TO EVALUATE.
SO THESE ARE JUST SOME APPLICATIONS THAT WE DEEMED
USEFUL FOR OUR OWN SECURITY STAFF THAT WE WANTED TO DEPLOY
TO HELP THEM BE EFFECTIVE. SO HOW DO WE MAKE THAT HAPPEN. SO
AGAIN, I'LL REITERATE THAT WE'RE TALKING ABOUT DATA THAT WE'VE
CLASSIFIED AS HIGHLY CONFIDENTIAL, WHICH MEANS THAT
THE BAR FOR PROTECTING THAT DATA THAT WE NEEDED TO MEET WAS QUITE
HIGH. SO FIRST UP IN OUR CONSIDERATIONS IS THE FACT THAT
ALL OF THESE APPLICATIONS ARE BUILT ON AMAZON Q. NOW, AMAZON Q
IS AN AWS SERVICE, AND THAT SERVES AS AN IMPORTANT SECURITY
TAILWIND BECAUSE LIKE EVERY OTHER AWS SERVICE AND AMAZON Q
IS NO EXCEPTION, EVERY AWS SERVICE GOES THROUGH EXTENSIVE
SECURITY REVIEWS. IT HAS TO MEET OUR SECURITY BAR FOR AWS. SO OUR
APPLICATION SECURITY APPSEC PROCESS IS A DEEP ENGAGEMENT, A
DEEP AND ONGOING ENGAGEMENT WITH SECURITY ENGINEERS WHERE WE WALK
THROUGH EVERY ASPECT OF THE APPLICATION ARCHITECTURE AND
LOOK SPECIFICALLY FOR THE KINDS OF THINGS THAT CAN GO WRONG WHEN
A CUSTOMER, WHICH WOULD BE AN INTERNAL, YOU KNOW, AN EMPLOYEE
OF AMAZON, USES THE APPLICATION BY BUILDING A TOP Q, AN AWS
SERVICE. THE AWS SECURITY FOUNDATION IS BUILT RIGHT IN. SO
YOU ALREADY HAVE THAT GOING FOR YOU. SO THAT'S THE FOUNDATION.
BUT OF COURSE, AS YOU KNOW, THERE'S A WHOLE APPLICATION
BEING BUILT ON TOP OF THE FOUNDATION. AND THERE ARE
CONSIDERATIONS THAT ARE THAT EXIST WITHIN THE APPLICATION
ITSELF. SO WE HAD TO THINK ABOUT USE CASES. WHAT ARE OUR GREAT
EMPLOYEES OF AMAZON GOING TO DO IN THESE APPLICATIONS FOR AN
EXAMPLE, LIKE ONE DESIRED USE CASE WAS AN INTERNAL CHATBOT
THAT EMPLOYEES COULD USE TO ANSWER QUESTIONS OR WRITE
DOCUMENTS. AND AGAIN, POTENTIALLY USING OUR HIGHLY
CONFIDENTIAL DATA. AND WE WANTED THIS CHATBOT TO BE ABLE TO
SUMMARIZE DOCUMENTS, ANSWER QUESTIONS ABOUT SPECIFIC AWS OR
AMAZON POLICIES AND TOPICS WITHOUT CONCERN OF LEAKING
SENSITIVE DATA. SO THAT'S WHAT WE DID WANT. AND THEN THERE'S A
BUNCH OF THINGS WE DIDN'T WANT, RIGHT. SO ONE THING THAT THESE
APPLICATIONS WERE NOT GOING TO BE PLUGGED INTO USER SPECIFIC
INFORMATION, YOU KNOW, BECAUSE OF THE NATURE OF WHAT THEY DID,
YOU CERTAINLY DON'T WANT THE USERS OF IT ASKING QUESTIONS,
ASKING USER SPECIFIC TOPICS BECAUSE IT DOESN'T HAVE THE
INFORMATION THAT IT WOULD NEED TO PROVIDE ANY ACCURATE OR
USEFUL ANSWERS THERE. SO WE DIDN'T WANT OUR APPLICATIONS
TRYING TO ANSWER THOSE QUESTIONS THAT IT COULDN'T. SO WE PUT
TOPIC GUARDRAILS IN PLACE TO BLOCK THOSE KINDS OF QUESTIONS
TO, YOU KNOW, TO PREVENT SIMPLE MISINFORMATION. SAME GOES, OF
COURSE, FOR CONTROVERSIAL TOPICS. SO THAT WAS ALSO
SOMETHING TO CONSIDER. SO WE IMPLEMENTED GUARDRAILS ACROSS
DIFFERENT CONTROVERSIAL TOPIC AREAS THAT JUST PREVENT USERS
ABOUT TO ASKING QUESTIONS ABOUT THOSE THINGS TO. AND THE LIST
GOES ON. AND THAT'S WHERE POLICIES, PROCEDURES AND
AWARENESS BECAME IMPORTANT. EVEN FOR THESE INTERNAL USE CASES.
AND WE TALKED ABOUT ESTABLISHED POLICIES BEFORE. AND THEY
INCLUDE OF COURSE, DATA AND ACCESS CONTROLS. SO WE'RE USING
INTERNAL DATA SOURCES HERE. AND OF COURSE IN, YOU KNOW, IN A
LARGE COMPANY LIKE OURS OR EVEN A MEDIUM OR EVEN A SMALLER
COMPANY, NOT EVERYBODY HAS ACCESS TO EVERYTHING. SO WE NEED
TO MAKE SURE THAT EACH USER OF THE APPLICATION IS ABLE TO
INTERACT WITH AND ACCESS DATA ONLY THAT DATA TO WHICH HE OR
SHE IS, IS, IS ORIGINALLY AUTHORIZED. NOW, AS YOU MIGHT
IMAGINE, BUILDING AND DEPLOYING THESE APPLICATIONS ALSO REQUIRED
SOME ITERATION OVER TIME AND A COMMITMENT TO ITERATION AND
FEEDBACK. AND ONE GREAT WAY TO GET FEEDBACK EARLY IS, OF
COURSE, A BETA PROGRAM. SO WE DID THAT INTERNALLY. AND BECAUSE
YOU NEVER KNOW EXACTLY HOW PEOPLE ARE GOING TO USE YOUR
APPLICATIONS, WHAT TYPES OF QUESTIONS THAT THEY'LL ASK, OR
ANY OTHER CONSIDERATIONS THAT YOU JUST MAY NOT HAVE OCCURRED
TO YOU DURING THE DESIGN AND PLANNING PHASE. SO IN BOTH THE
INTERNAL INTERNAL BETA PROGRAM AS WELL AS ON AN ONGOING BASIS,
WE MONITORED THE APPLICATION. SO THAT WAS ANOTHER KEY COMPONENT.
WE WATCHED WHAT TYPES OF QUESTIONS WERE COMING IN, WHAT
TYPES OF RESPONSES WERE GOING OUT. AND WE ACTIVELY SOLICITED
FEEDBACK OF COURSE, FROM THE USERS. SO ONE OF OUR EARLY BETA
AUDIENCES HERE WAS OUR SECURITY BUILDERS. AND WHAT DO YOU THINK
HAPPENS WHEN YOU GIVE SECURITY BUILDERS EARLY ACCESS TO SOME
KIND OF GENERATIVE AI APPLICATION? THEY TRY INPUT
VALIDATION. LET'S SAY THEY TRIED A BUNCH OF INPUT VALIDATION TYPE
CASES, INCLUDING CROSS-SITE SCRIPTING AND THINGS LIKE THAT.
SO WE MADE SURE THAT THE SECURITY CONTROLS AND GUARDRAILS
INCLUDED THESE TYPES OF THESE TYPES OF CONCERNS. SO MONITORING
AND ACTIVELY SOLICITING USER FEEDBACK. OF COURSE, THAT'S NOT
A NEW BEST PRACTICE FOR GENERATIVE AI. ANY INTERNAL
BUSINESS, ANY USER FACING PRODUCT BENEFITS FROM THESE
KINDS OF PRACTICES, BUT THEY'RE ALL THE MORE IMPORTANT WHEN
WE'RE TALKING ABOUT SOMETHING SO INNOVATIVE, SO NEW IN THE WORLD,
JUST REALLY LEARNING ABOUT HOW WHAT YOUR USERS ARE GOING TO
EXPECT FROM FROM THESE NEW APPLICATIONS. SO THAT'S HOW
POLICIES, PROCEDURES AND AWARENESS CAME INTO PLAY WITH
THESE APPLICATIONS. BUT I'M GOING TO TAKE YOU ONE STEP
DEEPER INTO THE DEFENSE IN DEPTH STRATEGY THAT MADE OUR ADOPTION
OF AMAZON Q BUSINESS APPLICATION SUCCESSFUL. I'M GOING TO FOCUS
ON ONE OF MY FAVORITE TOPICS IN AWS, BECAUSE IT'S WHAT I WORK
ON. LET'S TALK ABOUT IDENTITY. ALL RIGHT. ANY MODERN BUSINESS
APPLICATION. THIS ISN'T A GENERATIVE AI THING. ANY MODERN
BUSINESS APPLICATION ALREADY AUTHENTICATES ITS USERS AND
USUALLY HAS SOME NOTION OF AUTHORIZATION. THIS USER CAN DO
THIS, AND THAT USER CAN DO THAT IN AN AI APPLICATION SUCH AS
SUCH AS THE ONE WE'VE BEEN DISCUSSING, THE AUTHENTICATED
USER IDENTITY WILL AFFECT WHAT EACH USER CAN DO AND WHAT DATA
HE OR SHE CAN ACCESS, AND MAYBE ALSO HOW THE SYSTEM EXACTLY IS
GOING TO INTERACT WITH HIM OR HER. SO IF YOU FOLLOW A LOT OF
THE CHATTER AROUND AGENTIC I, YOU MIGHT HAVE HEARD THAT THERE
ARE ACTUALLY TWO IDENTITIES IN THE MIX IN A TYPICAL GENERATIVE
AI APPLICATION. SO THERE'S THE ONE YOU'RE PROBABLY THINKING OF.
THAT'S THE HUMAN IDENTITY. THAT'S THE AUTHENTICATED USER
WHO IS USING THIS APPLICATION RIGHT NOW. BUT THEN THERE'S ALSO
AN APPLICATION OR MACHINE IDENTITY, A NON-HUMAN IDENTITY.
AND EACH OF THESE ACTUALLY MATTERS. SO THERE'S HUMAN
IDENTITY. SO AS THE CATERPILLAR IN ALICE IN WONDERLAND WOULD
SAY, WHO ARE YOU? AS WE SECURITY BUILDERS MIGHT ASK, ARE THERE
ANY ROLE BASED PERMISSIONS OR ACCESS LEVELS ASSOCIATED WITH
WHO YOU VERIFIABLY ARE? AND THESE WILL USUALLY VARY FROM
USER TO USER, RIGHT? WE DON'T ALL HAVE THE SAME JOB AT AMAZON.
THERE'S LOTS OF DIFFERENT JOBS FOR PEOPLE AT AMAZON. AN
EMPLOYEE IN YOUR FINANCE ORGANIZATION IS GOING TO HAVE
ACCESS TO DIFFERENT DATA AND ASK DIFFERENT KINDS OF QUESTIONS
THAN AN EMPLOYEE IN THE SALES ORGANIZATION. BUT THEN SO THAT'S
THAT'S HUMAN IDENTITY AND THE AUTHORIZATIONS TO THE HUMAN. BUT
THERE'S ANOTHER PLANE HERE, WHICH IS THE IDENTITY OF THE
APPLICATION THAT IDENTITY PROVIDES THE CONTEXT AROUND WHAT
THE USER IS TRYING TO DO, AND MAY, IN FACT, AFFECT WHAT DATA
YOU SURFACE TO THAT USER. SO IF YOU'RE THINKING THAT THESE SAME
IDENTITIES, HUMAN IDENTITY AND APPLICATION OR NON-HUMAN OR
MACHINE IDENTITY WERE ALREADY THERE IN TRADITIONAL WORKLOADS,
YOU'RE ABSOLUTELY RIGHT. THIS ISN'T ACTUALLY THAT NEW.
SURFACING THE RIGHT DATA TO THE RIGHT USER, IN THE RIGHT CONTEXT
HAS ALWAYS BEEN AN IMPORTANT GOAL. SO WHAT IS NEW FOR
GENERATIVE AI HERE? WELL, THERE ARE A FEW NEW THINGS, RIGHT? IT
MIGHT, FOR EXAMPLE, AFFECT THE TYPES OF SECURITY GUARDRAILS AND
MODEL CONTROLS THAT NEED TO BE IN PLACE. RIGHT. BECAUSE THESE
ARE NEW CONCEPTS HERE. SO IT'S A NEW KIND OF QUESTION TO CONSIDER
FROM YOUR ORGANIZATIONAL PERSPECTIVE. SO WE HAVE SOME
PARTS WE CAN THINK OF AS TRADITIONAL SECURITY
CONSIDERATIONS FOR INTERNAL BUSINESS APPLICATIONS THAT YOU
MAY HAVE, YOU KNOW, ALREADY BUILT UP PRACTICE AND EXPERTISE
AROUND THINKING ABOUT AND THEN AND THEN SOME OTHER PARTS THAT
ARE NEW FOR GENERATIVE AI. LET'S TALK ABOUT HOW THAT WORKS IN
PRACTICE. SO I'M GOING TO SHOW YOU HERE KIND OF THE
CONVERSATION BEFORE THE CONVERSATION AS A USER STEPS UP
TO, YOU KNOW, MAYBE SOME KIND OF GENERATIVE AI APPLICATION. THIS
IS THESE ARE THE THINGS THAT GET FIGURED OUT BEFORE THE
APPLICATION STARTS. SO A USER NAVIGATES TO THE GENERATIVE AI
APPLICATION, PERHAPS, YOU KNOW, MAYBE IN A WEB BROWSER OR
SOMETHING LIKE THAT AND SAY THAT THEY HAVE YET TO AUTHENTICATE.
SO THE APPLICATION SEES THERE'S NO AUTHENTICATION SESSION HERE
YET. SO THE USER NEEDS TO BE AUTHENTICATED. SO A TYPICAL
APPLICATION WILL REDIRECT THE USER TO YOUR ORGANIZATION'S
IDENTITY PROVIDER. THIS IS A PATTERN CALLED SINGLE SIGN ON
SSO. AND WHAT WILL TYPICALLY RESULT FROM THAT INTERACTION IS
AN IDENTITY TOKEN IS ISSUED BY THE IDENTITY PROVIDER. AND THEN
THE USER IS REDIRECTED BACK TO THE APPLICATION. AND THE
APPLICATION NOW HAS NOT ONLY HAVE THE USER'S IDENTITY IN A
VERIFIABLE TOKEN, YOU KNOW, IT SAYS THIS IS BECKY, BUT CAN
ALSO, WITH THE HELP OF THE IDENTITY PROVIDER, FIND OUT
OTHER ATTRIBUTES OR CLAIMS OF THE AUTHENTICATED SESSION. FOR
EXAMPLE, THAT MIGHT. BE RELEVANT. SO THEIR ROLE, THEIR
DEPARTMENT, MAYBE MANY, POSSIBLY MANY DIFFERENT GROUP MEMBERSHIPS
THAT KIND OF MIGHT REFLECT WHAT THEY'RE WORKING ON. AND GIVEN
ALL OF THESE CLAIMS, IT'S NOW POSSIBLE FOR THE APPLICATION TO
MAKE SOME AUTHORIZATION DECISIONS. SO DEPENDING ON HOW
SOPHISTICATED THIS APPLICATION IS, IT MIGHT BE MAKING DECISIONS
ABOUT WHICH USERS CAN ACCESS WHICH FUNCTIONALITY WITHIN THE
APPLICATION, AND CERTAINLY THE USER'S IDENTITY AND OTHER
IDENTITY RELATED CLAIMS ARE GOING TO AFFECT WHAT DATA THAT
USER SHOULD BE ALLOWED TO ACCESS. IF YOU AND I ARE ON
DIFFERENT TEAMS IN THE COMPANY, WE'RE PROBABLY GOING TO HAVE
ACCESS TO VERY DIFFERENT DATA SETS. SO NOW WE'VE ESTABLISHED A
SESSION. THE USER INTERACTIONS CAN BEGIN. SO THIS SESSION NOW
THAT IT'S BEEN ESTABLISHED IS GOING TO HAVE DIFFERENT DEFINED
BOUNDARIES AND SECURITY GUARDRAILS, PERHAPS EVEN
DIFFERENT ONES BASED ON THE PROFILE OF THE USER. SO THAT'S
HOW THE SEQUENCE OF SECURITY CHECKS OCCURS IN GENERAL. LET'S
TALK ABOUT HOW IT WORKS IN AMAZON Q BUSINESS IN PARTICULAR.
SO AMAZON Q, LIKE I SAID, AN AWS SERVICE. AND AGAIN, IT INHERITS
ALL OF THE SECURITY GOODNESS THAT ALL OTHER AWS SERVICES HAVE
HAVE. FOR EXAMPLE, EVERY AWS SERVICE HAS IAM POLICY CHECKS AT
THE GATE. Q IS NO EXCEPTION. SO AFTER THE IAM POLICY CHECKS AND
DECISIONS ABOUT ABOUT CUSTOM SECURITY GUARDRAILS AND DATA
ACCESS CONTROLS, AFTER THAT, THERE MIGHT BE SOME FILTERING OF
THE RESPONSE. SO THESE ARE WHAT YOU'RE SEEING HERE IS MULTIPLE
LAYERS OF SECURITY. AND THEY'RE ALL WORKING TOGETHER. NOW YOU
ALSO HAVE TO THINK ABOUT APPLICATION IDENTITY NOW HERE TO
SORT OF ILLUSTRATE HOW THIS WORKS IN AWS. I'M SHOWING YOU A
REQUEST TO AMAZON BEDROCK TO ITS CORE API CALLED INVOKE MODEL.
THIS IS THE CORE INFERENCE API IN AMAZON BEDROCK. WHEN WE'RE
TALKING ABOUT BEDROCK, INVOKE MODEL API, OR ANY OF THE
THOUSANDS OF OTHERS OF AWS APIS THAT EXIST, APPLICATION IDENTITY
IS ESTABLISHED THROUGH AWS. IAM. THE REQUEST THAT REACHES BEDROCK
BEFORE IT REACHES BEDROCK ON THE CLIENT. IT GETS SIGNED ACCORDING
TO OUR SIGNATURE V4 SIGV4 PROTOCOL. THE CLIENT SIGNS EACH.
THE CLIENT WILL SIGN EACH REQUEST WITH ITS IAM
CREDENTIALS. NOW, TYPICALLY YOU AS THE BUILDER DON'T NEED TO DO
THAT DIRECTLY BECAUSE YOU'RE USING ONE OF OUR CDK OR ONE OF
OUR SDKS OR CLI. MAYBE YOU'RE GOING THROUGH THE CONSOLE. ALL
OF THOSE THINGS TAKE CARE OF THE SIGNATURE DETAILS FOR YOU, BUT
THAT IS ACTUALLY WHAT'S HAPPENING. AND IT ESTABLISHES A
VERIFIABLE APPLICATION IDENTITY. A LITTLE BIT MORE DETAIL ON
THAT, ON WHAT HAPPENS WHEN BEDROCK OR REALLY ANY OTHER AWS
SERVICE RECEIVES ONE OF THESE SIGNED REQUESTS. SO YOU CAN SEE
THAT INTERNALLY, BEDROCK IS MAKING A REQUEST TO THE AUTH
RUNTIME SERVICE. NOW THE AUTH RUNTIME SERVICE. THIS IS NOT AN
AWS SERVICE THAT YOU'VE EVER USED. THIS IS AN INTERNAL FACING
LARGE, LARGE SCALE SERVICE THAT WE RUN IN EACH AND EVERY AWS
REGION. THIS IS THE DATA PLANE OF IAM. IF YOU'RE FAMILIAR WITH
THOSE CONCEPTS. SO OURS VALIDATES THE SIGNATURE, THEN
RETURNS ANY IAM AUTHORIZATION POLICIES FROM IAM THAT ARE
ATTACHED TO THE AUTHENTICATED CALLER OR PRINCIPAL, OR ANY
POLICIES ATTACHED TO THEIR ACCOUNT OR THEIR ORGANIZATION.
THERE'S A LOT OF POLICIES THAT COME BACK FROM THE AUTH RUNTIME
SERVICE AND BEDROCK, LIKE ALL OF OUR OTHER AWS SERVICES, IS
INTEGRATED WITH THE SHARED AUTH RUNTIME CLIENT LIBRARY THAT
PERFORMS AUTHORIZATION OF THE REQUEST AND ALL OF ITS
PROPERTIES AGAINST THOSE IAM POLICIES. SO IT'S A MATCH OF THE
REQUEST AND ALL OF ITS PROPERTIES, AS PREPARED BY
BEDROCK AGAINST ALL OF THESE POLICIES THAT CAME FROM IAM. SO
THIS POLICY, YOU KNOW, FOR AN EXAMPLE OF WHAT THE POLICY MIGHT
SAY, IT IT MIGHT REQUIRE EACH INVOKE MODEL TO REQUIRE A
GUARDRAIL AS PART OF EACH REQUEST, OR ELSE IT WILL BE
DENIED. SO WHAT I'M TELLING YOU ABOUT BEDROCK HERE, THERE'S
ACTUALLY NOTHING SPECIAL ABOUT IT ABOUT THAT. WITH RESPECT TO
IAM, EVERY AWS API WORKS THIS WAY. AND SO FOR AWS GENERATIVE
AI SERVICES. THIS PROCESS IS PROVIDING AUTHENTICATION AND
AUTHORIZATION FOR THE APPLICATION USING EXISTING
TECHNIQUES THAT IF YOU'RE A BUILDER ON AWS, YOU'RE ALREADY
WORKING WITH. TODAY WE JUST SAW AUTHENTICATION AND
AUTHORIZATION. AND I'M GOING TO JUST RECAP THAT PART A BIT. SO
WE DISCUSSED HOW THESE APPLICATIONS MIGHT AUTHENTICATE
THEIR HUMAN USERS USING SINGLE SIGN ON SSO OR SIMILAR PATTERNS.
WE TALKED ABOUT HOW THAT USER'S IDENTITY MIGHT AFFECT THEIR
ACCESS TO DATA, AS WELL AS THE GUARDRAILS AND OTHER BEHAVIORS,
AND THEN FINALLY, HOW THE APPLICATIONS IDENTITY FITS IN.
THAT PROVIDES SOME CONTEXT AROUND HOW THIS USER IS
INTERACTING WITH THE SYSTEM. AWS SERVICES USE IAM FOR
AUTHENTICATION AND AUTHORIZATION OF APPLICATIONS. NOW, I'M JUST
GOING TO GO OUT ON A LIMB HERE AND GUESS THAT MANY OF YOU HAVE
HEARD OF AGENTIC. I WITH AGENTIC I YOU KNOW, THE INTERESTING
THING HERE IS THAT SYSTEMS START ACTING AUTONOMOUSLY. THEY MIGHT
MAKE DECISIONS AND TAKE ACTIONS ON BEHALF OF USERS. NOW WE'RE
SECURITY PEOPLE HERE AT RE:INFORCE. SO IF YOU THINK
ABOUT THE IMPLEMENTATION, ABOUT THE IMPLICATIONS OF THAT, YOU
CAN SEE HOW IT ADDS A WHOLE NOTHER DIMENSION TO OUR
AUTHENTICATION AND AUTHORIZATION NEEDS. ONCE AGAIN, A COUPLE
DIFFERENT IDENTITIES HERE. THE AGENT, FOR EXAMPLE, IS GOING TO
BE AN ENTITY THAT NEEDS ITS OWN IDENTITY. AND THEN AT THE SAME
TIME, IT NEEDS TO BE ABLE TO TAKE ACTION ON BEHALF OF THE
USER IT'S REPRESENTING, MEANING IT NEEDS TO WORK WITHIN THOSE
CONSTRAINTS. SO ONCE AGAIN, WE'VE GOT MULTIPLE MAYBE TWO OR
MORE IDENTITIES GOING ON HERE. AND SO IN ORDER TO BE ABLE TO DO
THAT, WE'RE GOING TO NEED A MEANS OF IDENTITY PROPAGATION.
THE ORIGINAL USER'S IDENTITY IS GOING TO NEED TO PROPAGATE
THROUGH THE AGENT SECURELY TO ALL THE SYSTEMS IN THE DATA THAT
IT ACCESSES. NOW, THAT MATTERS FOR TWO IMPORTANT REASONS. IT
MATTERS FOR AUTHORIZATION. SO WE WANT THE AGENT TO ACCESS THE
DATA THAT THE CURRENT AUTHENTICATED USER HAS ACCESS
TO, BUT NOT ANY DATA OR ACTIONS THAT THIS USER DIDN'T ORIGINALLY
HAVE ACCESS TO, BUT WITHIN BOUNDS. ACTUALLY, IT TYPICALLY
AN AGENT YOU DON'T WANT IT TO. THE AGENT HAS SOME SORT OF JOB,
A PARTICULAR CONTEXT IN WHICH IT'S OPERATING. YOU DON'T WANT
IT TO HAVE ACCESS TO THE FULL SCOPE OF ALL OF THE PERMISSIONS
THAT THE USER HIMSELF MIGHT HAVE BEEN DIRECTLY ENTITLED TO. AND
IT ALSO MATTERS FOR AUDIT, RIGHT? IF YOU GO TO THE AUDIT
LOGS NOW IN AWS, AS YOU KNOW, IF YOU GO TO THE AUDIT LOGS, THAT
MEANS YOU'RE LOOKING AT CLOUDTRAIL EVENTS. IF YOU GO TO
CLOUDTRAIL, YOU WANT EACH ACCESS TO BE ATTRIBUTED DIRECTLY TO A
USER, BECAUSE THAT MAKES IT MUCH MORE STRAIGHTFORWARD TO ANSWER
THE QUESTION OF WHO ACCESSED THIS DATA. SO THE GOOD NEWS IS
THAT AWS HAS BEEN INVESTING IN IDENTITY PROPAGATION FOR DATA
ACCESS USE CASES, ESPECIALLY IN ANALYTICS, FOR A FEW YEARS NOW,
WE HAVE A FEATURE CALLED TRUSTED IDENTITY PROPAGATION. THIS
CAPABILITY ALLOWS ANY AGENT, INCLUDING AN AI AGENT, TO
SECURELY PROPAGATE AN END USER'S IDENTITY SO THAT AUTHORIZATION
DECISIONS AND AUDIT CAN BE MADE CLOSE TO THE DATA AND REFLECT
THE USER'S IDENTITY. SO LET'S SEE HOW THOSE IDENTITY AND
AGENTIC AI PRINCIPLES WORK IN PRACTICE. ROBINHOOD IS A COMPANY
COMMITTED TO DEMOCRATIZING FINANCE, AND THEY WERE LOOKING
TO ENHANCE THEIR FINANCIAL CRIMES INVESTIGATIONS. SO THEY
BUILT A FIN CRIMES AGENT ON AWS. AWS IS CLOUD NATIVE TOOLS AND
CUSTOMIZABLE FOUNDATION MODELS SERVICES ENABLED ROBINHOOD TO
RAPIDLY EXPERIMENT, FINE TUNE, AND DEPLOY AI AGENTS TAILORED TO
COMPLIANCE WORKLOADS WITHOUT COMPROMISING ON CONTROL OR DATA
SECURITY. SO WHAT MAKES THE ROBINHOOD IMPLEMENTATION
PARTICULARLY NOTEWORTHY IS THEIR APPROACH TO COMPREHENSIVE
AGENTIC IDENTITY CONTROLS AND SECURITY. SO THEY BUILT A
MULTI-LAYERED SYSTEM WHERE THERE'S A CONTROL PLANE WITH
OPERATIONAL PLANS TO ENABLE DETERMINISTIC AGENT BEHAVIOR.
THERE'S AN EXECUTION PLANE FOR SELF-CONTAINED AGENTS
ORCHESTRATED THROUGH KUBERNETES. AND THEN FINALLY, THERE'S A
VALIDATION LAYER WHERE EVERY LLM AGENT INCLUDES A VALIDATION
COUNTERPART THAT REVIEWS GENERATED CONTENT FOR
HALLUCINATION, RISK, AND CONSISTENCY. SO EACH AGENT
OPERATES WITH SPECIFIC DOCUMENTED PERMISSIONS AND CLEAR
OPERATIONAL BOUNDARIES, AND THAT ENABLES FIN CRIMES
INVESTIGATIONS TO SCALE INTELLIGENTLY, RESPOND TO
SHIFTING RISK PATTERNS RAPIDLY, AND MAINTAIN TRANSPARENCY IN
EVERY DECISION ALONG THE WAY. THE RESULTS THAT ROBINHOOD HAS
ACHIEVED SPEAK TO THE POWER OF THIS SECURITY FIRST APPROACH.
ROBINHOOD SAW A 20% EFFICIENCY GAIN IN INVESTIGATIVE WORKLOADS
WHILE MAINTAINING FULL REGULATORY COMPLIANCE. THEY HAD
COMPLETE AUDIT TRAILS OF ALL AGENT ACTIONS AND VERIFIABLE AND
EXPLAINABLE OUTPUTS. SO WHEN YOU BUILD SECURITY AND IDENTITY
CONTROLS INTO YOUR AI ARCHITECTURE FROM THE START, YOU
CAN ENABLE BOTH INNOVATION AND COMPLIANCE. SO WE TALKED ABOUT
IDENTITY AND ACCESS MANAGEMENT. I'M GOING TO GO TO THE NEXT TYPE
OF CORE PROTECTION THREAT DETECTION AND INCIDENT RESPONSE.
NOW IF YOU'RE A SECURITY PRACTITIONER, WHICH YOU PROBABLY
ARE BECAUSE YOU'RE HERE AT RE:INFORCE, THESE CONCEPTS ARE
FAMILIAR TO YOU. AND JUST LIKE AUTHENTICATION AND
AUTHORIZATION, IT'S BUILT ON YOUR EXISTING EXPERTISE WITH A
FEW NEW CONCEPTS TO THINK ABOUT THAT ARE SPECIFIC TO GENERATIVE
AI. SO TWO ARE TRADITIONAL INCIDENT RESPONSE TECHNIQUES. WE
NEED TO ADD SOME AI SPECIFIC DETECTION PATTERNS. THESE
INCLUDE PROMPT INJECTION ATTACKS, MODEL JAILBREAK SIGNATURES,
MODEL BEHAVIOR ANOMALIES, AND UNAUTHORIZED DATA ACCESS
SEQUENCES. AN APPROPRIATE AUTOMATED RESPONSE MIGHT
DYNAMICALLY BLOCK QUERIES, ADAPTIVELY RATE LIMIT REQUESTS,
OR GENERATE ALERTS IN REAL TIME. SO BOTH BEFORE THE GENERATIVE AI
ERA AND NOW THAT WE'RE IN IT, ONE OF THE GREAT REASONS FOR
BUILDING ON AWS IS THAT YOU BENEFIT FROM OUR DEEP, BROAD,
AND LONG TERM INVESTMENTS IN THREAT INTELLIGENCE. OF COURSE,
THREAT INTELLIGENCE IS MOST VALUABLE WHEN IT'S, YOU KNOW,
USED. SO OUR APPROACH, THEREFORE, IS TO BUILD THREAT
INTELLIGENCE INTO OUR SECURITY TOOLS. SO THE CAPABILITIES YOU
SEE UP ON THIS SLIDE, EACH OF THEM IS POWERFUL AND RICH. AND
THEY MAKE UP THEY MAKE THREAT INTELLIGENCE AVAILABLE, TIMELY,
ACTIONABLE AND PRACTICAL FOR ALL OF OUR CUSTOMERS. AND WE SHARE
THIS CRITICAL INFORMATION WITH CUSTOMERS THAT WE BELIEVE MAY BE
TARGETED OR COMPROMISED BY POTENTIAL MALICIOUS ACTIVITY,
AND WE HELP THEM TAKE STEPS TO REDUCE THEIR RISK AND PREVENT
DISRUPTIONS TO THEIR ORGANIZATION. MATTER OF FACT, WE
EVEN NOTIFY ORGANIZATIONS WHO AREN'T OUR CUSTOMERS IF WE SEE
SIGNALS THAT THEY MAY BE COMPROMISED BECAUSE WE HAVE A
STRONG INTEREST IN MAKING THE INTERNET SAFER FOR ALL ITS
USERS. SO WE AT AWS AND YOU, OUR CUSTOMERS, ARE HEADING INTO THIS
NEW ERA OF AI TOGETHER. SO WHY DON'T YOU COME BACK UP HERE AND
TELL THEM MORE ABOUT HOW WE AWS UNDERSTAND SECURITY FOR THIS
FUTURE? >> I WOULD.
>> LOVE TO. >> AWESOME JOB. THANK YOU. SO
NOW WE LOOK TO THE FUTURE OF AI SECURITY. WE'RE SEEING AN
EVOLUTION IN HOW ORGANIZATIONS NEED TO THINK ABOUT PROTECTION.
SO LET'S TALK ABOUT OUR PERSPECTIVE ON WHERE WE'RE
HEADED. THE EVOLUTION OF GENERATIVE AI HAS FOLLOWED A
VERY CLEAR PROGRESSION, WITH EACH PHASE BRINGING NEW
PRIORITIES AND CHALLENGES FOR OUR BUSINESSES. WITH AI
ASSISTANTS, CUSTOMERS ARE EXPERIMENTING WITH GENERATIVE AI
TO IDENTIFY WHERE THEY CAN DRIVE VALUE, AND THEY'RE BUILDING LOTS
OF PROOF OF CONCEPTS, WHICH IS EXCITING. CUSTOMERS ARE TURNING
THESE AI APPLICATIONS INTO PRODUCTION WORKLOADS, RIGHT? AND
THEN THEY'RE TURNING THEIR FOCUS TO OPERATIONS, RIGHT? AND
OPTIMIZATION, THEN SCALING AI INVESTMENTS INTO AGENTIC. AS
BECKY WAS TALKING ABOUT JUST A FEW MOMENTS AGO, WE CONTINUE TO
EVOLVE TOWARDS A FULLY REALIZED AGENTIC WORLD WHERE WE'VE
INTELLIGENT MULTI-AGENT SYSTEMS THAT ARE GOING TO MAKE COMPLEX
DECISIONS AND COORDINATE EFFORTLESSLY WITH LESS HUMAN
OVERSIGHT, COMPLETELY TRANSFORMING THE WAY WE WORK AND
INNOVATE. AND WE EXPECT TO SEE THE RATE OF AGENTIC AI ADOPTION
RAPIDLY INCREASE OVER THE NEXT SEVERAL YEARS. THE KEY MESSAGE
HERE IS DO NOT WAIT. START BUILDING YOUR SECURITY
FOUNDATION NOW. TAKE ADVANTAGE OF THE INVESTMENTS YOU'VE
ALREADY MADE. ORGANIZATIONS WILL THRIVE IN THE AGENTIC ERA IF
THEY EMBRACE SECURITY AS AN ENABLER OF INNOVATION. AND IF
YOU BUILD FLEXIBLE, ADAPTABLE SECURITY ARCHITECTURES AND
IMPLEMENT THESE DEFENSE IN-DEPTH APPROACHES. WE'VE BEEN
DISCUSSING TODAY, NARROWLY SCOPED PRIVILEGE AND SECURE
ACCESS TO THOSE AGENTS AND FOUNDATIONAL MODELS, RIGHT?
SECURITY ISN'T JUST ABOUT PROTECTION THESE DAYS. IT REALLY
IS ABOUT ENABLING THE FUTURE OF AI INNOVATION. AWS IS COMMITTED
TO BEING YOUR PARTNER ON THIS JOURNEY. WE'VE DESIGNED TO BE
THE MOST SECURE INFRASTRUCTURE FOR WHATEVER COMES NEXT IN AI
EVOLUTION. RIGHT NOW, AS WE LOOK TO THE FUTURE OF AI, AWS REMAINS
COMMITTED TO OUR FOUNDATIONAL PRINCIPLES OF BUILDING SECURITY
AND PRIVACY FEATURES ACROSS OUR INFRASTRUCTURE, AND WE'RE ALSO
CONTINUING TO COLLABORATE WITH INDUSTRY ON DEVELOPING STANDARDS
AND PRACTICES THAT STRENGTHEN AI SECURITY FOR EVERYBODY. RIGHT.
WE'RE FOUNDING SPONSORS OF THE COALITION FOR SECURE AI. WE
CONTINUE TO CONTRIBUTE TO OWASP, AND WE'RE MEMBERS OF THE
FRONTIER MODEL FORUM, AS WELL AS OTHER INDUSTRY STANDARD PROJECTS
THAT HELP DEFINE THE NEXT GENERATION OF SECURITY STANDARDS
AND BEST PRACTICES. THAT WILL BE CRUCIAL AS AI BECOMES
INCREASINGLY CENTRAL TO HOW ORGANIZATIONS OPERATE AND
INNOVATE TOGETHER. AND WHEN IT COMES TO OPEN STANDARDS, IT RUNS
DEEP IN OUR DNA HERE AT AWS. IT'S WHY WE DECIDED TO BUILD
AMAZON EC2 AS A PROTOCOL AGNOSTIC CLOUD COMPUTING SERVICE
AND AMAZON SAGEMAKER AS A FRAMEWORK AGNOSTIC DEEP LEARNING
SERVICE. OUR COMMITMENT TO OPENNESS CONTINUES AS WE ENTER
THE AGENTIC ERA AND EXTENDING TO INTELLIGENT COMMUNICATION. YOU
MIGHT HAVE HEARD MULTIPLE PROTOCOLS THAT ARE EMERGING THAT
ENABLE THIS TYPE OF CAPABILITY, INCLUDING THE MODEL CONTEXT
PROTOCOL, OPEN SOURCE BY ANTHROPIC IN LATE 2024. NOW
DEMONSTRATING OUR COMMITMENT TO THESE OPEN STANDARDS, AWS IS
JOINING STEERING COMMITTEE FOR MCP BY SUPPORTING MULTIPLE
PROTOCOLS, WE ENSURE DEVELOPERS CAN BUILD BREAKTHROUGH AGENTIC
APPLICATIONS WITHOUT BEING TIED TO ONE STANDARD AND WITH HAVING
CONFIDENCE IN THE SECURITY THAT FOUNDATION. AND JUST LAST MONTH,
AMAZON ANNOUNCED THE RELEASE OF STRANDS AGENTS, AN OPEN SOURCE
SDK THAT TAKES A MODEL DRIVEN APPROACH TO BUILDING AND RUNNING
AI AGENTS IN JUST A FEW LINES OF CODE STRAND SCALES FROM SIMPLE
TO COMPLEX AGENT WORKLOADS AND FROM LOCAL DEVELOPMENT AND
DEPLOYMENT INTO PRODUCTION AT SCALE. SO NOW I WANT TO BRING US
BACK TO WHERE WE STARTED, BECAUSE IT'S A PRINCIPLE THAT
UNDERPINS EVERYTHING WE DO AT AWS. SECURITY IS OUR
TOP PRIORITY. SECURITY IS A COMMITMENT THAT WE'VE LONG HELD
TRUE FROM THE BEGINNING, AND IT'S NO DIFFERENT WHEN IT COMES
TO AI. TODAY, WE'VE EXPLORED WHY AWS HAS BECOME THE TRUSTED
FOUNDATION FOR AI INNOVATION, POWERING EVERYTHING FROM
STARTUPS TO GLOBAL ENTERPRISES. WE'VE SEEN HOW ORGANIZATIONS
LIKE TRELLIX, PWC, AND ROBINHOOD ARE BUILDING TRANSFORMATIVE AI
APPLICATIONS ON AWS WHILE MAINTAINING THE HIGHEST SECURITY
STANDARDS. BUT PERHAPS MOST IMPORTANTLY, WE'VE DISCUSSED HOW
WE'RE CONTINUALLY EVOLVING OUR SECURITY INFRASTRUCTURE AND
MENTAL MODELS TO STAY AHEAD, BECAUSE IN THE WORLD OF AI, WE
ALL NEED TO BE LIVING IN THE FUTURE. THANK YOU FOR JOINING US
TODAY. I HOPE YOU ENJOY THE REST OF RE:INFORCE. THERE'S STILL A
LOT MORE THAT YOU CAN TAKE ADVANTAGE OF TODAY. I HOPE YOU
THINK ABOUT HOW YOU CAN CREATE THAT DEFENSE IN DEPTH IN YOUR AI
JOURNEY. AND REMEMBER TO STAY FLEXIBLE, ADAPTABLE, AND OF
COURSE, KEEP LEARNING AND EVOLVING. AS I MENTIONED A
MOMENT AGO, THERE'S STILL PLENTY MORE TO EXPERIENCE HERE AT
RE:INFORCE IF YOU STAY HERE. COMING UP NEXT IS A TALK ON AWS
GLOBAL THREAT INTELLIGENCE. A LITTLE LATER TODAY. ANTHROPIC
HEAD OF RISK GOVERNANCE IS GOING TO BE TALKING ABOUT HOW THEY
COLLABORATE WITH AWS TO DELIVER ENTERPRISE GRADE SECURITY FOR
THEIR LMS AND GENERATIVE AI WORKLOADS FOR CUSTOMERS. RIGHT.
OR IF YOU'RE INTERESTED IN HEARING MORE ABOUT ROBINHOOD'S
JOURNEY, YOU CAN JOIN ME. AS WELL AS THEIR CISO AND DEPUTY
CISO LATER TODAY AS WE'RE GOING TO TALK ABOUT HOW THEY USE
SECURITY TO DRIVE INNOVATION AND THE FAST PACED FINTECH
ENVIRONMENT. WHATEVER PATH YOU CHOOSE IN THE WORLD OF AI,
SECURITY ISN'T JUST A FEATURE, IT'S THAT FOUNDATION THAT
ENABLES TRUE INNOVATION. SO THANK YOU AGAIN. ENJOY THE REST
OF THE CONFERENCE, AND IF YOU DON'T MIND, PLEASE FILL OUT THE
SURVEY AVAILABLE ON THE AWS EVENTS APP. SO BECKY AND I CAN
LEARN AND GROW FROM THIS EXPERIENCE AS WELL. THANK YOU
VERY MUCH AND BE WELL.
