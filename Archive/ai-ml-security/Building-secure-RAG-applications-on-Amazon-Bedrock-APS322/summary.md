# AWS re:Inforce 2025 - Building secure RAG applications on Amazon Bedrock (APS322)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=GILVXwAKyiY)

## Video Information
- **Author:** AWS Events
- **Duration:** 12.5 minutes
- **Word Count:** 2,320 words
- **Publish Date:** 20250618
- **Video ID:** GILVXwAKyiY

## Summary
The presentation focuses on building secure Retrieval Augmented Generation (RAG) applications using Amazon Bedrock. The speakers, Riggs Goodman and Isimah Emmanuel, discuss how RAG architectures differ from traditional database access patterns by using vector databases to provide additional context to generative AI models.
The key security challenge with RAG applications is that unlike traditional search engines where authorization happens at the point of accessing individual documents, RAG systems index and incorporate content directly into model responses. This creates a need for careful security architecture to ensure users only access authorized information through the AI system.

## Key Points
- RAG architectures require different security approaches compared to traditional database access patterns
- Authorization needs to happen before data reaches the model, not at individual document access points
- Multi-tenant architectures should separate data access based on user groups and permissions
- Protection against prompt injection attacks is crucial for preventing unauthorized data access
- Amazon Bedrock provides built-in security features but requires proper architecture implementation for compliance
- Sensitive data handling requires careful consideration of authentication and authorization at multiple levels
- Vector databases need specific security controls different from traditional databases

## Technical Details
- Amazon Bedrock
  - Managed service for accessing various AI models (Anthropic, Amazon, Meta)
  - Includes built-in security controls and compliance features
  - Supports TOS monitoring and prompt/completion tracking
- Knowledge Bases
  - Vector databases storing indexed documents from S3
  - Used to provide additional context to AI models
  - Requires specific security controls for data access
- Security Implementation Options
  - Application layer authorization
  - Separate knowledge bases for different access levels
  - Authentication and authorization controls at data source level
  - Multi-tenant architecture support
  - Protection against prompt injection attacks

## Full Transcript

Um, so this session, um, there's this little thing called generative AI that I think a lot of people like talking about, um, and what we're going to talk about today is the additional context that you put with gene of AI using something called, uh, retrieval augmented generation or RAG, uh, that uses vector databases in order to provide additional context into generative AI applications. My name is Riggs Goodman. I'm a principal partner solution architect at AWS. I'm Isimah Emmanuel. I'm a senior solutions architect TWS. And so for today's presentation we're gonna spend just 20 minutes we're not gonna go that deep into secure rag architectures. I'm gonna give an overview of bedrock for people who are not familiar with Bedrock, what knowledge bases are, and then dive into what security means with rag architectures because it is different. Compared to how you access databases, how you access other API calls to get that context to put it into your generative AI application, and then Emmanuel is gonna go through and walk through exactly how do you go about building the right security architecture with data authorization in order to make sure that you're actually building them securely so you're not gonna have things like sensitive data disclosure and other things like that. So for for for people who are not familiar with Amazon Bedrock, Amazon Bedrock is a managed service in order for customers to use geneive AI models. This can be from Anthropic, from Amazon, from Meta, but we host these generative AI models for customers so they can, uh, do, um, all the front end application stuff and we take away a lot of the undifferentiated heavy lifting of using generative generative AI with your applications. So we give you options with. Models we uh optimize for cost and latency and other things like that we securely host these models for you so um you don't have to worry about GPUs and other things like that, applying different safety controls with bedrock guard rails, um, and being able to orchestrate things with agents on top of everything that we do with Amazon Bedrock we also focus on the security aspect and the compliance uh aspect of it security, what we're talking about, we don't take any of your data and train them. Models or give it to model providers um we use things like TOS and being able to monitor exactly what your users prompts are what the completions are, and other things like that on the compliance side we provide uh different capabilities so they can be uh compliance with different um things like uh SOC2 and other things like that we we make them eligible but it's still up to you as a customer to build the right architecture so they can meet some of those compliance standards and other things. So that's Amazon Bedrock, but let's talk about a little bit of how do you add additional context to Amazon Bedrock. When I talk about adding additional context, what I mean by that is when a customer asks a question of a generative AI application, sometimes you want to include additional data as part of that context. So that could be system prompts or prompt engineering with uh gene of AI. It can be retrieval augmented generation or rag, which is what we're gonna talk about today. Or it can also be things like fine tuning models. Fine tuning is basically having question answer pairs where you're training the underlying model with additional data on top of what it has with just the massive amounts of data that the model is trained on. You can also do things like continuously, uh, pre-train the model and other things like that. For this presentation talking about the security aspects, we're gonna talk about rag architectures and how you build secure rag architectures with gene of AI applications. So with RAG, the way that this works is when a user makes a query to Amazon Bedrock, one of the things that they can include inside that query is being able to say I want to use this knowledge base that is basically a vector database or a database that indexes different documents from S3 or other data locations in order to provide additional context when someone asks a question about HR policies or what are the rules for certain things. Or being able to look at documentation and other things and provide additional context back to Amazon Bedrock and then it uses that additional context with the user query to make a call to that underlying uh large language model whether that's meta anthropic, Amazon or others that model will then respond back with whatever the output is in order to uh provide that additional context that you need, right? So this presentation, how do you provide the right security with rag architectures? The example that I always like to use with Rag to explain how this is different compared to regular database applications is with RA architectures I compare it to a search engine when you have an internal wiki site or an internal search engine and you send a query to that search engine, it's gonna respond back with different data of like these are different places we can go to get uh understanding of exactly where to go for that. But what do you do once you actually get those responses back? You click on that link and depending if you are authorized to access that data or authorized to access that page, you're either gonna get a 200 response or you're gonna get a 400 response because it's checking your authorization on whether or not you get access to that data um that is uh linked with that website and other things like that. With rag it's a little bit different when you do the user query to Amazon Bedrock and it pulls additional context from that knowledge base. One of the things it doesn't do, it doesn't ask you as a user to actually go to that data source. It's indexing all the information in the knowledge base. It uses that context directly in order to pass it to the model. And then come back with whatever the responses from the model and so when you're thinking about security you need to think about that overall of now you're not going to that underlying data source where you might have all permissions and other things and you have to put the right security in place so you can uh make sure that only users that are authorized to certain data get access to the data in that underlying data source. And so when we talk about different security with rag architectures what customers are looking for is one being able to use that additional context from data sources and other things like that. They want to implement things that have off in or all or authentication and authorization as part of it. They do want to use sensitive data that might not be uh available for public customers but also sensitive data that you might have different user groups inside your organization. You might have a finance group compared to a sales group that they need to split. The different data that only financial uh users are going to have access to some data while only sales people are gonna have access to the other. They use multi-tenant architectures. You want to be able to use data sources and have either one or multiple knowledge bases in order to build these multi-tenant architectures instead of having to build different applications for different users, and they want to protect against things like prompt injections. You don't want to build an architecture with one single prompt injection can get user access to sensitive data that they're not allowed to get access to. And so with that, let me turn it over to Emanuel and he will walk through 3 different ways to build rag architecture securely so you're not uh providing are you providing the right authorization for that data. Thank you. Um. We are going to discuss three strategies when you're providing secure access to your ag architectures. One is providing authorization at the application layer. The second use case is when you want to use separate knowledge bases in authorizing assets, and the last use case is using metadata filtering. Let's walk through this one at a time. Let's start with what would happen if we want to provide, you know, secure access at the application layer. This is um a use case where like most of you, you have your identity provider that provides authentication and so you do authentication at your identity provider and then you move to your application. That is where you do authorization and based off um the authorization that you perform there. You now provide fine graining access to Amazon Bedrock and then from Amazon Bedrock you can go to your knowledge base and then to your data source, retrieve whatever contextual data you need, um, augment it with the initial prompt and then send it to your model and then the user gets a response. Again, we are performing authentication at your identity provider and we are performing authorization at your application. A second use case we see out there that we recommend our customers to adopt is when you have um different business units, let's say you have a billing and a finance team or a sales and a finance team, um, you could have those different groups of users in your identity provider. You have Group A. Users and Group B users, you could use separate knowledge bases. So for Group A users, they go to your um your, your knowledge base, so I say Group A will go to knowledge base A and Group B will go to knowledge base B and then from there get access to data. Um, to explain this a bit more or less, look at this. We'll have your identity provider performing authentication. The user comes in there, it goes to the application, provide authorization. The authorization here is going to give them access to the bedrock knowledge base. So for a user that is coming from Group A, the application layer is going to authorize them to to bedrock knowledge base A. A user that is in Group B, your application is going to provide them access to Bedrock Knowledge Base B, and then from there they will now have access to your data, be able to pull the right data, combine it with your initial prompt, send it to your model, and then you get a response. The third use case that we see out there is when customers want to provide fine grain assets, and this is when you use a feature called metadata filtering. Basically with metadata filtering, you are going to line up those attributes you are interested in and then perform pattern matching. Now what happens is you're going to include in your knowledge base, let's say you have this data being stored in S3, you are going to include the metadata. JSON file. Within that metadata. JSON file you are going to mention those attributes that you're interested in. Let's say score number. So you're interested in people in data that only matches a particular number and maybe beyond maybe 10 if that's the number you're interested or 20, whatever the number is. Now you're going to perform a metadata fusion which is just pattern matching and then you're going to indicate what is the future you're interested in. Now matching that to whatever attributes you are interested you you were looking at initially. Just to make this very, very clear, you have a user coming to your identity provider, they perform authentication, you perform authorization there. Then once the user, the query that the user makes, we are going to perform a metadata filter which, as I mentioned, is just a pattern match, and then that pattern match will look at your data that is stored on your data source which is already, you will already create a catalog of that data using the metadata.json file. If we look at the score number earlier, it means that within your data source we already matched setting data that matches a particular number and a particular score, right? The score that's a key value pair. So we're going to only match those data that matches that and then we're going to send all those data to your prompt and then it goes to your model and then you get a response. What this provides is that fine grains access to only the data that the user particularly needs. Now, so these are the three patterns we see out there that we recommend to our customers just to summarize, first of all, you want to use an identity provider to provide authentication and then perform authorization at the application layer. The second recommendation we mention is use separate knowledge basis. If you have the right data strategy in place, you know your data, you want to use separate knowledge basis to perform data separation. The third item is you want to. Use right tagging. Tagging will really be important when you start growing, right? You have your knowledge base giving you access to your data as you bring in more data, you apply the same tags. You don't need to, you know, you, you just need to use the same knowledge base to apply to access those data. And then the last item for providing fine grainsets you can use metadata filtering. We have these resources that will guide you, this is a blog and then security for GNEI documentation. So that's all we have. Thank you. Thank you.
