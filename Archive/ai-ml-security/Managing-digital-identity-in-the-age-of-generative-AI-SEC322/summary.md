# AWS re:Inforce 2025 - Managing digital identity in the age of generative AI (SEC322)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=_imxmb1Za7Q)

## Video Information
- **Author:** AWS Events
- **Duration:** 20.8 minutes
- **Word Count:** 3,663 words
- **Publish Date:** 20250620
- **Video ID:** _imxmb1Za7Q

## Summary
This presentation by Lili Ahiam and Arthur from AWS explores managing digital identity in the age of generative AI, focusing on zero trust security principles and identity management for AI applications. The speakers emphasize the critical importance of implementing deterministic, layered security approaches that do not rely on AI models to make security decisions.

## Key Points
- Zero Trust Security Principles:
  - Not a service or product, but an architectural approach
  - Requires security to be built into applications from the ground up
  - Goes beyond network perimeter controls
  - Involves continuous authentication and authorization at each layer

- Critical Identity Management Strategies:
  - Never allow generative AI applications to make security decisions
  - Implement authorization from around the application, not within it
  - Use deterministic factors for authentication and access control
  - Validate credentials at every stage of interaction

- Authorization Best Practices:
  - Authenticate and authorize access at each component of the system
  - Pass identity credentials between different system components
  - Combine network and identity controls
  - Implement least-privilege access principles

## Technical Details
- Authentication and Authorization Layers:
  - Edge perimeter
  - Application layer
  - Orchestration
  - Data tools
  - Knowledge base access
  - Tool invocation

- AWS Recommended Tools:
  - Verified Access (edge authentication)
  - Verified Permissions (external authorization service)
  - Identity and Access Management (IAM)

- Security Implementation Recommendations:
  - Design with zero trust principles
  - Treat each application component as untrusted
  - Use LLMs only as planners or formatters
  - Implement strict data access controls
  - Prevent models from seeing unauthorized dat

## Full Transcript

So welcome to today's session. Um, we really want to take some time to talk to you about how you should think about managing your identities when it comes to your journey applications. We're gonna spend some time thinking about that in the right places to be doing your implementation of authorization. So my name is Lili Ahiam. I'm a security SA with AWS and I'm with my colleague Arthur today. So with that said, let's get started, OK? So, as I said earlier on, what we want to do today is really highlight what the recommended steps of the best practices where you should implement um authorization when it comes to your identities. But before we get started, we want to set level set on some basic definitions, right, on what you should think about when you're thinking about authorization and authentication when it comes to AWS. So, Um, we have a concept at AWS where we have the control plane and then the data plane, right? So the control plane is where, um, you get to say, can I, can I launch an EC2 instance, right? Or can I launch and create an SD bucket? And in this space, we have really well-defined patterns on access control to say who can authorize what, who can have access to what resource and who can actually create a resource and other things like that. And when we get a data plan, it really focuses on how your applications would interact with data. So in the example I gave in the control plane where we have your ACT instance, let's say it's gonna be, you have an application that wants to have access to your SD bucket to read or put something in your SD bucket. How do we really control access when it comes to this space, right? And it even becomes more crucial when you talk about generative AI, right? Because we have a generative AI having access to various amounts of data. So what we really want to focus here today is to really level set on the best way to really authorize when it comes to getting your generative AI to have access to your data, OK? So, We have recommended practices, and we want you to think about implementing something we call ze trust when it comes to authenticating and authorizing your users. And geo trust does mean different things to different people, but AWS we really start with this question that what will be the optimal way or pattern? To um to introduce security and availability to our systems. So we think of rust as a a security model where we are going beyond the network parameters and just checking for IP address to see who, where you're coming from to access a resource. Or we introduce other layers like identity, asking you, who are you and where are you from and what can you access, right? So having that kind of difference in depth and layers is what we want to think about. So today we really want to focus on the identity part. And this is also very integral when we talk about Gen AI because when we think of Gen AI, there are two things. The natural language part of Gen AI, right? So sometimes we think that because it's a natural language um system, we can say who can have um authority to access this kind of data. But we don't want you to think of Gen AI in that space. It shines in other areas, but we want you to absolutely leave out authorization to a deterministic factor when it comes to Gen AI. I want you to think about how you can implement Xero trust to be able to do the authorization of education towards your GI applications. So when we come together to put all of this framework, we see that we are actually authorizing at each layer from the edge to the perimeter, all the way to the resource. And when we do this, we always make sure that we are asking at each point in time, who are you and what can you access, right? We don't fall on past authentication to give access to, to a user or to um different kind of identity. So really implementing this ensures that we are having that kind of defense in depth nature throughout the full cycle of your um Ubius authentication authorization in AWS. So, one thing we want you to do is to think about how we can apply this zero trust concept to general application design and what will be when you're translating into the practical architecture form, right? And that's what you're going to really spend today thinking about and talking about. OK. So before we actually go on to think about um how do we do Authorization for our gen applications. There are fundamentals that we want to set in place, right? And to get a fundamental set, I want you to think about this scenario, right? We are continuously revolutionizing and we are creating new things. So imagine you create um a state of the art identification access management um platform, right? And then it gives you 85% probability when it comes to authorization concepts. How many of us are going to buy that kind of device for authorization? Probably none of us, right? We always want to make sure that when it comes to authorization, we are using a deterministic factor that 100% of the time we can rely on the authorization contract that is coming in. So then when we want to do this, JR is not the place to do authorization. Then because of this nondeterministic nature, right? Because if we do that, we are going to be getting 85% chance that the authorization concept is right. And we don't want to do that. So we want to think about leaving, sorry. We want to think about leaving their authorization to deterministic factors. Things that would 100% surely come back to say that Lily is authorized to perform this action or to perform this function. And with that said, we want you to think about really taking one thing from this talk that when you're thinking of identification, do it around your gen application and not from your Gen application. That's one thing I want you to really take away today that when you're thinking of authorizing you and authorizing access to your data, it always should be from, not from your gender application, it should be around your gender application. And Arthur's gonna really go into depth about how we can apply this concept in your architecture design for H&A applications. Thanks, Lily. Right. Good afternoon everyone. So my name is Awesome, and I have just a quick intro here. I'm a security specialist to say in the same team where Lily is. Um, today is my 7th year at A. So been here for a while. So what I wanted to do is, uh, Lily talked about the dos and don'ts, and that absolutely makes sense. So if you take nothing away from today's session, take the previous slide, uh, don't let your agenda I don't give it the authority to make security decisions on your behalf. But the other component there was the zero trust, right, and the session title is about managing digital identity and all of a sudden we're talking about the zero trust. So where is the connection? And what some of the components of zero trust that we need to remember is that 10 trust is not a service. You can't buy it. There's a you can't, uh, click it's a tick box within the console. This is something that you have to weave into your application from the ground up. Uh, similarly to how you develop your GNAI applications, you've got your development tools on one side, you've got your SAS applications on the other side, maybe A28 somewhere, MCP tools, so highly, highly distributed components, similar to how you build the rest of the universe. That's, that's one section. The other one is with zero trust you no longer depend on the perimeter control as being the sole barrier between your valuables and the rest of the universe. So you're now adding identity into it and the conception and the conceptual part here is that on with zero trust and you hear, you see this diagram here which is similar to what Lily showed before, the one before was. A generic version. So here's what we think XeroTrust is. This is kind of a GAI specific implementation of it. So Partly here what we have is we have the edge perimeter application. We got the orchestration and the data tools and all of these layers are in between your requester and somebody getting access to your valuables, which is all the way in the end of the line there. One of the things that you see here that's common across most of these components is the deterministic deterministic control set. And hopefully with a shared context, the one thing that's not here for deter deterministic control is that large language model box which is completely isolated. Why? Because we don't give or we don't want to give agency to your LLMs to make security decisions for you, so we're kind of removing it from the from the controls that let other components like Phil said build around around your GII GAI. Uh, the other element here why we're looking at zero trust is passing over the credentials, right? So we're talking about you're no longer dependent on deterministic on network network controls. You're now also you, you're using the identity. You're passing identity credentials from one stage to the next, and within the zero trust world, the best of the two is not a binary choice whether you use identity or network controls, it's when you use both of them together. Now, some of the places where it, uh, where it comes in is how do you authenticate and how do you authorize access to each one of these boxes because none of them. Trust one another. There is no implicit trust that if I'm at the box number 2 that I came through the particular age. So box number 2 treats it as an unauthenticated request. So how do you do this? Well, this is AWS conference, so I'll do a quick plug. So we do have verified access, um, and verified permissions. So and we have verified the access verified permissions, and verified access is great for the edge. And it's a system that uh that authenticates you before you come through. So there's kind of an implicit notion of those two controls, the who and the what and where also working together. The other one is, uh, verified permissions. Um, has anybody seen this just by the show of hands? Anybody, has anybody worked? OK, some the verified permissions allows you to offload your authentication. Uh, uh, your authorization decisions onto an external service within AWS, right? So verified permissions separate service you, uh, you generate the policy in there. You offer you ask it the questions this user authorized and you move on. The idea here though is that in every one of these boxes you perform those functions, every call, every data fetch. You uh you pre-authorized before and then what that leads to is you can now combine data and logs from the systems because now they're sharing sharing a security uh sharing the same secure context security context. They're using the same or similar systems on verified access verified permissions in terms of policy management. You're now combining those logs you're pulling them together, and now your analytics and your security operations center or your spons or however you monitor your apps, they now pull all this together and they can work out the entire session, the entire thread thread how system works. Right, and that's kind of the opinionated guidance from AWB. Uh, these, um, this presentation will be available online afterwards. There was, uh, there will also be a recording of it on YouTube if you wanna listen to it. So going through some of the components, the, the one that you've seen on the screen, and then we'll go through the entire application flow. So for the first one is the actor that's your application, your user, that's your service, and uh that actor is requesting. To interact with your application, right? So the identity at that point might already be known or it might be. Or it might be just a blank there a brand new session. Depending on that, you're, you're going over to the edge. Depending on the tool set that you're using in there, you could use things if you use, for example, verified access verified access will request the authentication, uh, authentication process that will send you off to whatever the trusted entity is, get the authentication credentials, get the token, and then pass the, pass the token over to the. To the uh to the endpoint, the endpoint will authorize access and then route you to the back end of your application. So right there out of the gates, you now have the identity, you now know how to manage this. And then You get to your application. Well, you verified access allowed you through the gates. Your application now takes the same token not being passed over, validates whether the user has the permission to access the app. And so that's, that's your other, uh, section. Then on the then you get You interact with your application. Your uh your planner now kind of comes into play. You send a query, you chat with your documents as the, uh, whatever the functionality is. At that point, the planner needs to be aware of what could potentially use and what other services. So imagine the setup where you have multiple agents, you have a central planning agent, you have multiple agents coming out of it. Those multiple agents, one of them is, for example, get financial information, the other one, create a new insurance plan. Well, you might be allowed as a uh as a human agent you might be allowed to create to go in and create a new insurance plan, but you can't see the financials. So sending the workload over to the financial agent is kind of pointless because all you will get back is a deny action because remember you're passing your credentials with it and the agent will go out and refuse or refuse work because you don't have access. So if a planner has an understanding as to what the permissions are, it will let you scope down, uh, scope down your work and just not generate additional workload on your system. The conditional access and that's where really things begin to get interesting because now your agent just received the work. You need to go out, you need to check whether you can go and get the data 1st and 1st and foremost. So imagine that you're the back end for your error for your agent is a database. Your reads out of your database are limited to what the user security permissions are. So if author is not authorized to read full table, then you never read the full table. You never return more than what you you want LLM to see. Why? anchoring back as to what Lilly was talking about. If if your foundation, if your model has seen data, you can structure the problem. You can rely on the, on LLMs to simply Follow your deny, deny command. Deny is not a, is not a good security control. Deny within the prompt is not security control. And then tool invocation, right, so we've got, uh, we've got the garden variety of different methods now and all of these are evolving. We have, uh, the, uh, we have regular databases, we have MCP MCP tools, and you can authenticate today to an MCP server, but the authentication between the MCP server and downstream tools, it's still kind of in drafts and. Proposal stages, so all of that is currently evolving, but the idea here is that the tool that shows uh the the as you pass identity to the tool, you don't let the tool do more than the identity is permitted to do. Right. And then this kind of loops around because a tool, a tool could be an agent of its own, and then you just restart the entire cycle. So what I'm going to do now is I'm going to walk through the application flow, kind of see where are some of the places where you, what are the right places to authenticate. So we've got the user, we've got the edge, and then here I have two components. I have cloud front and verified access. Again, this is AWS conference. I'm using AWS tool sets, but the archi from the architectural standpoint of view. It's something on the edge that filters out the bad stuff. And if that's something that's on the edge that can filter out bad stuff can also do that within the context and understanding of your identity, like verify uh verified the access cam, so much the better. Uh, so we validated that, so that's step number 1. Step #2, we pass this over to our application. So they have uh so application now checks whether this user is even permitted to access uh access the app. And let's let's say the answers to that is yes and it potentially uses the identity services underneath and we talk about identity and access management, AVP is Amazon verified uh permissions, whatever the tool is, it goes out, it validates, is the current set of credentials permitted to access data. Assume that it is, it goes into the orchestration phase and at that point we have one agent in here could be more, but the principle is the same. It now it takes those credentials. It takes the prompt and it supplies those uh those to uh, to an agent. An agent in turn says alright, well, is this. If you're using bedrock, that probably would be a lambda function. Uh, but if you use other agents, whatever the mechanism is therein, the agent goes back to its knowledge base. Now knowledge base, some of them support native authentication. In some cases it might be the MMIDB table. In some cases it might be a SQL server. In other cases it might be a rag. So depending on what the knowledge base is, the agent at that point interacting with the knowledge base needs to have a contextual understanding as in how to pass permissions and how to retrieve data only. That this specific user is allowed to see if I'm passing off tokens through on the front and all of a sudden you're using different type of a security system in the back there needs to be a mapping process within the agent. Then following up, the MCP those same same idea as the knowledge base except it's more complicated knowledge base, you retrieve those they retrieve those dynamically uh those um yellowish check boxes, that means. There is kind of work going on as in how uh those tools get the credentials over down to downstream. And then finally, And whenever all of this data is available and it returns to the agent, you send this off to the foundation model. And at that point, the foundation model now acts with the query that with the, with the original prompt and the available data, it pushes those two together. And gets you the right answer, right? And that, uh, and the stuff that you return back. Right, so again, all of this is going to be available on the web after we're done, but the idea here is that you never that red box over there, if you get to the red box where you're sending data over to your foundation model and that if at that point you need to be able to say return only a subset because a user is not authorized, you're this is too late in the process. Right, and then kind of the take home cheat sheet as in what are, what are some of the, uh, some of the things to do, right, so it's designing designed with zero trust in mind. zero trust is a good security model. It assumes that the application is distributed, right? and. If you think about the zero trust, uh, conversation, where did it come from? We used to build houses and 4 walls, and we used to put all of those and that's your perimeter control, put all of our valuables in there, and then close the door. Well, today it no longer works because your valuables are no longer, they no longer fit inside the house. You've got a a data center application. You got a sal application. You've got an A2A agent sitting somewhere else. You've got an IOT device sitting somewhere else. So Xero Trust assumes that the application is highly distributed, which fits very well in the, in the context of the Agenta Agentech workload. ZeroTrust is also designed. in such a way that no, uh, none of the individual components trust another, right? They don't trust another one. They never have an implicit trust. Yeah, this is the, this is kind of the where you want to be, right? And then use LOM as a planner. Use LLM as a formatter. Do not give your foundational models the agency to control your security. On that note, thank you very much and um will be available off the side here. OK.
