# AWS re:Inforce 2025 -Secure agentic AI: Mitigate risk in autonomous decision-making systems (NTA126)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=1USS4qwx8WA)

## Video Information
- **Author:** AWS Events
- **Duration:** 10.0 minutes
- **Word Count:** 1,631 words
- **Publish Date:** 20250619
- **Video ID:** 1USS4qwx8WA

## Summary
This brief session focused on securing agentic AI systems that can autonomously make decisions and take actions. The presentation demonstrated a serverless architecture using AWS services to mitigate three key threats: tool misuse, privilege compromise, and repudiation/traceability issues. A live demo showed how to build secure agentic AI workflows with proper input validation, access controls, and comprehensive logging.

## Key Points
- **Three Key Threats**: Tool misuse (attackers manipulating agents), privilege compromise (exploiting access weaknesses), repudiation/traceability (difficult to trace agent actions)
- **AWS Security Stack**: API Gateway for request authorization, IAM for permission management, Lambda for orchestration, Bedrock with guardrails
- **Multi-Layer Defense**: Lambda input validation, Bedrock guardrails for prompt injection protection, IAM least privilege access
- **Agentic AI Capabilities**: Autonomous systems that can access tools and parse internet data in real-time, unlike traditional AI
- **Usage Plan Protection**: API Gateway usage plans with rate limiting (10 requests/second) and API key identification
- **Guardrails Validation**: Bedrock guardrails provide input/output validation and prompt injection attack prevention
- **Comprehensive Logging**: CloudTrail for API activity tracking, CloudWatch for monitoring and alerting across all services

## Technical Details
- **Architecture Components**: Application → API Gateway → Lambda orchestration → Bedrock guardrails → Bedrock agent → Lambda execution tool
- **Input Validation**: Query length limits, IP address logging, content filtering in orchestration Lambda
- **IAM Policy Restrictions**: Limited actions including guardrail application, model invocation, and execution profile access
- **Execution Lambda**: Dedicated function for internet parsing capabilities with restricted permissions
- **Monitoring Stack**: CloudWatch dashboards for API Gateway latency, request metrics, Lambda invocations with configurable alarms
- **Security Boundaries**: Each service follows least privilege principle with specific IAM roles and policies
- **Workshop Resources**: Hands-on Bedrock agents workshop and AWS Solutions Architect guidance for agentic AI design patterns

## Full Transcript

Hi everyone, how are you all doing? Good evening. Welcome to Philadelphia. I am super excited to spend the next few minutes with you all here at Room Force 2025. Uh, please raise your hand if you've heard of Agentech AI. I'm sure you've all have heard a little bit about it so far, right? Uh, so for this session in the next few minutes we're really gonna dive into how we can use AWS to mitigate some of the threats that we have recognized with tool-based systems. So this will be our agenda for the next few minutes. I wanna start by recognizing a few customer challenges that we've noticed when implementing implementing agentic AI systems. We'll review a recommended solution and best practices for mitigating some threats. We'll review a solution architecture behind the solution. We'll walk through a demo of the solution and we'll review the outcome as well and takeaways, and then we'll talk about next steps for you all. So agentic AI here we're talking about enhancing the capabilities of large language models. We're talking about autonomous systems that can make decisions and take actions to perform tasks without human intervention. So there's 3 key threats that I want to recognize to you today. The first being tool misuse. So this is the idea that attackers can manipulate agents to actually misuse their tools. The second threat I wanna recognize for you today. Is privilege compromised, so the idea that attackers can actually exploit weaknesses and privilege management and then lastly repudiation and traceability. So the fact that maybe these agents can actually reject an idea that is given to them or these actions of agents are difficult to trace and log. And of course security is top priority at AWS, so let's dive into how we can use AWS services to help defend against these threats. I first want to introduce to you 6 key services, the first being API gateway. So this is our service that helps you securely build and deploy APIs on AWS. The way we will be seeing this used here is request authorization through the usage plan capability of API gateway. Secondly, we have IAM or identity and Access Management Service. So this is what we be using for permission management for both services and users. Thirdly, we have Lambda, which is our serverless compute service. And then fourthly, Amazon Bedrock, the easiest way to scale to create scalable generative AI applications. In particular, we're gonna be looking at bedrock guardrails. So this is the feature of Bedrock that allows us to configure safeguards in the interest of responsible AI for both input and output validation. And then lastly we talked about untraceability being a concern and a challenge customers are facing, so of course we'll dive into cloudwatch and cloud trail for logging and monitoring. This is our architecture we'll be taking a look at. So we're gonna be taking a look at a sample application starting here on the left. So this could be any application that invokes an agent. It could be front end or back end. So our app invokes an agent and then API gateway allows us for the application to interface with our infrastructure. And then here we're using AWS Lambda as an orchestration, so it's actually handling the uh incoming prompt or query from the user that's coming through API gateway and then it's sending it first Bedrock guardrails. So Guardrail is actually gonna do some content validation for both input and output, and then it sends that request to the agent in Bedrock. That agent has access to a lambda function that actually executes a tool and then in this context of the demo we'll see it's actually parsing the internet and has connectivity. All along we're using AWSS IEM to give these services, uh, least privileged access to each other to perform these actions and then cloud rill and cloudwatch for visibility. Now we're gonna dive into the demo. So this is a sample application here we're gonna want to start by asking it um just what are some new features or new analysis from AWS. The key difference I wanna point out to you here is how it's acting differently than how a traditional AI application would. So a traditional app wouldn't be able to give us the current or correct information because it doesn't have Internet connectivity. But because this application is agenttic, it's actually going out and parsing the internet to retrieve the answers for us, and we can actually validate this by going to the website itself and seeing that it's giving us the most up to-date information. So now that we see how our sample application works, let's go and dive into the back end and see how this, uh, work flow works. So first, the request comes in through API gateway. How we're using API gateway to protect our application is via the usage plan. You can think of the usage plan as a contract between yourself as the API provider and your client or user as the API consumer. So usage plans allow us to set limit rates. Here we have 10 requests per second. And actually associate an API key. so every request being made to the API is able to be uniquely identified. So now we are diving into our lambda function. So our lambda function is doing two different things. It's doing some input validation. uh, here, for example, the query length max. Some IP address logging. And then it's actually sending this request to our bedrock agent. So now we're here in Bedrock. Remember we talked about guardrails, so these are safeguards, uh, that are put in place, fully managed for both input and output validation. So we have that first line of defense with lambda guardrails our second line of defense, specifically a prompt injection attack. We're using the prompt injection guardrail. So let's say we're pretending we're to be a malicious actor. We wanna tell the agent to misuse its tool access. And our guard rail was able to effectively block against that attack. And remember we talked about IAM so IM is what is allowing us to actually restrict the access that the agent has to begin with. So if we dive into the IAM policy that's attached to this agent. We see that it only has limited actions, for example, being able to apply the guard rail, invoke the model and the entrance profile, for example, and then lastly, the lambda function. If you notice, the lambda function is actually the execution tool. So remember our first one was what orchestrates the entire workflow and does some content validation. Our second lambda function here is actually built to allow the agent to go parse the Internet, so that's our execution lambda. And our third challenge we talked about was traceability. So this is where we really want to dive into cloud watch and cloud trail for monitoring. We're gonna navigate to a few cloudwatch logs here. We're using cloud trail to track. API activity here and for our two lambda functions as well. So it's not just for API gateway and the calls made to the API that we created, or excuse me, within the account but also for the ones that we created for the API. And then in cloudwatch we have some dashboards here as well. We can take a look at things like API gateway latency, the requests coming in. Lambda invocations as well, giving us full visibility and monitoring into our agentic AI application. We can even set alarms with cloudwatch. So say there was to be um a number of server side errors here, we could set an action there, for example, we can get a notification or even have it set to do remediation actions. So this concludes our demo for today. Let's review the outcome that we saw just now. So we were able to address those three challenges our customers are seeing by creating a serverless and secure Agente AI workflow using Lambda. And then we saw inputs and outputs being validated, so we saw that first line of defense with our orchestration lambda function when that query came in it was checking for the query length it was checking for, um, where the IP address was being called from. And then with our bedrock guard rail for prompt injection, it was also checking the input and on top of that the output that the model was giving from the agent. Lastly, we were following best practices with access management with identity access management and API gateway with that usage plan we saw here. And most importantly to address untraceability challenges, we use cloudwatch and cloud trail for each to make sure that each step is traced and logged from the very first moment that that query is sent to our application to the final output from our agent. I want to share some resources for you all on getting started with securing and uh securing agenttic AI applications. On the left we do have a workshop available if you wanna get some hands on experience, step by step walking through Bedrock agents. And then on the right we have some guidance built by AWSS Solutions architects when it comes to building Agente AI applications, some design patterns and things you should consider. I really hope you enjoyed this session. Uh, please go ahead and make sure to fill out the survey and see how we can improve. If you have any questions or wanna continue the conversation, let me know. I'll be hanging around over here by the theater. Thank you so much have a great night.
