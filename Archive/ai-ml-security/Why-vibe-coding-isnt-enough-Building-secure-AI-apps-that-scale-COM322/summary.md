# AWS re:Inforce 2025 - Why vibe coding isn’t enough: Building secure AI apps that scale (COM322)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=0ANFTzktNXA)

## Video Information
- **Author:** AWS Events
- **Duration:** 20.2 minutes
- **Word Count:** 4,497 words
- **Publish Date:** 20250620
- **Video ID:** 0ANFTzktNXA

## Summary
This session demonstrates how to evolve AI applications from quick "vibe coding" prototypes to production-ready, secure systems that can scale to millions of users. Brian Huff shows the dramatic difference between AI-generated apps that appear functional but lack security, scalability, and production readiness versus properly architected applications built with AWS services. The presentation covers a comprehensive "shift development left" approach that transforms prompt-to-deploy workflows into robust, secure, and scalable applications using containerization, infrastructure as code, and automated security practices.

## Key Points
- "Vibe coding" (prompt-and-deploy AI development) creates apps with hidden vulnerabilities, no authentication, poor scalability, and security risks that only become apparent at scale
- Always design applications thinking "are you prepared for a million users?" rather than building for just 10 users to ensure proper architecture from the start
- Amazon Q can automatically fix security vulnerabilities in AI-generated code, reducing 6 package vulnerabilities to zero with simple prompts and dependency updates
- AWS CDK with Python/TypeScript enables infrastructure-as-code that automatically configures resilient, multi-AZ architectures with proper networking and security controls
- Production AI applications require a complete stack: Cognito for auth, API Gateway for streaming, EKS for container orchestration, CloudFront for CDN with Shield/WAF protection
- Containerized RAG (Retrieval Augmented Generation) architecture uses S3 for file storage, Bedrock knowledge base, and OpenSearch for vector embeddings with secure file processing
- GuardDuty malware protection for S3 prevents infected files from reaching production by scanning uploads and quarantining threats automatically
- Rate limiting and token tracking prevent "denial of wallet" attacks where users exploit unlimited AI generation capabilities at the company's expense

## Technical Details
- Complete production stack includes: EKS clusters, CloudFront CDN, DynamoDB, OpenSearch Service, S3 with pre-signed URLs, and Lambda for event processing
- CDK deployment strategy uses multiple stacks where outputs from one stack become inputs to another (EKS → CloudFront → OpenSearch → Bedrock knowledge base)
- Security implementation includes: zero-trust architecture, AWS Shield Advanced for DDoS protection, WAF rules, SSL termination, and VPC isolation
- File upload security workflow: pre-signed URL → upload bucket → GuardDuty scan → safe files to production bucket → quarantine infected files with alerts
- EventBridge automation triggers knowledge base sync when files are uploaded to S3, maintaining consistency between file storage and vector embeddings
- Container architecture separates public-facing Next.js app from private FastAPI server, with EKS managing both workloads within the same VPC
- Monitoring and logging through CloudWatch, CloudTrail, and EventBridge provides real-time visibility into user interactions and API usage patterns
- GitHub integration with Amazon Q provides automated PR code reviews and security scanning as part of the development workflow

## Full Transcript

All right, everybody, welcome to CO 322. This is why vibe coding isn't enough and how to build secure AI applications that scale. So thanks everybody for coming. OK, so you know the drill. I wanna build an app that lets me talk to my documents and I want to be able to upload PDFs these PDFs and talk to them. So it's gonna be thinking for a little bit. And it looks pretty cool. So now we can drag and drop files that'll upload right to our application. So it's pretty sweet, but I want a list of my documents. I wanna be able to see the most recent ones, so can we add that? So just gonna think for a little bit more and now we have a list of our documents. So this is all ordered, it has all the data about it, pretty cool. Now what about a list of my most recent conversations? I wanna be talking to these documents. I wanna have some data. I wanna be able to track all that. It's gonna be thinking a little bit more. And now it comes up with this, so pretty slick being able to just have all these chat histories right in my app. Now this is a cybersecurity conference, right? So we need authentication and authorization so let's add a log in. It's gonna think for a bit. Got a login page. Now one last question, can we add an analytics dashboard, you know, make it more visual, make DUI pop? It's gonna think for a bit They got a dashboard so kinda cool it's a graph you can go over it looks really fun. OK, last question, can we make a cool landing page? I feel like this could scale to millions of users and I want to go to market with this tomorrow. It's going to be thinking a little bit more. And now we've got a vibe coded app, it's ready for prime time, right? Not quite. So there's gonna be a lot of problems with this app that you would never know about. You would never know that these problems occur. It's one of those if you know, you know, do we have zero trust architecture? Probably not. Do we have insecure dependencies? We probably do. DOS and attack protections for spam and bots? Probably not. Rate limits in spam? No. We have poor scalability design patterns, no authentication, authorization, or it's probably very low and. If users upload malware, is that gonna attack the rest of the application? There's a lot of problems that come from vibe coded applications that you'd never know about unless you built it. And this is the number one question that I always encourage anyone to build is that are you prepared for a million users? You should always build something and think about the maximum amount of impact that you could have from it. I always get excited about building. I'm a self-taught engineer, so I always think about like how many people could this impact. So you wanna think about this. You don't want to think about like building an app for like 10 users. I wanna build an app for like a million people. So how do we, how do we think about that? How do we build for that? So my name is Brian Huff. I am an 8 of us devtools hero. I used to be an 8 of SUNY builder and I'm a full size software engineer, but I didn't actually go to school for this. I got excited about tech and I ended up teaching myself over the pandemic how to learn how to code, and I love empowering other people to build software, but we're gonna get into like the nitty gritty today of how to actually productionize vibe coded workloads. So it's gonna be like building apps the hard way. So I always encourage people of like if something feels intimidating like. You know, it, it might be a little bit confusing, but I tell you it's possible and it's really fun to be able to build apps like this. So Jennifer, today we're gonna enter the vibe code era. So we are in this era we have to acknowledge that we are in the era of vibes. So to deal with this we're gonna learn how to shift development left and I learned a concept last year about shifting security left, but I want us to even think more about how to shift development left. We're then gonna build a real Gen AI application kind of like what you just saw earlier. And then we're gonna build a playbook so that you can go to production with this type of workload. So this is what we're gonna talk about over the course of today. So we're gonna enter the vibe coding era. So what does that look like? So we're building software, we're going really fast, so we're doing zero shot prompts, we're using the tools and technologies, all the cool stuff we're doing upfront planning, you know, and then Gen AI low code no code stuff, right? So prompt deploy, this is the strategy and you're just prompt deploy recursively until you get the app that you want. So that's kind of like how vibe coding works. Now there's gonna be about 4 of these types of tools that you might use or you might work with so the invisible infrastructure is like I don't wanna think about servers. I don't wanna think about all the complicated stuff, help me build my my system. Then you have the Gen AI builders that are like, I, I want you to build the complicated stuff so that I don't have to. The plug and play back ends you might just need off, you might need data, you might need functions, you might need certain usability patterns so you can just integrate that into your app. And then the low code no code builders, those are the fun ones that's what we're gonna talk about so that's where it's like prompt, build an application and make it work. Now the vibe coding pipeline is prompt and then deployed. You probably already know this, but it's important to think about. What I want us to think about is shifting development left. So what that means is that it might start with a prompt. We're in the vibe coding era, so we have to acknowledge that like things might start off as a prompt, but it doesn't have to end the prompt. We want to do scanning over all the code that it generates. We want to then go and build. We're gonna, that's really important because we want to take the prompt, turn it into an actual architecture and build it. We want to automate some of these processes. So it's all programmatic, it's all deterministic, it's not expected to chance we wanna review our code before it reaches our users, right? We wanna test stuff and then we deploy so you can see that there is quite a lot of steps that can happen that prompting ignores and it ignores it because it tries to make it easy, but building these types of software that shouldn't be that easy. We want tools to help us with these patterns. So how do we productionize the vibes? So that's what we're gonna talk about. So these are all different patterns that I'm sure you all know about authentication, API, using LLMs. This is not new to all of you. I know that. But how do you take that and turn that into a productionized workload? This is gonna be the stack of tools that from AWS can really help you a lot. So Cognito for authentication, ASync for API, API gateway if you want to do streaming, S3 for file storage, Bedrock for LLMs, um. Then it gets, then it gets fun. So if you want to distribute this workload, we're gonna containerize our applications we're gonna put it on EKS, which is a Kubernetes orchestrator. We're then gonna put that in front of Cloudfront or behind cloud front so we can distribute our application to more people. Dynamo DB for a fast readable database and then open or Amazon OpenSearch service for our vector DB. So all these parts are gonna work together. We're gonna see how to build a software with all of this together. This is the builder tool kit that helps me a lot and I really build just with Python and TypeScript. GraphQL if you're building APIs, it's really able like great to be able to just make queries, mutations, all that stuff. Then Docker Kubernetes and AWS CDK if you can master these types of frameworks in these programming languages, you can build like 80 to 90% of all software. So that's kind of where like it kind of starts with just this. You can build a lot of stuff on it. So this is the big question that we have to first of all ask is our application secure? So we're gonna start off with the front end that's what we downloaded from our vibe coded app. So Gen AI can lead to a lot of bloat if you've ever used Gen AI platforms, they're gonna install a whole bunch of packages, a whole bunch of code you probably don't need. They're probably using outdated packages and if you do MPM audit and actually see what it did, it might create an app with a lot of vulnerabilities. So this one has 6, but you might have one that has more. So you would never know this. This app is fine. You'd be able to actually. Put that on the web, but you shouldn't because you're gonna be exposing users to a lot of vulnerabilities that list of 6 might become 10 or 20 down the road. So securing the app, this is why we need to get rid of the bloat. We need to get out of the outdated packages. So how do we do that? So we're gonna use Amazon Q and this is actually a real use case. This is real stuff that I did and I thought it was really cool. So this is the Amazon Q VS code extension. If you open it up and you go to the package. JSON, you can actually do that and that's on the right you can send it to prompt and I actually took this and I asked Q and I said, Hey, there's these 6 vulnerabilities. Can you help me address them? It was able to then take all of the updates that were needed and it returned basically no vulnerabilities. So I was able to basically take 6 vulnerabilities and then turn that to 0 just by doing that one thing super, super simple, but it was really easy because I've done, I've worked with like you know you migrate up to this, you update something and then now you have to do like NPM like force fix and all that stuff so you don't need to do that it just updated it for me so really easy way to just add security. Now we want to make sure that the infrastructure is scalable and that we can build and then deploy that. So now we're gonna go to the back end. So if you've ever used CDK or maybe you haven't, it's really easy to get started. You could use Python or TypeScript. I use Python for this as an example. So you're going to do CDK in an app. You're then going to activate the virtual environment, and then you're going to install all the dependencies. So this is just like an easy way to just get started building the app, the repository for your back end. Now this is a CDK template, so that's the virtual environment that we're gonna activate. All of our stacks are gonna go in here. So if you see me say like CDK deploy something, that file is gonna live in there. Then we have the test framework, we have the app entry point. We're gonna import all of those stacks into the app.ie file, and that's where we'll be able to do CDK deploy X. Then configuration of metadata, dependency management, helper scripts. You don't need to really worry about those other things. It's mainly app and then the um the main stack definition folder. So. This is basically how to get started with the CDK. So you're gonna CDK bootstrap your environment. You're going to, and that needs to happen per account that you deployed to. It just needs to happen once and then you synthesize the AWS cloud formation template with CDK synth, and then you're gonna do CDK deploy. I have CDK bootstrap down there just to remind you that if you do ever try to do CDK deployed, it doesn't work. It's probably because you didn't do CDK bootstraps. That's why it's there. But then after that you're gonna do CDK deploy. This is basically our app. We want our user that's authenticated to talk to our app build, and then the app build is able to talk to our fast API server. So we're using NextGS for the app, fast API for the server, both of those distributed through Coopernettis. That's what it looks like and this is just a part of it, and that's kind of where there's like a lot happening behind the scenes. So we're gonna walk through all these parts and it'll seem a little less intimidating, but that's kind of where you have multiple EKS clusters that can talk to each other and there's a lot going on. So let's deploy the app. We want to start off. We have our front end application and it looks really cool. It's our Talk with documents app. We're gonna put that on Amazon ECR, which is the container registry, and it's really easy. You just create a Docker file that looks like this, and then you could build it either with a CICD pipeline or you could just do it locally. Um, if you do it with a CIC pipeline, you're just gonna need that IMOIDC roll and then that will auto build it. Once that's a container and that's in the cloud, we can now take that container and put it on EKS. So EKS with CDK makes it so easy you can literally define on the right so like. 14 you can do max availability zones is 2 that creates resilient architecture like what you'd expect. You can provision everything within a single VPC, lock it all down. So CDK makes it super easy, so you don't need to worry about all these other configurations. CDK will just do that for you. So we're gonna then add a load balancer so that's gonna help us fan out when users are trying to get requests to our server or our app is talking to our server. We wanna make sure that things don't crash and that it it can expand. So CDK handles all the IM stuff, adds the load balancer in there, and just kind of configures everything for you, makes it really easy. So what we're basically gonna have is we're gonna do CDK deploy EKS stack. That's gonna create EKS. That's gonna create availability zone number 1. That's gonna create availability zone number 2. And inside of that we have EC2, and that's going to help deploy our service workers with the Kubernetes pods. Then we're gonna add elastic load balancing there and then this is distributed completely through CDK. So we just update CDK, we'll update the stack, makes it super easy for us to get started with Kubernettis, so. Do we need a CDN? And the answer is yes, because the load balancer is just gonna do HTTP, but we wanna do HTTPS. We wanna do SSL termination. We want to do DOS protections. We want to add WOF. There's gonna be a lot of things that the content distribution network will be able to help us with. So that's cloud front. So what why this is cool is that we already deployed the EKS stack. We can take the outputs from the EKS stack, so some of that stuff might be like the DNS or you might store some things in parameter store, but you can take the outputs of that stack, put it into the cloud front stack, so we talked about having like multiple stacks, and then the outputs of one become the inputs of another one, and then we're able to deploy our cloud front distribution. So what this is gonna look like we do CDK deploy cloud front stack. We're gonna add a cloud front distribution, and now we can add Shield, we can addO, we can start productionizing and packaging our app and making it safe. And all of this is with programmatic code in Python. So now we're going to deploy the server. We're gonna do basically the same thing that we did with the app, except it's gonna be the Docker file is gonna be a little different because we're using fast API that's a Python server, but we're gonna basically build the container for that. Now we already deployed that EKS, which is the app. When we do CDK deploy EKS server stack that's gonna create the one on the right and that's a new server so now because they're all within the same VPC within the same cluster IP, the server can talk to the app and there's a secure link, but the server doesn't. Need to be exposed to the internet. We're going to need the app to be exposed to the internet because like users are going to go to the IP address or the URL, but the server needs to stay locked so only the app can talk to it. So it's a great way to just use CDK to lock down your infrastructure and your networking without needing to be a networking wizard. Now is our users' data secure? So a lot of logging doesn't happen with vibe coded apps, and this is why if you build on AWS you can have things like cloudwatch, cloud trail, and EventBridge that can help you track what's happening for your users around the clock. So let's say that a user use the app, they're using the API, they want to get some data from Dynamo DB we can actually start seeing that happen in AWS in real time, which is really helpful because then you get visibility across how your users are using your app. Now if we want to do containerized rag, which is what we're doing, that's retrieval augmented generation, that's how you can talk with your documents, um, the user will talk to the client. We're gonna authenticate. We're gonna talk to the API. We're gonna talk to the Dynamo DB database. We're gonna get some data about the file, some metadata, some information, and then we also can use API gateway that can be connected to our fast API server so that we can do streaming and that then is going to link up to the Amazon Bedrock knowledge base and that in turn is connected to our Amazon open search service vector store. So that's gonna store all the vector embeddings for each file as it gets uploaded. Now to deploy the vector store we're gonna create our own open search stack. You don't need to write all this down, but this is just like what the stack kind of looks like. We're gonna do CDK deploy open search stack, then we're gonna do the next one which is the Bedrock knowledge base stack. So we're gonna do CDK deploy knowledge based stack, and then once this becomes the input of that we can then deploy our architecture. So one of the things that also just like a little catch-22 is that when users upload files, this is kind of like what's gonna happen so you're gonna authenticate hit the API we're gonna talk to the server and we're gonna do pre-sign URL strategy so that it's securely uploaded to S3. Now to sync the knowledge base we're gonna need to use event bridge and that's going to basically say if you update, so basically if you upload or write a file to S3, kick off this event bridge, we're gonna use this lambda function and that's going to be. Basically doing an ingestion job to then go to the knowledge base and then update open search service so this is something that you can create and that will work just synchronously as things are working, but just something to look out for it to make sure that your knowledge base is synced up with how your users are updating their files. So we need to make sure that these files are also safe and not going to harm our platform and our users. So if a user uploads a file We don't really know like if that file's cool. What if there's a virus in it that could then basically infect your whole server that could infect other users because let's say that you upload a file and then other users use that file and their workloads or something like that well now they're infected so you need to think about that and not cause any issues because just because it's a file uploaded to the cloud doesn't mean it's safe. So the way that we're gonna do this is that we're going to upload this, um, you can use a lambda function, but in my build, um, I was using my EKS server, so either way, um, but then you'll get a pre-signed URL back that will then go up to S3 and that's just the upload bucket that's gonna kick off a job to Amazon Guard duty malware protection for S3. That's gonna determine if it's safe and then it'll be copied over to the production bucket. If it's not safe, it's gonna get deleted. It's going to then be quarantined and then that would also give us alerts to our system to let us know what's going on. So also are we tracking how our users use our applications so if you have users that have unfetterated access to APIs or any sort of other services or something like that, it can cause a lot of issues. Now why this becomes important is there's sort of an attack vector called denial of wallet. So where that becomes is that it could be one user it could be many users, but that user could ram your client. Now they're using your app like their own, you know, LLM of choice and now you're basically footing the bill for their own AI generations. So that's why you need to think about this of like. How do you make sure users can't invoke too many things? So two solutions here. One is track tokens, super easy way to just track the generations of tokens you say like, oh, you only have 10,000 tokens a day or something like that, but you can just make a function like it doesn't have to be that complicated. But it's really important with cost tracking so that users just can't exploit your system. The other part is rate limits. So that's another thing where if you just say like any time that they hit the API, just count up one, and then you say like oh they only have like 100 you know requests a day or something like that or 1000 or something like that. So automating the security process. One last component to just productionize this we can use Amazon Q kind of like what we learned about before, but Amazon Q developer in the PR process. So we'll set up. Amazon Q, when you push to GitHub like that, that's gonna kick off a web hook. IM is gonna hit Amazon Q and then we're gonna get back a response. So what that's gonna look like is you add Q to your repository and then you get these AI generated code reviews, which is pretty cool. And then also if there's issues with certain checks, Amazon Q could actually take action on that if you wanted to or just alert you that something's wrong. So We just went through a lot of stuff. It's kind of like a speed run in productionizing an application, but there's a lot of stuff to get through and only 20 minutes. So what does this mean? Our production or basically our productionized app is ready for production. It kind of looks a lot like what the app was before. However, our checklist now checks out. We have all of these green check marks as opposed to the kind of scary questions that we had at the beginning of the talk, and that's the thing where you can be rest assured knowing that your software that you deploy actually is deterministically. And perpetually secure and safe, you'll of course need to keep updating it over time, but these are things where like I love seeing green check marks. I don't know about you, but like I love seeing checks go and tests, and that's something where now we have our back. We have strong scaling design, we have zero trust architecture, and we know when we can validate this. We also have authentication and authorization enforcement and logging all the good stuff we want and malware protection, you know, we can scan our code. We have all these great parts of our application. So the productionized playbook is these 10 steps you only really need to think about these 10 things and then you can make sure that your application is scalable and that it's secure and if anybody asks you, you have a whole list of notes to actually validate that you did what you're supposed to do. So if you want to build this, I have 3 different repositories in this one repo it's like a monolith. So there's the CDK, there's theA API server, and then there is the next JS application. I highly encourage you to check this out so that you can start building your own AI applications, and it was really fun to build. This was like probably the most complicated build like I've ever done, um, so it was really fun. Like I learned a lot and I'm sure you will too, and if you have any feedback on it, I'd love to hear it. So thank you again for coming to my talk and I hope you are excited to build.
