# AWS re:Inforce 2025 - Use generative AI for business growth amid the regulatory landscape (GRC225)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=tD5Baie7nfk)

## Video Information
- **Author:** AWS Events
- **Duration:** 14.0 minutes
- **Word Count:** 2,076 words
- **Publish Date:** 20250620
- **Video ID:** tD5Baie7nfk

## Summary
This session explores the critical balance between innovation and responsibility in generative AI, providing a comprehensive guide to leveraging AI technologies while maintaining robust governance, security, and ethical standards. The presentation offers practical insights into managing AI development within complex regulatory landscapes.

## Key Points
- **Regulatory and Governance Landscape**
  - Existing standards and frameworks for AI governance
  - Importance of balancing innovation with responsible development
  - Multiple layers of regulations, compliance standards, and risk management frameworks

- **Responsible AI Dimensions**
  - Foundation of Trust: Privacy, Security, Governance
  - User Protection: Safety, Robustness
  - Responsible Design: Fairness, Explainability
  - User Empowerment: Controllability, Transparency

- **Key Challenges in AI Governance**
  - Complex permission management
  - Inconsistent documentation
  - Fragmented model performance monitoring
  - Maintaining compliance while maintaining development speed

- **Amazon SageMaker Solutions**
  - Role Manager: Simplify permission settings
  - Model Cards: Centralize documentation
  - Model Dashboard: Consolidated model performance monitoring
  - Model Registry: Comprehensive governance and audit trails

## Technical Details
- **Governance Tools**
  - Custom permission creation
  - Centralized model documentation
  - Performance monitoring
  - Audit trail maintenance

- **Responsible AI Practices**
  - Well-defined use cases
  - Diverse team development
  - Continuous risk assessment
  - Extensive testing
  - Clear governance policies

- **Regulatory Considerations**
  - Region-specific regulations
  - Compliance standards
  - Security frameworks
  - Threat mitigation guidance

**Key Takeaway**: Generative AI represents a transformative technology that requires careful, thoughtful implementation. Success depends on balancing innovative potential with robust governance, continuous learning, and a commitment to responsible development.

## Full Transcript

OK. Good morning, everyone. This is GRC 225 using generative AI for businesses within the regulatory landscape. Now before we start, I want to talk about fire. Yes, fire. Fire is one of the humanity's most earliest and most transformative discoveries. It illuminates our paths, it warms our homes, it sparks transformation. Well, today's generative AI capabilities holds that same transformative revolutionary power, but just like fire, we need to carefully handle it and respectfully harness it so that we can take its full potential. Today's session, gonna show you how to be both a fire starter and a fire keeper. How to spark that innovation while maintaining the guard rails that keeps that innovation safe and sustainable. My name is Tala Grete, and I'm a senior security consultant working with AWS Professional Services, and part of what I do is I help organizations master that delicate balance, turning regulatory requirements into uh from constraints into the very foundation of responsible AI. Our agenda is fairly simple. We have about 20 minutes to talk about these 4 points. We're gonna touch on current landscape. So what do we have in terms of standards and frameworks, and then some small slides on responsible AI. After that, we're gonna touch on 4 key challenges customers face within the governance and AIMLs face. Third section, we're going to discover Amazon Sage maker and 4 of its key tools that will help address these 4 challenges, and lastly, some practical steps and like QR codes for resources and how to move forward. Today's generative AI capabilities are transforming how businesses innovate. It is opening doors to to incredible possibilities across different industries, but with great power comes great responsibility. We're facing now new challenges around security, around privacy, around biasedness, around transference. So the key here is to have balance. We need to innovate boldly while also innovate responsibly. Good thing is we're not starting from scratch. We have lots of standards and frameworks that already have started for us the same route. Let's take a look. We have our baseline of generative AI services. Moving up, we have regulations. These are non-negotiable, constantly evolving, regions specific, country specific, territory specific regulations similar to the EU AI Act. On top of that, we have compliance standards. These are the standards that are satisfying businesses requirements. Here I've put the ISO suits. On top of that, we have security and risk management frameworks. So similar to NS RMF. On top of that threat mitigation guidance. So we have AWAS well architected framework. We have OAS top 10 for RLNs and so on. All of these are maintaining our governance structure, but I wanna take a step back and ask you a question. So if you look at these, which of these are generative AI specific standards and frameworks? So all of these are AI, but which are these specifically to generative AI? If you think about it, It's these, these are generative AI specific standards and frameworks. They are crucial to help us build our and deploy our AI workload within our environment. Alongside these, we have our AI dimensions that are, are on a responsible AI provided by AWS. So let me walk you through those. I split them into groups of two so that it's easier to explain. First, we have our foundation of trust. We have privacy and security and governance. Privacy and security is basically how we handle our data and models. Uh, governance ensures that we are implementing best practices across the entire AI supply chain. So building on that foundation, we have prioritized user protection by safety which prevents harmful output, outputs and misuse and dras and robustness. This ensures that systems are reliable even under unexpected conditions. OK, with these protection mechanisms in place, we now have to design our system responsibly. So. We have fairness, which basically you considering different impacts on different stakeholders and explainability. Are you able to understand why your systems are producing the outputs that it is producing? And then finally, We empower our users through effective system management by having controllability and this is basically mechanisms to guide and monitor your AI behavior and lastly, transparency so that you can have your users make informed decisions about either using your AI workloads or not. OK, we've now covered the first section. Moving on to the next one, on, on the 4 key challenges that customers might face within the AIML governance space. First is permission management. So before even uh you have a model, take a look at this workflow balloon. Before a model exists, you need to set permissions for data scientists to prepare the data to to select the data that is needed for, for your deployment, and then you need to give access to different machine learning engineers to build and deploy these models. Even the same team might require different permission levels across each step or stage of that workflow. So doing this on a manual basis, on a traditional basis, can get complex and harder to scale on larger organizations. Second, we have documentation challenges. So. Teams use different tools to document and track models. Information can become inconsistent and scattered. So when you try to find or share something, it can create unnecessary and some manual work. Our third challenge is monitoring model performance. Organizations do struggle with fragmented visibility across their entire models and how they are performing, so they go ahead and find their own proper monitoring, custom built ones. These also can get complex and also expensive. And our last challenge is governance and compliance controls. Maintaining these controls while also maintaining development speeds could get in the way. So you might have you might require comprehensive other trails. You might require a standardized processes. Well, good news thing. I'm gonna talk about Amazon Sage maker. Amazon Sage Maker has 4 key tools that will address these 4 challenges. So let's take a deeper step and go through them one by one. Our first challenge, as I mentioned earlier, permission permission set up can get complex. Each groups would require different levels of permissions. So traditional ways could be setting this manually and it could be time inclusive and could create bottlenecks when initiating a project, so. If you, if you've used this, then this is the great feature of Amazon Sage maker. The Amazon Sage maker role Manager, you can define custom permissions for sage maker users within minutes. Not just that, you can create custom policies based on your specific needs. OK, so the way it goes, I'm gonna do this. I'm gonna talk about this feature, the solution, and then I'm gonna summarize it in three key benefit points so that these are the three points that I want you to get out of this session. So if I wanted to sum the benefits of a sage maker role manager, I would say it would sim simplify your permissions for ML activities. So you have your, this guided process helps you consider all critical and necessary dimensions without overlooking critical aspects. It uses guided workflow for all creations and lastly, you can now define custom permissions for sage maker users not in weeks, not in months, but in minutes. This accelerates users on boarding and projects initiation. OK, moving on to our next challenge. Documentation. Currently ML practitioners are using different tools to document everything from business contacts to development decisions. So when it becomes time to have approval workflows or audits or even answering customer inquiries, finding the needed information can become like a treasure hunt. Our solution to this is to use Sage maker, Amazon Sage maker model cards. This transforms your experience by creating a single source of truth. It centralizes and standardizes your documentation throughout your entire ML life cycle. OK, so let's summarize the three key benefits I want you to walk away with. First, you standardize, you centralize your model documentation. This makes sure that you have consistency across your entire ML portfolio. Second, you have a single source of truth for all of your model behavior, so you have a better understanding for your use cases. And third, you can only access and share complete model information for approvals, for auditors, for stakeholder reviews within that to or feature. OK, our third challenge, our third challenge when it comes to model performance or monitoring that model performance, organizations face visibility issues. Most companies lack this consolidated view on their deployed models, making it difficult to detect bias or performance or drifts. So the solution here is to use Amazon Sage maker dashboard. All of your models, all of your models, you can audit them. And, and lineage their performance all in one place. So to sum up the benefits of the third feature, I would say you can view your and monitor all of your deployed models in one single place, eliminating the need for any custom solutions. You ensure that models are maintaining optimal performance and production. So when anything deviates from its original expectations, you can figure it out. And lastly, you can identify and address model drifts and anomalies in a few simple steps. Our last challenge is governance and compliance. So if you have ever heard of the regulations such as the Equal Credit Opportunity Act, so it requires employees and companies to explain their model decisions and then demonstrate the proper risk management, so organizations can spend months or even years trying to figure out which data is satisfactory for this regulation. The solution here is to use Amazon Sage maker model registry. It basically provides a central, single central repo for all of your model. It's like a single point of glass for that. It automatically logs and uh logs their approval workflows and maintains comprehensive audit trails for everything you do within your uh model performances. So, if I wanted to sum it up in three key benefits, I would say it maintains comprehensive model cards. It enables approval workflows to ensure that you have governed workflows. And lastly, you can manage model performances within centralized versioning within and share it across teams, across different environments. OK, I'm gonna take a step back. We've looked at our governance tool, but now I want to show you 6 key practices that you can learn how to build your generative AI responsibly. So we would start with having well-defined use cases. The better uh use cases are the ones that you are more specific and you narrow your focus to. You would have the better outcomes. Second, invest in your people. Prioritize education. Prioritize diversity teams that brings different perspectives into your AI development. Third, make your risk assessment a priority. Regular performances can help you stay ahead and figure out what kind of issues you will, uh, potentially face. This comes without saying test, test, test, and automatically and continuously test. It's not about functionality, it's more about safety. It's more about reliability. It's more about maintaining trust. This journey is not a straight line. You don't start and finish in a straight line. It's an iterative journey. So continuous performance across your AI life cycle is key to have your long term success and finally establish clear governance policies because these policies need to have both accountability and measurable outcomes. This was this was QI, so I want to talk about these resources that will help you get started. I've mentioned AI building AI responsibly, and I've mentioned the eight pillars that you have or dimensions that you have. You can find this first QR code to dive a little bit deeper and see how AWS does it and how you can implement it within your own organization. And then if you haven't started with Amazon SageMaker, this is the 2nd QR code you can get started and know the features that it offers and services it offers. And lastly, if you do ML ops, you have a specific QR code for that to help you get started with SageMaker for ML Ops. The usual you have the events up, so if you enjoyed this session, please uh rate this and give your feedback through this application and if you have any questions, feel free to join me on this next to the stage. Thank you so much. Have a nice day.
