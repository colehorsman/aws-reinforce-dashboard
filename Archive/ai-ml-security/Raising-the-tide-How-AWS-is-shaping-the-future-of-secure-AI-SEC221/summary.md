# AWS re:Inforce 2025 - Raising the tide: How AWS is shaping the future of secure AI (SEC221)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=bnS60rtcGOs)

## Video Information
- **Author:** AWS Events
- **Duration:** 18.2 minutes
- **Word Count:** 3,225 words
- **Publish Date:** 20250619

## Summary
This session from AWS re:Inforce 2025 was delivered by Matt Saner, who leads a team of security specialists for AWS Industries, working with 250 of their largest global customers. The presentation focused on AWS's approach to securing AI systems and their involvement in the Coalition for Secure AI (CoSI), drawing parallels between the current AI security challenges and historical safety innovations like automobile seatbelts.

The talk addressed the significant challenges organizations face when deploying AI in production, particularly around security, compliance, governance, and risk management. Saner emphasized how the fragmented nature of AI guidelines (with over 1,600 different frameworks and regulations globally) creates confusion and friction for organizations trying to implement AI securely, making standardization crucial for the industry.

The presentation detailed CoSI's four main workstreams: AI software supply chain security, preparing defenders for evolving cybersecurity landscapes, AI security and risk governance, and secured agentic AI. The speaker emphasized the importance of industry-wide collaboration and invited audience members to both consume and contribute to CoSI's developing frameworks and guidelines, highlighting AWS's commitment to working backwards from customer needs.

## Key Points
- Security remains AWS's top priority in AI development and deployment
- CoSI was founded in June 2024 to create standardized, practical guidance for secure AI implementation
- Over 1,600 different AI guidelines and regulations exist globally, creating fragmentation
- CoSI brings together diverse stakeholders including model providers, tech companies, and academia
- The initiative focuses on practical, prescriptive guidance rather than theoretical approaches
- Four main workstreams address different aspects of AI security
- Open participation and contribution model for industry stakeholders
- Emphasis on continuous evolution of guidelines as AI technology advances
- Focus on both immediate tactical solutions and long-term strategic guidance
- Integration with other industry efforts like OWASP's LLM Top 10

## Technical Details
- Workstream 1: Software supply chain security for AI systems
  - Focus on model evaluation
  - Data corpus assessment
  - Open source vs. vendor model considerations
- Workstream 2: Cybersecurity landscape preparation
  - Framework development
  - Best practices toolbox
  - Circumstance-specific security guidance
- Workstream 3: AI security and risk governance
  - GRC perspective implementation
  - Compliance monitoring
  - Auditability and traceability requirements
- Workstream 4: Secured agentic AI
  - Multi-modal and multi-agent systems
  - Excessive agency prevention
  - End-to-end protocol development
- Implementation through various contribution levels
- RACY model for participation
- Email lists and Slack channels for communication
- Sponsored model for formal contributions

## Full Transcript

Good afternoon. Has everybody had a good conference so far? I really appreciate you coming and listening to my talk today. There's so many great speakers here. I really hope that um as you go home you're like that's exactly what I needed to hear and I'm excited to talk a little bit today today about what AWS is doing not just for our customers but for all customers or all adopters across the industry. Um, let me introduce myself a little bit. My name is Matt Saner. Again, obviously work at AWS, um, I am, uh, actually based out of Indiana, and, um, I lead a team of security specialists for what we call AWS Industries, and I have the privilege of helping about 250 of our most complex largest global customers try to drive their business outcomes with security solutions, um, and beyond the day job, I, I'm a private pilot I would. Love to be in the sky 24/7 if I could, but this is a nice place to be with you all here in Philadelphia. All right, so today just to tell you a little bit about where we're gonna go. I'm gonna talk a little bit about our top priority. You're at a security conference. I bet you can guess where I'm gonna go with that. Um, what is the challenge when we think about AI security and AI enablement? What are, what are we really thinking about, um, and, and what are we trying to solve for and work backwards on? Next is what is uh cosi? What, why does it exist? When did it come about? What is its purpose, and why should you care? And then finally, what is Amazon doing and notice I say Amazon here. I'm not saying just AWS. This is a pan-Amazon concept that both AWS and Amazon are uh bringing to industry. And finally, This is a coalition, so it's not just us. What can you do? What can you do both on the consumption side of it and the contribution side of it. So once upon a time, We invented the automobile. And there was a famous quote around how the uh uh you know we're gonna put the horse and buggy industry uh out of business and that's not a good thing. Well, no, I don't know that AI and ML is putting anybody or anything out of business, but it is transforming the way we think about uh how we enable business and another tool in the toolbox and when the automobile was invented. It took about 50 years before seat belts weren't something that were even available in a consumer version of an automobile and even then you had to pay for, right? And then, uh, Volvo in 1959 patented the 3 point seatbelt. And what did they do? Well, they could have thought about that as a as a differentiator. Well our cars are more safe. We're gonna keep that patent and as we keep that patent, um, people are gonna wanna buy our cars, but they didn't do that. They shared that with the industry and um quickly in the 60s, uh Wisconsin became in the US, Wisconsin became the first state to mandate seat belts um and but it wasn't still until the late 80s when. The rest of kind of the states started to say maybe we should have seatbelt laws. It wasn't until the late 90s most states had seatbelt laws or said maybe even the rear seatbelts or rear seats should have seat belts, right? Um and now, uh probably most of us, I hope most of us, uh don't even think about it, we just put our seatbelt on, we get in, we drive, we feel safer, we felt more secure, millions of people lives have been saved, very important. So as we think about this new frontier, AIML not being new. But generative AI being kind of the democratization that has caused an explosion, we want to not wait 50 years to invent seatbelts. We also don't want to just think about how does AWS invent a seatbelt? How does a provider X or model provider Y create seatbelts? We're thinking about this holistically. We're thinking about this as an enabler so that everybody can safely and securely deploy AI out of the box by design. So What are some of the trends? How many people here are already deploying AI generative or otherwise in production? OK. How many of you find that to be challenging? From a security compliance governance risk perspective, uh, pretty much the same number of hands that went up in the first one or the same number of hands that went up in the second one, and these are themes that we're seeing from our customers. Analysts are also hearing from across the industry, and this is something that we feel, uh, compelled to solve for proactively solve for, work backwards from our customers in. And we are doing that and we will always think of that uh as our our main motivation anytime we launch a product, if we can't do it securely, it doesn't go to market. That's bar none, just full stop. So you can see here, uh, Matt Garman, Andy, um, all of our leaders, uh, across the, uh, era of since AW's existence has said security is our top priority and it will always be our top priority. So we want to think about that again, not just what are we doing for our customers, but what are we doing to drive the industry forward in a secure manner while enabling people to move fast and agile and securely. So last year in June the launch of the COSI, which is the Coalition for ScuII was uh founded, um, and it, it consists of a variety of uh folks across both uh uh model providers, tech field, academia, and beyond to figure out how do we provide, how do we answer the open-ended questions. Right, the royal we and the impact that we're trying to make is to be prescriptive, not just be academic. Uh, I, I, I, I get again the privilege of talking to customers every single day and they don't wanna hear, you know, some research paper answer. They want to know what do I can I actually do at my desk today now and if I can't do it today now, tell me as soon as what, what, when can I do it and what do what do I do either tactically or strategically to make work backwards decisions. And that's ultimately what CoSI is trying to help produce is general guidance that informs you as a customer informs us as a provider informs model providers as they build and train models and informs, uh, potentially regulators and governments and other entities across the globe of what does it mean to, uh, build and deploy secure AI and we wanna do that collectively and openly and transparently. So as you can see, I call this kind of the the NASCAR slide, right? You got all the logos of a variety of folks that are members of this. This slide probably by the time I, I, uh, was editing it the other day, uh, it's probably already outdated. That's how much interest cosi has kind of gotten in terms of members, uh, that grow, um, also, uh, working on effort. With other, uh, uh, related kind of efforts, uh, if you're familiar with OAS and the LLM, uh, top 10 for LLMs similar kind of concept and they're they're trying to now become a uh a member of, of Cosi and correlate what they're trying to drive, how that, uh, augments and complements what Cosi is trying to drive, so very open inclusive, so that's who. And what, but let's talk a little bit about the why. So kind of similar to what we saw with those data points, right? It, it, there, there's fragmented guidelines. There's, there's over 1600, uh, kind of traced, uh, efforts that are creating frameworks or governance models or regulations or laws even that can go. From, uh, large entities like the EU to individual countries to states to even uh municipalities, so, uh, that, that fragmented guideline, uh, lack of standardized approach, uh, causes, um, confusion or uh delay and friction. Um, so what we want to do again is bring together diverse stakeholders across the globe, across industries to say what are the common themes, also maybe what are the nuanced themes that might impact specific industries or specific, uh, geographies, and, uh, come together to provide that prescription prescriptive guidance. So if we have that puzzle pieces of scattered across the table, we wanna take those uh puzzle pieces collectively as a group and say what does this puzzle look like? And that's what we're ultimately trying to do so provide those best practices, tools, methodologies for secure AI development and deployment covering all aspects of building integrating, deploying, and operating AI systems to mitigate AI specific security risk. OK, great. I've talked about the mission, talked about the vision. Makes sense, right? I mean, pretty self explanatory, but it's, it's important that we are very explicit and intentional with doing these things easier said than done, right? All right, so I read that. Alright, so how are we doing that? We're doing that through 4 primary work streams right now. The supply, uh, software supply chain security for AI systems is, uh, Workstream one. this is obviously something that when we're talking with our customers, you know, they won't really wanna think about how, uh how models are, are, are, are, uh, what's the corpus of data that's, uh, formulating a model? Tell me a little bit about, you know, these open source models versus these maybe, uh, models provided by, uh, vendors. Uh, what, what are the what are. The the distinct challenges, um, legal, uh, risks, security, safety that I need to take into consideration there and again a lot of the work that's coming into this work stream is focus is is not just gonna help potentially you as someone deploying or selecting these models and what you need to think about it absolutely will, um, but it will also help inform how these models are delivered and the expectations that these models should be built against. Workstream 2 is preparing defenders for a changing cybersecurity landscape. Uh, this is one we've been spending a lot of time on and, uh, helping contribute to, uh, uh, because this is something that is kind of near and dear, uh, to, to our hearts, which is giving people the answers or a toolbox full of different tools that says under these circumstances here's what best practice looks like uh what do you need to think about? So this is helping provide frameworks. So if we think about all of that disparate, uh, discussion points, frameworks, etc. thing that's going out there, where do you start? Like what really matters to you and why? What's the difference between this framework and that framework and which one should I adopt or should I do a hybrid or. I work for an organization where I wanna create my own framework. Well, maybe that's OK and if you do, I would caution probably not the place to start, but at least if you know why these frameworks matter, you can extrapolate from them and apply those into your organization's needs. Workstream 3 is the AI security and risk governance, um, so if you're thinking from a GRC perspective, maybe you're in a regulated industry, maybe you have specific compliance needs that you need to, uh, demonstrate maybe you care a lot about explainability, um, traceability, auditability of your systems and your, uh, your GI, uh, uh frameworks. This is kind of what they're solving for, right? so. What if you had more of a checklist than I don't know no one's telling me what my chess checklists look like because it's still nascient and novel and those are still evolving so this is trying to bring those together and um and and create those uh opportunities as well as how might you instrument and orchestrate the way to monitor and determine your complaints against these frameworks. And in 4 secured, uh, this is relatively new. The 1st 3, workstreams kind of launched shortly after Cosi was announced last summer, so they kind of spun up in the in the mid to late fall. Uh, Workstream 4 is relatively new in the last, uh, 3-ish months taking off and it really, uh, is to help with agentic AI, right? This is the, the theme of, of the conference probably, probably have, uh, maybe went to some sessions, but as Agenta AI really takes off and becomes the thing that, uh, transcends beyond the, the chatbots or the, the Gen AI democratization that we've seen. Um, we really wanna think about the complexity that those cause we wanna think about excessive agency. We wanna think about what is the protocol and the data flow path for the way that agents should operate multi-modal, uh, multi-agent. Uh, we need to make sure that from an end to end perspective that we're able to work in a, um, optimized kind of, uh, way, uh, in, in something that's easy to, uh, measure and operate and secure. So that is an outline of what the work streams are right now. I, I do see those evolving over time and as a work stream stream produces things that may spin down, new work streams may spin up like I said, Workstream 4 kind of has evolved and, and, uh, uh, emerged, and we'll see that continue, uh, through the life of of Cosi, but. If you take anything away from this talk, it's please I want everybody here to see what Cosi is producing once kind of some of these things are starting to become draft and final draft and launch in terms of artifacts being produced by these work streams, uh, consume those, see how your organizations might be able to adopt those, but if you feel compelled, and I hope you do. You, uh, think about how you can contribute to these. We really need to think beyond, um, someone, uh, or just, you know, the, the tech industry or the model providers dictating these. We at AWS work backwards from our customers, right? Ultimately we need your voice and I think I would speaking on behalf of Kosi as well, I think they need the voice. Of the customer as well, right, so, uh, think about how you can contribute. So, uh, whether it's one of those four work streams, uh, you can, uh, join those, you can do it kind of in a, a racy kind of, uh, mode if you will, where either maybe you're just monitoring and you kind of wanna just observe from an informed perspective it's open, um, to do so you can monitor the email list. Uh, slack channels, etc. or if you wanna contribute you can do that as well. um, there's, uh, uh, you do sign kind of an agreement of hey if I contribute this is what it means, uh, but it's, it's very simple to get in, um, uh, and there's different levels of contribution. I won't kind of get into that, but obviously it's a sponsored, uh, model, uh, for, for contributions, uh, but you can submit the code we do really want open feedback from, from, from just about anybody though, um. And then like I said, leverage that guidance so when it is, uh, put out to the world it's put out freely to everybody, right? And, uh, and it will evolve as this world continues to change around us they I will see the these will have a living breathing uh uh life life span to them so it isn't like a one and done publish good luck you're on your own it will continue to evolve as we learn more about emerging threats, emerging capabilities, and, and, and answers to, uh, the hard questions that everybody's trying to solve for. So here's my QR code slide. This is the slide that uh I'll leave it up here a little bit, um, these are a variety of. Open projects that AWS is contributing to as it relates to kind of the space and each has this kind of own scope and what they are trying to achieve. Uh, I, I'm assuming a lot of people now again have seen the OAS, uh, project in probably for years and years, but the LLM top 10 for LLMs for example, um, they're doing a lot on agentic AI as well now, uh, Cosi which we talked about Frontel model form. Is uh comprised of several of the leading tech and model providers uh in the industry working backwards to say hey these are what we're gonna do from a responsible AI perspective um and building those those uh ground rules and ground truths um and then uh open communities like the emerging Agentic community which is trying to solve like what does agentic AI uh look like in from a security perspective. So again, uh, I would encourage everybody to, uh, be a member, um, it, it takes a village, right? This is something that, uh, you know, we all get better when we all contribute, uh, even if the feedback is I expect more I need more, I'm blocked on this. Those are probably usually the most impactful pieces of feedback because that is what we should be prioritizing outside of uh cosi, uh, in these projects that's what I would also encourage you to do if you have an account team at AWS. We want to hear what it is that you need us to do for you to enable you AI or otherwise. So just to quickly summarize. Security is our top priority. It's in our DNA. It will never be second place. It'll always be first, um, so we will continue to maintain and raise that high bar on your behalf. As I mentioned, it takes a village we can't just solve in a black box, uh, our way, um, and that be different than the way that somebody else is gonna solve so we wanna be a part of that village we want you to join us in that village. Everyone is welcome. And yeah you are part of the village so can't wait to see you there. I really appreciate you coming by. It's lightning talk. It's really fast. Thank you. I hope that was beneficial. Um, thank you, thank you, appreciate it. Uh, uh, final note, if, uh, my session or any session you go to, we really do value the CSAT surveys. It really matters to us. So if you could please take a moment, um, today or, uh, before you leave to fill out the CSAT, it helps us get better so that the next time you come to one of our conferences we can deliver a higher bar every time. Thank you.
