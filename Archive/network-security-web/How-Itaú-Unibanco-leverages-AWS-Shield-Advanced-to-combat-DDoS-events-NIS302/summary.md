# AWS re:Inforce 2025 - How Itaú Unibanco leverages AWS Shield Advanced to combat DDoS events (NIS302)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=vcuc3mJv7b8)

## Video Information
- **Author:** AWS Events
- **Duration:** 54.4 minutes
- **Word Count:** 6,594 words
- **Publish Date:** 20250620
- **Video ID:** vcuc3mJv7b8

## Summary
This comprehensive session explores how Itaú Unibanco, one of Latin America's largest financial institutions, leverages AWS Shield Advanced to protect against DDoS attacks across their massive AWS infrastructure spanning 11,000+ accounts. The presentation covers AWS DDoS threat landscape statistics, revealing over 700,000 attacks in the past 12 months with evolving multi-vector attack patterns. The session details Itaú's architectural evolution from centralized to decentralized DDoS protection, implementing AWS Shield Advanced, WAF, and Firewall Manager across thousands of CloudFront distributions and load balancers while maintaining governance through AWS Organizations.

## Key Points
- AWS detects and mitigates over 2,100 DDoS attacks daily across its global infrastructure
- Modern DDoS attacks are evolving toward multi-vector approaches combining infrastructure and application layer attacks
- Over 80% of attacks last less than 5 minutes, with 41% lasting under 1 minute, requiring proactive detection
- Itaú Unibanco operates 5 AWS Organizations with 11,000+ accounts supporting 100+ communities of practice
- The bank evolved from centralized inbound account architecture to decentralized edge protection using AWS Firewall Manager
- Current protection covers 7,000+ CloudFront distributions, 350+ load balancers, and 300+ Route 53 hosted zones
- Centralized logging through Amazon Data Firehose enables unified security monitoring and incident response
- Integration with AWS Shield Response Team (SRT) provides 24/7 specialized DDoS response support

## Technical Details
- **Attack Statistics**: Largest recorded attacks reached 7M requests/second, 1 terabit/second bandwidth, and 1B packets/second
- **Architecture Evolution**: Transitioned from centralized inbound account to decentralized model using AWS Firewall Manager for governance
- **Protection Stack**: AWS Shield Advanced, CloudFront, WAF, Route 53, Global Accelerator, and Network Load Balancers
- **Access Control**: Implemented AWS managed prefix lists, custom headers with shared secrets, and origin access controls
- **Rate Limiting**: Application-layer protection using API Gateway rate limits and WAF rules with hierarchical priority
- **Monitoring**: Centralized logging via Data Firehose to S3, integrated with SIEM for correlation and alerting
- **Incident Response**: Automated playbooks trigger when Shield Advanced events occur, involving SRT team collaboration
- **Cost Protection**: Shield Advanced provides DDoS cost protection for scaling charges during attack mitigation

## Full Transcript

We are very excited to have you with us to talk about how Itau Unibanco will leverage AWS Shield Advanced to combat DDoS events. We know that you are here to know more about Itau Unibanco, one of the largest financial institutions of the world. You're gonna have a chance to. But before, let me introduce myself. My name is Guilherme. I'm a principal solutions architect at AWS. I'm based in Brazil, and today I am with other co-presenters that I want you to meet then as well. I'm Douglas Lopes, social architects specialist in services. I'm Jose Tiburcio, a security architect at Itau Unibanco. Excellent. Let's go ahead and get started. In the session, we are gonna explain to you concepts and trends of DDoS attacks and how to use AWS services to protect your edge. By the end of this presentation, you're gonna have a better understanding on how to implement DDoS protection using AWS huge advanced. But even better, you're gonna have a real use case for large enterprise such as Ita Uni Bank who has thousands of public points across thousands of accounts. But before I get started, I have a question that keeps many executives and technical leaders awake at night. How much would 60 minutes of downtime cost your business? The impact of downtime goes far beyond financial losses. Of course you have to consider, for instance, lost revenue from transactions that can be processed, lost productivity across the organization, but the most important impacts are the damaging customer trust and reputation and the long term impact in customer confidence. Based on this, your online presence is not just a convenience, right? This is your real business. When we have Adidas attack that succeeds, every minute of downtime is devastating for customers and the attackers know that very well. With that being said, I have another question. Show of hands, if you are using AWS, should did you even said to protect your edge services against DDoS attacks. OK, I can see that some people are using Shuvan said, others are not, which means that both of you are in the right place because this is exactly what you're gonna cover today. I'm gonna pass through some DOS statistics, concepts, and trends. And after that, I will hand over to Douglas, who will deep dive on AWS huge advanced implementations. And then we will hand over to Giusetchi Bursu, who will describe it auni Bank's journey to protect thousands of public endpoints against those attacks in a decentralized and distributed model for financial services. This is gonna be awesome. And then we're gonna have some takeaways and research. But before, let me recap some concepts and explain what Adidas attack is and why it is a critical concern for organizations. This is a typical AWS architecture. No secrets behind the scenes. But just imagine that you have an online store. In normal days, your customers just easily walk in and walk out, but suddenly you have thousands of customers, not just to shop, but to block the entrance. This is essentially what Adidas attack does, right? And as you can see in the diagram, those kind of attacks are distributed because they come from multiple sources. They don't have just one location, but hundreds of thousands of compromised systems offering IOT devices, computers, servers, all of them coordinated to overwhelm a target. Did those attacks are from infrastructure sites such as UDP flood, sea flood, or from application side such as HTTP flood, DNS squad flood, among others. But, Once you're gonna have a 300 level conversation with Tainnibunk, I need to bring more details about DDoS attacks. And to do that, I will explore AWS DDoS statistics to explain how AWS support DDoS attacks at scale. We're gonna have some numbers in terms of volumes. I would describe some out layers, such as the highest request per second attack, throughput packet per second. It's gonna be some kind of overview about AWSDOS threat landscape, OK? In the last 12 months we had more than 700,000 attacks. Which means that every day, AWS detected, mitigated or blocked more than 2100 attacks. This is a huge number. Moving out to the au layers that I mentioned before, the highest, largest requests for the attack passed more than 7 million requests per second. And then the largest bandwidth have attack almost reached 1 terabit per second. Moving to application-based attacks, the largest packed attack passed more than 1 billion packets per second. You can see that we have a huge volume of attacks hitching AWS global network infrastructure. Now, let me share a dashboard that has an interesting comparison between application and infrastructure-based attacks. The data comes from 2021 until today, 2025 Q1 and as you can see, application based attacks had an increase in the over the years, especially because of the cloud, because of now new applications can be easily deployed, right? We have more aligned points, which means that we're gonna have more targets that justify the increase of application attacks. But in 2024 Q4, we had a change in the behavior where the lines were crossed and you can see that application attacks. Decrease it, infrastructure attacks increase it a little bit. So, which means that this is an interesting insight about how the attacks are evolving because in 2025 Q1, they move it to a more balanced perspective, but the volumes are still growing. A right way to read this dashboard is that now we have more sophisticated attacks that can explore multivector attacks as a blend of infrastructure and application. That's the reason that we can see some kind of balance between the numbers in the last quarter. But I want to deep dive more in those kind of numbers. Your left hand side, you have the volume of DOS attacks or events related to the infrastructure. We had more than 307,000 events for the infrastructure on the bottom, you can see Q1 and QQ4, which represents 2024, right? But when you move to 2025 Q1, we had a spike. So this is representing in the dashboard that you saw before. Moving out to the right hand side to the application base of the attacks, this is interesting, right? So we had a similar number, more than 307,000 events, but now the behavior is, is a little bit positive, right? Because in he won 2024, we had a spike and down the number decreased and we are seeing an increase in 2025. He won. Which means that the balance of infrastructure application-based attacks drive us to a multi-vector-based attacks tenders, right? Moving to the largest request flood events, we have data from 2019 until 20 2024. We see that in 2023 we had an ultra layer, right? More than 155 million requests per second. Of course, when you move to 2024, the number dropped. It was an ultra layer, but the message here is that. If you compare 2029 until 2024, we do have increase in request per second attacks. Now bring this in a different perspective with different different dimensions. More than 30% of the attacks was request flood attack, which means this, uh, the basic kind of attack, right? At attackers are just sending high traffic, high volume of of traffic to the targets. Then we moved to separated vectors for the infrastructure, mainly packet flood until reaching sea flood. As I mentioned, the taxes are increasing exponentially, but what is interesting to uh to bring to the, to, to our sessions that now they have changed in terms of duration. More than 80% of the attacks, the duration of the attacks last less than 5 minutes. And within this number, more than 41% is lasting less than 1 minute, which means that those kinds of attacks are challenged because they were designed, developed to give you disruption before your mitigation process kicks in. This is a challenge for AWS as well because we have to increase our threat intelligence in terms of malicious traffic exactly to avoid customers outage before, before the attack reach the customer, right? In terms of movements, as I mentioned it, and you can see that in the dashboards, we can see attendance moving from simple fluids to multivector attacks. Again, now attackers can have infrastructure and application-based attacks simultaneously in the same attack. This is a challenge because you block one vector, you're gonna have another one. And then we are seeing IoT botnets as attendance as well, especially because of 5G and more, more uh connected devices. No attackers then can have a chance to have compromised devices and create an army and uh perform a massive attacks. 2, to targets. As I mentioned that before, every day across AWS infrastructure, we detect, mitigate, and block those attacks. With a large public network footprint, AWS has insights into activities on the internet in real time. A large amount of traffic across the internet must be gathered and analyzed for threat intelligence to combat DDoS attacks. Based on this, AWS has a unique visibility in terms of traffic because of our size and scale. With that being said, are you hand over to Douglas. Thank you, Greco. Well, before you listened to Ita uh and See what they are doing to protect their workloads against those protections um. Uh, we're gonna, uh, talk a little about, uh, how, uh, and the protections are done by uh AWS. Actually, uh, we have services that are dedicated to protect, uh, our worklogs against the dos and these services are called the ELG and the protection services. Among the services we have Amazon Cloud Front, which is our delivery HTP based the content, uh, servicing. And also we have Amazon Hot 53. In or DNS service and also IWSCloelerator. The services that deliver TCP UDP communications. Uh The perimeter protection services, uh, what we call pyrami protection services are services that are related to this are integrated with this. These are, uh, for instance, AWSW, or web applicationarro and WS for manager that are integrated with huge, uh, or, or standard of the dos protection. And talking about this, these services at WSU has two tiers in WS the other WS, uh, should that is the standard protection as I mentioned, and also at the events that, uh, can extend these protections, uh, to the, uh, other levels. Uh, shoe door under the those protection services. The detections and mitigations permit the entire network perimeter including the POPs. And that extends our network. And where should implement protections? And and against the attacks in the, the services, the, the edge service like Iron and 53. And the protections in this, uh, pops are in line. It means that the detections and mitigations will occur immediately, and many techniques are used to detect and block these attacks, including impacted validation and its tributed, uh, screwing capacity. Uh, also the protections, uh, extends to the border of the network that is, uh, near the to the regions which makes that the protections, uh, uh, makes that the majority of the attacks, uh, to be blocked even before the customers, uh, be impacted. Well, however, customers that, uh, needs greater protections and ability to customize the those protections they use should advance it and should incorporates the shoulds, uh, protections but also extends use more with, for instance, um, the, the possibility to use web application file more extensively. Also it allows you, it's included in its package, the possibility to use for manager, the rest for manager that allows you to centralize the compliance and the enforcement of the security policies among your resources. Uh, to protect with children and to protect with wife. And the customers that use university uh are benefited from many features. Um, uh, one of the features that they uh can rely on is the increased, uh, visibility. Uh, it allows them to, uh, have access to metrics for monitoring events and alarms. Also they have access to the 24 by 7 team experience they needles that we call SRT or shoulder events should the resource, uh sorry, shoulder response team. That allows customers to uh have access to this specialized team of support. And also customer has another very interesting feature that is the cost protection for scaling during attacks. It means that customer can uh scale without incurring elevated costs uh because they are uh absorbing the attacks absorbing the the the. Uh, that the The high volume of these attacks. Turns out that some customers have deployed should advance or are planning to uh to do it so. Uh, however, they are not, um, taking the advantage of all what should advance its potential, and I would like to share some information that can help them to extract most of it. Uh, when you are deploying shooting events that, there are some processes that you have to follow, and among these process, these steps, the first one is on the DOS architectural resilience review. Uh, many customers are using professional services like AWS Proserver Proserve or, uh, sometimes they are using partners to do it, but sometimes they choose to do it by themselves and in this case they might not be following the best practices so they, uh, they can be uh reliable and resilient to this, uh, uh, against the, the those uh attacks. And to follow this best practices, um, for instance, among the best practices that we recommend is to reduce the tax surface and design on a scalable architecy which includes the use of muchesi, um. The strategy? The use of auto scale. And also in addition to this use of 8 edge services, the research service that I have mentioned before, uh, Amazon Cold Front Global Accelerator, and also Amazon Ho 53, and with this you can take the um advantage of the great capacity of the services to absorb uh large distributed attacks. Well, and when you can, you, you are looking for do this review, know that you can get help from a WS, uh, if you, um, you should talk to your account team and ask them for an specialists say to assist you with this. Uh, it's, it's good to have someone that can help you to pinpoint important procedures to make an actory that is resilient compliant. With should invested benefits like the cost protection for skilling during a task for test. Well, and, well, when you are have, uh, a single account is a very straightforward process to onboard your device, as I mentioned, first thing, important thing is that the does uh resilience review, and then you, uh, continue with the subscription to the services choose the resource that you are going to protect you. Authorize the AWSSL team. To have the proper access it's uh important to mention here that you should have the business or enterprise subscription of the support in order to have access to this team. And then enable the proactive engagement. The engagement is, uh, imagine when you during an attack or even before you not see this. You, uh, you are being contacted by, uh, the security team to identify what is the impact. And also not uh in the end you should um complete the contact list for escalation. Well, but sometimes then you even if you have the proper level of support or even if you have, um, uh, enabled the productive engagement, the productive engagement is not engaging and it could be because the health checks are not being configured. It's important to configure the the health checks because the the diversity is unable to uh uh to get the, the signs and the evidence that your application must be impacted, uh, without these health checks. It's important to include this because it can adjust the the tax detections properly and the pro engagement can work as it is expected. Another interesting feature is that customers that use Sus has access to is the far drills. Which are the synthetic simulated attacks that ingest statistics and methods that can be used to uh test incident response process and give your visibility of of how is going. To be uh in the console for instance uh when you have a real attack occurring, so it's important to use this tool. Finally, uh, well, when you have Uh, one on one account is easy to configure it to on board should, but it might be a challenge when you are in a large environment and large accounts. Uh, large organization where you have many accounts and many resources. So for do this you should use the AWSC, uh, for manager. Uh, AWS, uh, for manager is integrated with the AWS organizations and AWS config which allows it to, uh, detect it, uh, when our resource is included in your organization. And mitigate if it's not uh compliance with the protections defined by the security team as for instance the the protections implemented by Shirley events and the NLWW. And also today, uh, the less for manager allows you to use the heter fitting of uh of AWSwa rules what allow you to maintain the, the, the rules that were applied by your application teams but also including the, the rules that was defined by the the the security team. And well if you have a uh uh high complex uh organization that impose challenges to on board the process, the good news is that there are tools that can be used to help in this process. Uh, we have, uh, launched, uh, on the one click deployment of share invested which allows customers to use infrastructure as a core tools like the form in cloud formation. To implement should invested uh per exits and also implement the the for manager, uh, to protect the resources we should invest in the WSF, uh, another interesting tool is the automations for photo manager that allows you to centralize the, the, the auditing rules across your accounting organization and in this, this automation solution. Uh, has the possibility to use a workflow that will help you to deploy automatically should it advance it as well, but also has another workflow inside it that uh can detect if your resources are not using health checks. And it can create the health checks based on your resource and implement it if you're uh protecting a resource which should invest. OK, so that's insights. I certainly, uh, know that you help you to start most of sure diversity and allow you to protect better your, uh, research with shoulder diversity in large environments. Now, I will invite Jose to the stage. Thanks Douglas. First, let me introduce you to Itaibuco. We are a universal bank with over 100 years of history. We offer financial services tailored to various market segments. We are also the largest financial institution in Latin America and one of the largest in the world by market cap. We are the most valuable brand in Latin America as well, and we have over 96,000 employees distributed in Brazil and overseas. We are undergoing a substantial digital transformation to modernize our processes and solutions and to achieve this goal, we organize it ourselves in in different teams. The first team is the cloud Foundation team that is responsible for essential cloud services, including AWS account provisioning, network, and basic connectivity. Next we have the platform teams. We are responsible to develop infrastructure as called modules. Standards and blueprints that reduce the cognitive load of our developers so they can focus. And using those technical capabilities and uh cloud services is the business team which creates the business value for our end customers. We have seen a reduce in cost in transactions costs compared to previous years as well as a notable increase in the number of deployments that we do compared to previous years as well. Uh, and we have uh more than 6000 AWS certifications, which makes us, uh, the most significant AWS cert certificate, uh, certification program in the world. Supporting all those teams is my team which which acts as a security pillar and offers services and controls to support the platform teams, the business teams, and the cloud foundation teams. We have a large AWS footprint that powers this operation. We have achieved a significant scale on AWS since the inception of our cloud migration. We have 5 AWS organizations in the production environment with over 11,000 AWS accounts and more than 40 million configuration items. That it supports more than 100 communities of practice uh distributed in 300 release trains and with over 2700 squads and more than 5700 business services. These numbers reflect the magnitude and complexity of our cloud operation and to reach it, we designed a scalable landing zone. Our lending zone is responsible for scaling AWS accounts to support applications belonging to multiple business units. We have integrated our ITSM portal where the product owners and developers can request a new group of accounts. As you can see, the control plane is responsible for orchestrating the account provisioning, calling AWS Control Tower and the AWS Service catalog APIs. To launch new govern accounts. After that, the platform teams using delegated accounts inject controls, governance, and frameworks into those product accounts. This environment is organized so that the lending zone can expand with new management accounts as we require and. To, uh, in this way, we can create additional product accounts to support applications in our business units as well. So Given our scale, we needed to standardize and control our edge services exposures. So that's when we will dive deep on the our journey for exposing those applications using AWS edge services. This initial phase was crucial in setting a strong foundation. I will explain to you how we implemented edge services protection against DOS starting with this centralized approach. To support the business units that need to expose public facing applications using AWS edge services, we've created a centralized inbound account which is maintained by the SEOps team. We've started with Cloud Front, ALB, API Gateway, NLB, and S3 bucket integrations and to support ALB and NLB, we've created uh VPC where public subnets forwarded traffic to a private VPC endpoint which in turn forwarded the traffic to downstream services. The business units using our lending zone self-service. Were allowed to create new product accounts and they had complete control over the the their AWS infrastructure. Once they were ready to expose to the public internet, they needed to open a ticket to the SAOps team which in turn configured the AWS services resources on the inbound account. Once we had everything in place, we needed to ensure that no direct access was allowed to our public face origins, so we wanted to ensure that only our cloud front distributions could forward requests to to the origins, thereby reducing the attack surface and centralizing the service exposure. For static web content, we use it origin access identity. And So we can authenticate cloud front access to the S3 buckets distributed in the accounts. While new applications were created, we gradually migrated from Origin access identity to our origin Access control to embrace the KMS support and this is the standard for the whole organization. For API gateway, ALB and NLB, we explored different mechanisms such as custom headers that use shared secrets, cloud front IP ranges, and lastly, AWS managed prefix list for cloud front which allow allowed us to natively integrate with security groups, route tables, and file manager. We do know that Cloud Front has VPC origins, and it is in our roadmap for the future. Now that we had protected the origins and the users can't bypass cloud front from the inbound account. But remember when I said that we have a self-service that the developers and the product owners can create new product accounts, right? These accounts will scale out with new VPCs, new applications using the pipelines to deploy applications across environments from development to production. So we realized that we needed a way to create a governance for the DDoS and Edge services that follows this development life cycle. So we needed to give the ability to developers to launch their public endpoints in their own accounts. So to do that. We created an IP set that allowed access to IPs that belonged to AWS managed prefix list and to Itaibunku's data center, as well as our AWS Agress file elastic IP addresses so that our applications and automations could have access to our public facing services. This allowed our developers to create workloads in their accounts and follow every step from the process of exposing of exposing applications to the internet, protected from DDoS attacks. We don't need to expose non-production environments to the internet, so by doing this, uh, this DOS governance, we could allow the developers to, to implement these public facing services from the start using development and staging environments to validate their application architecture. And move on to production later. So now that we have the protection in place and we, we had everything under control, we started receiving heavy load from the internet and even from the internal applications who accessed our public facing services. The network infrastructure was robust, uh, but the applications themselves couldn't handle the traffic resulting in auditors to mitigate that we explored the architectures for scaling out uh the environment. AWS should advance it comes with DOS cost protection. So we can be safeguarded against the scaling charges resulting from DDOS related usage spikes. So if any of those protected resources is scaled up in response to a DDoS attack, we can request you advanced service credits through our regular AWS support channel. IAO has thousands of applications and just scaling the infrastructure will not absorb all the traffic, so the downstream applications can be impacted. And to manage that we started exploring different mechanisms so we moved the security protection to the application layer using AWS API gateway rate limits so we can fine grain our API uh we we can much better control the API usage from our clients. But remember that's not sufficient when you are protecting your application for uh in the the public internet. You also need in conjunction with that to use AWSwa in the AWS cloud front so you can implement uh different uh rate limits and application. Jail restrictions to to better suit your needs. So now that we had the governance and the autonomy, uh, we had to create these rate limits so we set up a journey we started to analyze the events that occurred during the year in Brazil and we noticed that every major event like the Mother's Day, Christmas Day, salary payments Day and every other important day of the year. Was when the the the traffic spiked so we do an event management during the year so we can better prepare ourselves we set the baseline for the the the applications exposure and we've also worked with different application teams in in in the bank. To create custom rate limits because as a large enterprise you may know that we have integrations with different partners call centers, 30 party integrators, and we also have our own internal and external automations so we needed to analyze the the way that. These applications worked so we could separate legitimate traffic from attacks. So after that, we set out to create our WAFF rules with a list of priorities. We set out to create this strategic hierarchy of different WAFF rules. At first we have the allow and block IPs list which allows us to block immediately malicious agents. We also are heavy users of Amazon managed rules with its IP reputation lists and anonymous IP list which collaborates to our protection. And we also are users of marketplace third party rules which can help us, for example, dealing with a WASP top 10 attacks. We also have at the bottom of the hierarchy, our baseline rate limits or our custom rate limits developed for each application use case. So, let's revisit our evolving infrastructure scenario. We've successfully implemented the robust protections for our origins, uh, using the managed prefixes, the custom headers with shared secrets. Uh We leveraged the security groups, we leverage the route tables, and we've also established the application based rate limits and implemented these rate limits to safeguard our end points against the DA's attacks. However, our environment continues to expand rapidly. And we are facing new challenges by leveraging the scalability of our landing zone. The growth in applications and accounts has led to an increase in the request to our security operations teams. So it started to become a bottleneck, and this started to impede our cloud expansion. So we look at 4 ways to overcome these challenges. That's when we started to rethink our architecture. As we gained experience and maturity, we transitioned to a decentralized model. To address these scalability issues, we made a strategic pivot in our operational model. We decided to centralize the governance while distributing the execution. So this shift led us to adopt a decentralized approach for edge protection. So we maintain a decentralized control over the policies and standards we ensure the consistency and security across the organization and meanwhile by distributing. The execution of the edge protection measures, we empower the individuals and the teams to implement and manage their own edge services within the established framework. This decentralized approach enables greater agility, faster response times, and specific application needs. To implement that, we use it a delegated uh account for the AWS file manager, and we learned from the past when we implement implemented the centralized approach. So similar to the inbound account, this firewall manager account is managed by the SAOps team. We use File Manager to connect to AWS organizations. To streamline our controls and governance. With AWS File Manager, we can have a single console for managing this edge protection across accounts. We can create policies uh to manage AWSWAF rules, shield advanced protection, DPC security groups, network fire rules, and Route 53 resolver DNS file rules from this central location. The monitoring becomes centralized through this single console. This consolidated view helped helped us. To help the security team to maintain the controls consistent, consistent with our baselines, so the business units could scale out to multiple product accounts. And as we, we, we, we went on this journey, we learned a lot. We scaled a lot as well. As you can see, we have more than 7000 cloud front distributions, more than 350 load balancers in elastic IPs, more than 300 Route 53 hosted zones, and more than 10 global accelerators for products that does not support cloud front integration. All of them protected by the shield advanced, launched in the product accounts, created by the business units and centrally governed by the security team. So that's fine. That's well we've discussed this architecture, the best practices, the applications. However, having this protection alone is not enough. The security team needs to operate the edge protection. We could centralize governance, implement observability, and respond quickly in the event of DDoS attacks. Let me go back to our landscape. When we started our journey to protect the edge services, we had the application logs and security logs in the same the same product account. The application teams were interested in the application logs, and the security team needs access to the WAF logs, the AWS edge protection logs. So this causes an operational overhead for the for the security team because they had to jump from account to account to perform basic tasks like ad hoc queries on the logs that were stored in each account as 3 bucket. That's when we decided to migrate ourselves to use Amazon Data fire hose to streamline the logs to a central S3 bucket where the security team could. Perform the ad hoc queries and the application teams using their product accounts could focus on the app logs. Although we had access to this centralized bucket, we realized that we needed to integrate. This information with our CM system where we can perform a series of events correlations using event centralization from multiple sources. This provided us with enough console solution that allowed the security team to access it without requiring to authenticate in each AWS account, so improving their productivity. So now that we had the wa log sent across accounts through this centralized bucket, we had created an automation to send those logs to our CM end point. We also enabled the security hub file manager integration allowing us to centrally monitor all the findings from the product accounts and forward those to the CM as well. The setup enabled us to have a single pane of glass for logs and events. And allowed us to have observability in terms of edge protection and if an attack happens, we already have the permissions for the AWS huge response team. So they can access the Wa APIs and the logs stored in the S3 bucket. The SAOps team collaborates with the SRT team and the application team to initiate the analysis of the event. It is essential to engage the application team because they can provide uh. They can collaborate with us on traffic analysis, cost impacts, criticality, and specific app behaviors. So when an AWS should advance a team arrives at our CM system, Uh, an automation automatically notifies the set up team. The SAOps team follows the predefined playbooks and run books specific for that scenario. For an identifier ongoing attack. The team performs an immediate assessment to understand what is going on. And we verify all the details about the attack, like its type or its impact. We also check for performance issues that may be affecting our applications and services, and we will review the automatic mitigations applied by AWSU advanced and AWSAF, including traffic filtering and rate limiting. Additional actions may be necessary. So like uh. Adjusting security security groups, enabling additionalA rules, and etc. We also documented from the start. For identified subsided attacks, we performed a post attack analysis review, including its duration, types of factors that were used on the attack, the affected resources, and the effectiveness of our automated mitigations. We also conduct a resource assessment that allows us to take a picture of our uh resources and see that that they display normal behavior in matrics. When the mitigation is in progress, we closely monitor the AWSU dashboard for real-time updates to track our applications and performance metrics and keep an eye on the resource utilization. We don't interfere with ongoing automatic mitigations and we avoid making unnecessary changes to security groups and network ACLs. We also document. Any observed impact on our services. We also ensure that we are prepared for escalation procedures, keeping all relevant team members uh on standby and engaging with AWSSRT team as needed. To bring more context and understand the attack behavior, the security team can perform queries to the CM system. Using the event details attributes to search for specific patterns and sources of attacks. At the same time, the AWS edge services provides different metrics. AWSU Advanced, AWSwa, AWS Cloud Front, and AWS Global Accelerator that you can use to perform the analysis and as well as in your mitigation automations. So the goal is to gain a comprehensive understanding of the overall attack, providing a detailed view that will help the security team to quickly identify these patterns and signatures of DAS attacks. So, it also enables uh this identification of sources of the attacks and the effectiveness of our current roles, which is crucial for fine tuning the automated mitigations. So this coordination between all the teams, the AWS should advance the the AWSSRT team, the security team, and the application team can go even further to coordinating with our ISPs and law enforcement enforcement agencies in Brazil and overseas. The volumetric analysis as well can help us explain our scale scale out and scale in strategies. Some practical examples of activities that we perform with the SR team include managing, for example, uh route tables to direct traffic to a black hole or messing with the cloud front cache behavior or geo restriction or enabling uh geo blocking for. Just for an example. We also can modify wa uh rate based rules or string match rules. After the remediation is done and the the the event is mitigated, we can now work with the postmortem analysis and we gather with the security and application teams to review what went well, what we could do better, so we can feed our current playbooks with new information that helps us dealing with future attacks. We also regularly perform fire drills with the AWSSRT team to simulate our alerts and automated uh mitigations. So Let's recap what we've learned in our journey. Work with your weight limits. Uh, discuss with the application teams, the application behavior specifics. With that you can create more specific rate limits for that use case. Analyze your business impact and be prepared to to to to scale out. Adopting scale out and scaling strategies is important for you to better handle these DAS attacks. Also perform a thorough review of the important events that you have in your calendar year. To better prepare and handle these these DDoS attacks and common threats that we may face on public facing uh internet services so. Do a postmortem analysis that goes deep in the root causes of the attacks and that will allow you to feed the documentation and the procedures of your teams so they they can act quickly next time. Also be aware of the friendly fire. As with every large enterprise, we have uh multiple uh applications that we execute to automate processes and to access public facing services so internal applications can perform denial of service attacks as well because of bad configurations or bugs, so be aware, be aware of that. And explore AWSU the advanced events that can help you mitigate, automatically mitigate these DDoS attacks using the metrics that it provides. So, thank you. I will hand it to dogs. Thank you, Jose. It was amazing to see all those journey and learn from them, from the, for the experience. Uh, actually we have some takeaways and among them leverage a levels for manager. Uh If you use centralized the approach or decentralized the approach, no matter, you must have used the photo manager because it allows you to protect uh any scale also reduce your attack surface doing it by protecting your or using edge services. Also we have seen the importance of have a consolidated view or one pane of glass to uh monitor and to see everything that is happening and when you are doing your documentation or procedures uh um patterns and playbooks also training your team, uh, for incident response use fire drills. Here are some links that you can get access to research share in this session. And thank you for all your time and I hope you have enjoyed the session and our events so far.
