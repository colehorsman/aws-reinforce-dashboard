# AWS re:Inforce 2025 - Build and scale a security-first engineering culture (SEC204)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=eoXQT_gbliw)

## Video Information
- **Author:** AWS Events
- **Duration:** 49.7 minutes
- **Word Count:** 9,841 words
- **Publish Date:** 20250618
- **Video ID:** eoXQT_gbliw

## Summary
The presentation focuses on building and scaling a security-first engineering culture within organizations, delivered by two AWS Identity leaders - Brigid Johnson and Kristen Haught. They present a flywheel model that demonstrates how security culture can gain momentum and sustain itself through identification, celebration, risk addressing, and systemic change.
The speakers emphasize the importance of involving multiple stakeholders - engineers, security professionals, leaders, and business stakeholders - in creating and maintaining this culture. They use a fictional engineer named "Pickles" to illustrate the difference between poor and ideal security response scenarios, highlighting the importance of prompt reporting and addressing of security issues.

## Key Points
- Security culture needs to be driven by all stakeholders, not just the security team
- Self-identification of security risks by engineering teams provides the biggest impact
- Clear security expectations and standards must be articulated and published
- Leaders should actively celebrate when security risks are identified, not punish
- Creating a positive feedback loop through celebration and recognition helps sustain the security culture
- Regular business stakeholder engagement in security risks is crucial
- Building momentum requires both experience and accountability

## Technical Details
- AWS Security Expectations: Annual published document outlining security standards
- Identity and Governance Services: Mentioned as part of AWS's security infrastructure
- ASAC (AWS Security Assurance Center): Internal security program mentioned
- Guardians Program: AWS initiative for developing security-minded engineers
- Logging Security Controls: Referenced in context of handling sensitive data like SSNs
- Identity Systems: Multiple AWS identity products mentioned but not specifically named

## Full Transcript

Welcome everyone to re:Inforce. My name is Brigid Johnson, and today we're here to talk about build and scale security first engineering culture. I am joined by Kristen Haught who is a senior, uh, security engineering manager. We actually both work in AWS identity, so you might be questioning. like why are you all fit to talk about uh culture security culture specifically well we thought this was a little good 12 punch um so I I'm a director in AWS identity. I own a bunch of identity systems, um, products you all use hopefully and so. Um, you want my engineers to be very security first minded, so that's great. So I'll talk about my experience as an engineering leader and bringing that culture to those systems, but Kristen here, you wanna talk a little bit about your background? Sure. So up until January of this year I was in AWS security so I spent a lot of time working in ASAC, um, working on programs, um, like our Guardians programs where we're developing engineers across the. Organization to think about security but I was always in that I am a central security team member mindset until recently where um I've moved into the identity organization and manage a team of security engineers that support a number of different identity and governance services um one of the organizations that we support is Bridget so um I've been amazed by the culture that Bridget has instilled in her organization. I have, um, so anyway. So I'll, I'll share kind of like those two different mindsets that I've had of working within a security organization and then coming into um a developer organization. So the coolest part is since we've been working together for a while now we get to share some stories. So speaking of stories, we're gonna introduce our engineer for the next hour. Um, his name is Pickles. He is also my horse, but any of y'all have an engineer on your team's named Pickles? Maybe there might be a a team mascot, um. And so if you're bored you can just count how many times we say pickles throughout the presentation, keep you on your toes, but let's talk about pickles. So Pickles, the engineer was working on a new feature, you know, he was coating away with his hooves and. Whatever he how he codes and his vibe coding maybe and then he discovers that his service is writing Social Security numbers to the logs he's like that's probably not good but I got this feature it's not that great or like I got this feature the security issue is not that great. Security will probably fix it, you know that those security people will come in and fix it. It's a Friday afternoon. I don't wanna report it that seems like a lot of work, so hopefully you all. Cringed when you heard that story like a lot on the insides and you're like well that's not the right story the right story. Is is that Pickles is working even if it's on a Friday afternoon he identifies the issue he follows clear steps to report the issue him and his team get engaged maybe some experts get engaged, they assess the impact they assess the risk they work to mitigate the the risk and then at the end of the day Pickles gets a carrot and we all celebrate, right? That feels a lot better and this is what happens in a strong engineering uh security first engineering culture. So let's talk more about how we get there we're gonna kind of cover a few different things during this session we're gonna get started with just like who was involved, um, probably a lot of the people in this room today, um, we're going to break it down into this flywheel that, um, I think really, um, accentuates what uh a security first culture looks like and how it gains momentum and continues to sustain itself over time. Um, we're gonna talk about empowering engineers to identify security risks, um, and figuring out how do you move from just like fixing things that are identified to driving systemic change so that these things don't happen again, um, and then we're gonna talk about the impact. What does this all mean? Why do we care about it, um, and then give you some tips on how to get started in your own organizations. So, there's a few different key personas involved. One, you guessed it, it's the engineers. Um, how many of you are engineers in this room? Alright, we got some awesome, obviously incredibly core to the culture of uh security first engineering culture, but also the security people. How many of you are in a security or compliance or audit function within your companies? OK, we got the mix. Awesome. OK, but it doesn't stop there. It also is the leaders of the company. How many of you are in a leadership role within your organization? Awesome. And then it's the business stakeholders as well, incredibly important. How many of you have a business role within your company? Awesome. OK, every single one of you plays a role in building this culture. So what does it look like for each of those different personas? So our engineers in the room, these are the people that we want who are day in and day out building these applications, writing new code, um, we want them identifying security issues and we want them prioritizing them. Um, and that means being able to find them, um, within whatever they might be doing on a given day, whatever applications that they own, and there's the security persona so these people are, um, it's really important that they're able to clearly articulate what the security expectations are. Um, I think that oftentimes is missed where a security persona comes in and says, hey, I'm gonna go and help do these security things when in actuality really start by focusing on what are the, the expectations that you have and the standards that you can set to make it easier for them to achieve those outcomes. Well, even in AWS we have AWS security expectations and they're published and updated yearly, so you know about it exactly. Then we have the leaders so important that leaders are aware of these security risks and celebrating them when they're identified. And then the business personas, these are the people that really need to be regularly, regularly engaging on these risks, not just like saying hey they've got this, they'll take care of it, like asking questions about what the risk is, what the impact is, and inspecting the progress of um of fixes that are identified, but how do you get it going? So this is our flywheel that we're gonna use this throughout the presentation to kind of talk around um core components of building this culture um it starts on on the left you'll see identify it really starts with identifying, but it we've placed this where it is because it is kind of an uphill battle to identify risks we're gonna spend a lot of time talking about different tools and mechanisms that you can put in place to encourage engineers to do this, um, and then it's celebrating and we have celebrating there at the top because if you do. Do it right and you do it consistently that's where you start to build your momentum and that enables engineers to be able to address the risk in the right way and then leading to systemic change which is really important um in order to prevent these risks from reemerging over time um and then we have this sub flywheel with experience and accountability and as these engineers gain more experience with identifying and addressing risks and you inject accountability where it's needed, it'll help that flywheel gain more and more momentum. And whether you're just getting started or you have systems in place already for your security first engineering culture, adding more investment, leadership time and attention, more juju into any of these buckets will continue to spin the flywheel. So that's, that's the goal. It's all about the juju. It's all about the juju in my words. All right, so when we talk about identifying security risks, this is the first one. The biggest bang for your buck is to get the engineering teams to self identify risk and so we're gonna spend a lot of time here today but the number one thing to help with this is to make it easy, predictable, and a little bit boring for them to report potential security risks and I use that term potential very intentionally if they're they feel wobbled. They're a little nervous. It should be a noop situation. Cut the ticket, get the right people involved to assess if it is. If it's not great ticket get closed, everybody moves on with their day, and if it is a security risk, then the right people get brought in to mitigate and assess and all of the things, um. To make this real like you can have easy tickets all day long, but if you do not celebrate when engineers self report um security risks we're gonna talk about this a lot you're not gonna get them to self identify you have to encourage that behavior time and time again. And then one thing that I found has helped a lot in my organizations is security risks can be a little bit scary. They can be overwhelming they can make somebody a little bit anxious and so bringing in high judgment individuals who have seen scenarios like this before is a really, really good path to make sure the engineering teams feel supported throughout their, um, if they identify risk. OK, so we talked about engineering teams and self identifying risks. We're gonna this is really really important but obviously you're gonna have security tools um that detect risks please try to make these available to the engineers as much as possible rather than a central security team seeing all these things and being like bang, fix it, right? Make them available put them available into their tools that they're already using their pipelines, their code analysis tools, their reporting, their tickets, whatever you got going on. And then the third bucket we also have is externally discovered risks. Now hopefully you find so much in the first bucket that the last one is a little small, but they do happen and realize that they happen from more than one place. They're not just always formally submitted by a customer who wants to do like there's bug bounties and all that, but they also pop up on social media platforms, blogs that are written, um, video blogs, all the things where somebody like this is weird. We in AWS find those and we actually cut the internal tickets so we can do the investigation to see if it's real or not and then when you do engage with the customer, uh, foster a see and understand to kind of understand where the customers at what they were trying to do the inputs and outputs. So I've often in my career heard things like we can't have a security engineer on every team Kristen or we can't you don't, that's right. We can't train them all to be security experts and security should be security's job. Has anyone ever heard any of these things before in their conversations? Yeah, I see a lot of nodding heads. Those are things that we hear often and they're all honestly really valid thoughts, but we're gonna debunk this throughout this presentation because. They, they don't need to be blockers in this. We're gonna, we're gonna bust those me alright, so setting up engineering teams to self-identify, I wanna drive home the point that it has to happen at every point of the development life cycle. So starting at product design, you gotta be asking questions, break our mindset, how can a bad actor exploit this new change, this new feature we're launching, this change in the system. In tech design and reviews have your security teams review it or have somebody who's just has a good security mindset asking are we verifying the inputs are we inspecting our assumptions in my um in my uh organization we have a design doc and it's a template and there is a specific part about assumptions and then there's a specific part about the security nature of those assumptions and so calling it out explicitly really trains your engineers. Be on the lookout early in the process and then yes you'll have automated tests you'll have tooling to kind of identify to make sure that all those assumptions that you were going after are actually valid and you're verifying the inputs into your system that is when we went out and asked a bunch of our security engineers where I said what's the number one thing you wanna tell customers about our security first engineering culture they're like verify inputs every input into your system should be verified. That was our number one thing. And then hopefully if you've done your homework earlier in the process your security reviews should go pretty seamless and I would actually say like that's that's the case for a lot of my features um we we go out or a lot of updates to our system our security views are boring we don't find a lot of new things and that's a good thing because we've done it early and thought about. So regardless of what your software development life cycle looks like, product design, test design reviews like don't whatever that is, take these three things and figure out how you inject it into each a step within each of those things and if you do that it'll be an incredible first start at this new culture. And then when an engineer self identifies a security risk or a security issue, the key ingredient is to celebrate pizza and champagne works, but emails also work key ingredient or just Bridget's favorite is my favorite food, um and pizza. But so we have a security review meeting every week and when an issue we review an issue. And it's self identified. We hear the VP say, hey, who identified that and everyone's like, Whoa, and then they're like, no, send an email. This is great. kudos to them, right? And so what happens is the manager usually kicks off an email with the employee on and the VP's are just like, great job, great job, great job you can see some here or slack messages, lots of kudos um if you are a leader and you're res. To one of these, please try to make it as specific as possible. I did have one pop up the other day and just like pickles, it was a Friday night and the engineer did report an issue and it was real and um I actually called out thank you for reporting on a Friday and he was like yeah that was scary right? but you got to encourage that behavior to always report it if you see something. That was a fun animation that I didn't know was about to happen so I'm not gonna spend too much time on tooling, but the reason I wanted to have this slide is because these are the five key areas where you want to make sure you have tooling because it will help you identify risks within certain key spaces. So look at these and there are presentations across reinforced on each of these different topics, um, and, and. Ask yourself if you have tooling that fits within these buckets um and then the last one is less about tooling and more about a pin testing framework. A lot of people think like oh I must hire like a pin tester or an external contractor to do pin testing for me but actually engineers are the best pin testers um and if you give an engineer some time to go and break some stuff. They're gonna figure out how to break it and it that's the best thing that you want to happen so I'm not gonna harp on this too much, but I just wanted to have this so that you could look into um the where you have the tools um to enable engineering and I'll put a plug in for access control gaps because I own Access Analyzer. I think it's the best thing since sliced bread and so if you haven't checked out Access Analyzer, definitely do it. It can help. So we can demystify or demystify um you must have security tooling to find security risks and issues. I know I just talked about the tools, but you definitely do not need security tools in order to find stuff. um, these engineers who work on these applications day in and day out and know this code better than anyone else are best. Position to be able to find things um and going back to that breaker mindset and inspecting assumptions and and inputs is the best place for them to start to be able to say what would I have expected to to be put into the system and if it doesn't come through in the way I expected what are all those ways and then what happens what gets returned when I do that? Um, so you don't need the tools, right? They're, they're great for driving systemic change which we'll talk about later, um, but you don't need them to identify issues. Um, another myth that I hear often I could have a whole conversation I should actually do a reinforcementation on the common myths, but I often hear engineers say there's very little risk associated with non-production systems, and I'm sure anyone who's been in the security space for long enough has had a scenario where. We didn't properly protect a non-production system and an attacker used that as a pathway to get into the production system. This scares me all the time and it's something we inspect as a security team a lot, um, so don't have a bad day because you didn't think about this or you had engineers think that it's non prod, it's not important. Let's spend our time in the prod space. You just made our audience cringe for a second time. I know raking them up here. I'm sorry. Um, OK, so this is kind of just a high level overview where are the different ways or mechanisms where you can find issues threat modeling, if you're gonna start anywhere, have your engineers threat model, but don't overemphasize the, the how to of a threat model. Just think about. Have them think about what am I building what could go wrong and how do I address it start there code review using code analysis tools, um, AI is making it a lot easier for us to do these kind of code reviews, um, but really important, um, to look at that and then dynamic analysis doing that pin testing on a regular basis and then adding adding these automated security checks into your pipeline. Um, and then the red one is the one that we all don't love, but it is the customers, the disclosures, the external researchers that oftentimes can find things, um, but if we can shift left, if anyone's ever heard that term before, even in the identifying risk space we we will be in a better place. So now we have all these issues you're done an amazing job. This is just a screenshot actually from Threat Composer. Shout out to Threat Composers's open source threat modeling tool, um, and you can go and use it and it's just a really simplified framework for engineers to be able to enter threats and ask questions that you want them to ask. But you have all these threats, so what are you stressed out a little bit by now because you have all these threats and you're just like what do I do? You have all these issues, um, so we've identified a lot and that should be an ongoing place. The key theme here is that you're gonna actually use the security issues that you find to spur the rest of it, right? You're gonna use it to address them and you're gonna use it to make systemic change and you're gonna. They use it to encourage the engineers to keep doing it right and that's where that fly will um really happens. So let's talk about you have all these security issues and then you have to address them. We actually struggled with the word address because it's like do you mitigate them? What if it's not a security issue? Do you, um, prioritize them and then we've kind of figured out addressing the security issue and what does that mean? So what it means is you gotta articulate the risk and every time you're articulating the risk everybody put their doctor hat on their doctor they need to be super clinical they need to talk about um clearly documented behaviors and outcomes so for example an individual. With an account and knowledge of a bucket name can read the contents um a lot of times in this step is where security issues start to get, uh, amplified a lot of scary words added um and so we like to remind everybody to be super clinical then you assess the risk so determine the risk of it, the urgency, um, are their customers impacted what is the perception risk sometimes that goes out there too. And so anyone can get access to your carrot sales data and horse PII like that is not OK, right? Like we can't have our horses PII out there letting them know I don't know what horse PI what colors they are or something um and then you prioritize next steps. There's always this debate between long term and short term. Number one thing, and I'll repeat it, is like go mitigate, get a team to go mitigate as fast as possible. Get a team to be assessing the impact. They should not be the same team, right? Getting going to separate or they shouldn't be the same people. They can be on the same team. And then track action any long term thinking as a leader you should be saying things let's deal with that after we've mitigated the issue or we've gotten a hold of the mitigation. Let's think about that later, right? You want people focused on the actual steps to mitigate the issue. So we talk about articulating the risk is we're gonna put your doctor hat on if you watch TV you gotta be really clinical and 11 way to always force this is use threat language. So what are the prerequisites? What's the threat source? Um, in my previous example they have an AWS account they have knowledge of the bucket can threat action can read the context, which can lead to threat impact getting access to horse PII data and negatively impact our horse customers, um, be clinical and specific. Um, this helps you figure out where to drive the mitigations. It helps you prioritize, right, because you know exactly what the inputs are, you know exactly what the action they can take. And then the other thing this really helps with with security issues you're constantly pulling in people. Right, like, oh we need somebody from the service we need somebody from this other team we need legal now, right? And if you have clearly articulated the risk, it is so much easier for those people to get caught up to speed you've ever been part of a security issue and every time somebody joins the call they're like, What's the issue again? No, write it down somebody just laughed so that means that they've been in that situation. No, write it down, put it in the ticket or whatever tracking system you have, make sure it's super clear. Be a doctor and articulate the risk. The other thing I see happen all the time that I'm sure y'all can relate to is engineers come to you with an issue and they say I found this and I have this idea. This is how I'm thinking of fixing it and you're like, Whoa, whoa, whoa, let's not solution this yet. Just like let's figure out what has happened. And what the issue is, um, so I always try and, you know, ensure that they're thinking about how to articulate it before they do anything else. The other thing I wanted to call out to you is when you're making it, thinking about how do I um uh enable these engineers to report the risk, um, make sure to not establish a culture of when they reported that they are then. Responsible for going out and owning the fix or like having to do all of this paperwork or questioning or whatever to dive into it like I think that is one place where I've seen people go wrong with trying to build this culture out um because that then it's just gonna discourage the engineer to do it they're not gonna wanna do it because then they're gonna be on hook on the hook for stuff so just don't fall into that pit. Um, and, and make it really easy for them to assess the risk. So if you do need to get information from them, how do you get get it from them in the quickest way? We'll have a really set simple framework for getting the information that you need or that the the organization would need in order to go dive into it and figure out what the right path forward is. This is a screenshot actually from our security tool internally. We ask the exact same questions every single time a risk is reported, um, and we articulate those, but here's the thing. It will change over time as you dive into the issue and as you learn more and so make it something that can be updated and evolved and have that be the central place where everyone goes to learn about what is happening um because I think the changing of information can oftentimes create confusion and frustration and and churn that you don't want when you're trying to to solve an issue fix it as fast as possible. Um, so Bridget alluded to something earlier, our weekly security meeting. So at AWS you might have heard of the weekly security meeting in a previous presentation, and this started, you know, over 10 years ago since I've been here, and it was started by Andy Jasi. He said, I wanted, I wanna know what. The security issues that are happening across the company and he said I want to know about it regularly, so he established what we call the weekly security meeting every single Friday him and our CIO Steve Schmidt at the time would meet as along with the the engineering owners of whatever security issue they're reviewing that week. This has grown into something that each individual engineering organization also conducts weekly on their own and our VP is there every single week um my team owns that weekly security meeting. Jamie Angel's in the room. I saw her earlier she's helping with questions. She leads one for a database and AI services, um, and it's a really important and valuable mechanism for not only getting the leaders engaged in understanding the security issues like in going into the depths of the tech to understand what happened. Um, but it's also a really great way to efficiently get the right stakeholders and really smart, unique differing perspectives together to make sure that you're solving these difficult security challenges in the right way. So we have it every single week, um, in that meeting you'll see we have just a very simplified agenda and, um, you don't see it in the picture I put but in our tables discovered by is one of the first fields in there so we always know who the engineer was who who discovered it. Um, and then I, as an engineering leader I use this meeting because I'm like great, I have all these people in the room. Let's make decisions. So if we're figuring out a priority decision or if we go option A or option B, I actually use it to drive decisions because I have all the right people there already. Yeah, it's awesome, um, and then we use those metrics like the discovered by metrics to say, are we increasing the number of. Times engineers are identifying things or internal teams are identifying things versus us finding out they're a customer or bug bounty or an external researcher so it's a great metric for you to use to measure kind of the progress you're making, um, so a real life example of how this weekly security meeting can add a lot of value is, um, recently, you know, we learned about an overly permissive console policy. With a service that an engineer had reported um we looked into that within um our normal te opps response process the engineering team identified a fix um that all happened between like the few days of it being reported and the weekly security meeting we then came and reviewed it in the weekly security meeting. And one of the security engineers in the room at that time said, well, what about this? And it was realized like the fix that they had implemented actually wasn't as um comprehensive as we were expecting it to be so it was a great way to them to for them to really poke at all the different um access paths and issues with that policy. We then went and the service team went and updated that fix so that it could be more robust um and that kind of shows the value of that kind of mechanism and then that brings us to our next point which is the systemic change, right? So you can address the issue you can fix it, but then you're gonna ask yourself how do we make sure this doesn't reoccur either in this system or across all the other systems and this is, this is where it all connects without. A step you're just gonna have a lot of security issues and a lot of addressing you need to go back and ask for the long term systemic change and what that looks like and we asked this a lot in our weekly security meeting what other services can be impacted by this risk? Do we need a correction of error which is a little bit longer format to kind of dive into why this happened, how it happened, what other systems have the same pattern. Which then brings you to action items is is there tooling that needs to be updated? Are there mechanisms that need to be updated to make sure that nobody has the same whoopsy, right? And so the goal is, is if you discover some a security risk is that all systems around you don't discover that same one or if they've discovered they have it too, they have a good path, uh, to remediate it. And we have this debate a lot in that weekly security meeting of central ownership versus distributed ownership. Should this be a central team building a tool to make this easy? Should this be, uh, updated to our existing tooling or should this be on the team that owns the system and we try to make it. Easy as possible so that we hopefully can avoid a campaign of like hey everybody go do this one action in your code but sometimes it does happen where we need a campaign and we have to say OK how do we make this as easy as possible for everybody to update um. I'm sure you've all uh lived through some campaigns especially if you're around and what was that 2020 there's some security issues that everybody was front and center for um and so um but be vigilant for issues that have can have can have cascading impacts and always ask yourself the question what other services could be impacted by the same pattern it doesn't have to do the exact same thing, but the pattern really matters here. So what you'd wanna do. Is in this situation we as part of that weekly security meeting said OK, how are we going to prevent new policies, new console policies from having the same really permissive actions that it had in it and obviously we said well let's just block those. Why would we even allow those policies to have them well they're. exceptions and extenuating circumstances which I'm sure that you all um experience and so that's why we hadn't blocked it to begin with and so then we decided to leverage Access Analyzer actually um to go and assess all the existing sign in policies to determine where there might be. Um, other issues similar to what we had already identified with different actions and sure enough it it found a couple that we really needed to look into which then started that flywheel over where we went and went through what's the best way to to lock down those policies um to meet the needs, um. Of the customers, so I once had a boss that said never let a good security issue go to waste, right? And so if there's something you've been trying to push through your organization and you're like oh if we had just changed that, if there's a security risk that actually gets surfaced about it, use it to implement the long term change. It is the best way to get something done. But it's a delicate balance because as someone in security I don't ever wanna be perceived as someone who you can't do it all the time, but you can do it sometimes um alright so we've completed our first flywheel so we've identified, we've celebrated like crazy. Pickles's got all the carrots we've addressed our issues maybe some of them we found weren't issues, some of them we did. We've made the systemic changes, but there's more. And so we hear this myth a lot. Engineers need robust security training and knowledge. Well, I beg to differ. I think that there truly is no compression algorithm for experience in the space and because security is quite ambiguous at times and scary and there's risks involved and a lot of stakeholders, engineers are wobbly about it and they don't like dealing with it because it comes with all this other stuff, um. And it just takes experience and being involved and so I always, you know, I, I, as I ran the Guardian's program, um, I always got questions about like what training do you give them and I said I invest in giving them experience um because at the end of the day we could spend hundreds of hours and dollars trying to build the best e-learning course you've ever had in your life. But it doesn't get you nearly as far as getting them experience and that's another value of that weekly security meeting because they get to come and hear how we talk about these issues, um, and learn the questions that are being asked in the areas that we're poking so that they can continuously get better and improve over time. And so as a leader your job is to make sure you're pulling in people continuously so that they gain experience or they use their experience to help somebody else gain experience and so hey Dan, you were helpful guiding this one team we have a similar issue. Can you come in? Hey Danny as our team security engineer that's the kind of map to our team, help us calibrate this risk and then they he walks through it with my team and like gets them to understand so the next time they can do it on their own or it's a little bit faster. Also realize a lot of your engineers have this knack and interest and desire to understand security more to get better at it, foster that encourage it um I've had multiple engineers on my team go from engineer building systems all the things and slowly they migrated their way over to be a security engineer just because they got curious and they learned and so um. Do foster that because it just helps if an engineer knows the systems and they have a lot of experience with security it's just like it it's so good for your systems it's so good for your security culture. And create a community for those individuals whether it's through a formal program like the Guardian's program if you haven't heard of what that program is, it's similar to a champions program um at AWS we, um, as we started to grow so rapidly, um, you know, over 5 years ago now at this point, um, we had a long line of teams that wanted to go through an APSEC review because they have to go through. An AS review before they can launch and we kept running into these issues where it's like they're saying you're not moving fast enough APSEC and so we said well why are we not moving fast enough and it was because the teams that were coming to us ready for a security review, ready for launch weren't ready at all. They hadn't thought about security in the way that they needed to to ensure that they were ready to deliver something and ship something to our customers in a way that would keep them secure. Um, and so we said we've got to do something about it and so what we said is we need to develop engineers, software engineers on every single two pizza team to understand and think about and bring up, most importantly bring up security throughout every step of the process, um, so that's our community I think um you know we have a lot of different resources online and I actually did a talk earlier today going into more depths with this with another customer who built their own program. Um, so you can learn some tips from there, but if I were just gonna give you any tip if that's something that you're considering doing, just start very small and specific and enable those, um, engineers who get involved to um to communicate and learn from each other and talk about that one small specific thing. So for example threat modeling you could say I want this person um on this engineering team to help their team threat model every single time. Um, and, and give them a feedback mechanism for that one specific activity and um go from there. It also goes into the product design and tech design, right? So you have a security guardian this is how we use them early and often so that it's not so last minute. Exactly. Um, and, and then foster that sharing of information we talked earlier about the security persona and how it's really important for them to set consistent, you know, standards and expectations across the company. Um, I think the, the hardest challenge is like those may change or they might live in a number of different systems whether they're a policy or a standard or best practices just make give it, give your engineers one central place to get that information because if it's too hard to find stuff, um, they're not gonna go looking for it anymore um so that's just my favorite part of the slide I don't know if. Anyone sees can see it, but the little bar at the bottom, this is from one of our wikis, and I went there to take a screenshot and look what it says in yellow report an incident one click I I'm pickles. It's Friday night something's wonky report an incident, right? It's it's at the top of almost all of our security wiki pages or it all leads to one very simple intake form, very simple intake form. Um, and that intake form actually goes into the system that I have some screenshots on here, um, where every single security issue that gets reported, um, has action items associated with it. It sounds super obvious, but these action items need to have, um, owners. Estimated completion dates and an escalation mechanism for when if they aren't met um and that that accountability is really important because we can spend a lot of time in security diving deep into what's the right thing to do, what's the right path for what's the right fix. There's 5 different fixes which one are we gonna do? You can, you can invest in that and then forget to do this one important piece to drive accountability. Um, and, and a lot of those that time spent will unfortunately be lost because a lot of things are happening all the time and you have to have a way to inspect the work that's being done over time to fix an issue and the action items range from what is the specific mitigation to making sure we get accurate numbers on customer impact to long term plans and sometimes the action item won't be the long term plan it'll actually be like go figure out the long. Term plan and it might have a hypothesis in there and as a leader one thing to make sure is like this accountability is very helpful for me right because we're in a security issue we're gonna focus on mitigation we're gonna spin up another team to get the impact and I know this thing is waiting for me at the end to be like, OK, we will solve the long term problem once we kind of get through the initial the the initial risk and will you tell us what your or fish is real quick what your or fish. What's this other picture on the screen? I want you to talk about your hot topics meeting real fast. Oh, OK, um. I was like what are we talking about? You do. So I also, we do, we have security issues, but there's also long running things where you know you want to get better, right? Maybe you want to scrub your logs or maybe you wanna reduce your long term keys or um uh there's a whole slew of things where you just know you wanna get better and so every two weeks I review with my teens I call it security hot topics and this meeting serves two purposes one, so we have a list of all the places we know we wanna move and. Approve our security bar and I have managers as well as um our our principal engineers in there and sometimes some some senior engineers as well and we review it the other thing this meeting is for is if there's something hot and we have to make a decision, a priority decision and get moving decision an option decision we use that meeting as well and that's really really powerful. One of my favorite things I'll join that meeting and sometimes I'll be running late from another and I'll jump in and like Bridget's already. Like 8 ft deep into into some like issue and I'm like I love it though because although she is a leader of many many engineering teams she is deep in the tech and she's asking questions to understand what's happening, why it happened, what the different options are, um, and I think that that engagement from a security perspective from her as a leader is really really impactful. Never discount the power of leadership time and attention. Um, it is, it will get the right things done. All right, so we've completed our double flywheel, but, um, let's talk about how this actually lights up in your world. So this is, uh, a day in a week in the life of Brigid. Um, and so you can see my calendar. This is not my complete calendar. I wish it was this clear, but these are all the security related items on my calendar so you can see that weekly security meeting that we talked about. You can see my hot topics meeting that we talked about. Oh, by the way, I do an operational review where kind of, uh, security trend. This is where all our tooling items get reported in the operational review. Oh, and then we have a monthly roadmap meeting. This is where we also summarize what we're doing to improve our security bar, um. Then you can see there's this like pickles issue and it's 3 times that week and this is what we do we stand up both a Slack channel and a standing meeting until that issue is complete and we know the path forward and so I will join a meeting every other day to make sure the teams are moving in the right way we have the right risk calibration, we have the right urgency and that's the time and leadership time and attention that I'm talking. About and then we have one for a longer term security which is on Wednesday afternoon like a plan review. I also review my security tickets on an ongoing basis. Um, Jenny has been really helpful to summarize these for me, um, and then you can see I keep a slack channel of this would be a really bad week with 5, but I, uh, of ongoing security issues, um, and so they all get a slack channel and put the right people together and whatnot. And I think like I know that we're throwing a lot at you and we have a very robust culture, but you don't have to do all these things just start with one. You don't, it's really let's give ourselves a little reality check. Well, and I think, yeah, the reality is is all those things are done, they're not done to perfection. Like every doc that's written, we don't overindex on how was it written. We over index on what are we talking about and what are we fixing. And that I think the Slack channels help with that too because it allows like people of all different levels asking different questions and getting caught up on things so and it doesn't happen on day one. I've had a lot of people come up and be like oh my gosh, my team, they can't do all of this and it's like you have to chip away at it little by little so if you put your pickle hat on like when I bought him, he only went backwards and as a horse that's like not normal um and then he kind of got OK with water and then he started jumping things and they started. Jumping fancy things, so you need to invest in the the elements of this flywheel. You can literally just pick we're gonna start celebrating when people uh self identify. We're gonna have a common ticket with a bunch of questions for them to assess the risk really quickly. It just starts small and keep adding and this is how AWF got there. It was if I joined 11 years ago now. It was not this robust at all. It was, um, and we've gotten better over time. So where can you start? Number one, if you're a leader, and this is one message I just wanna really drive home, um, I had a new organization joined my organization about a year ago so cultures were a little bit different. The number one thing I did when it came to security was ask what is the risk? What is the risk and people would get used to pinging me and saying, and I told them I wanna know about every security risk, and I want to know what the risk is. I don't ask for the solution. I don't ask for the timeline I ask about the risk, right? And then you can ask, hey, do we have the right people. Involved and all that sort of stuff now my team sends me the ticket saying we cut the security ticket here's the risk and it's in the ticket that's very convenient and as a leader, um, I do track action items so this is something you can do. You can do this in any type of written format that you use in your company we use words like word uh docs and memos, um, PowerPoint, uh, tracking system. There's a ton of them out there, but track your action items to completion for your security risk. If you are a leader like the number one thing I hear from engineers is my leaders don't care about security. Um, when they're talking to me about security, you have to foster this culture. You have to bring engineering together, security together, business leaders together. If you are an engineer in the room and you're like my leaders don't care about security culture, guess what? In about I don't know, a week, 24 hours there'll be a YouTube video of this talk, and you can be like, Hey, look, use this YouTube, listen to this this talk, and we have to foster this in in our organization. Um, celebrate you gotta celebrate reporting and fixing security issues. Security topics can be a little grim sometimes, a little sad. We gotta keep it light, gotta keep it happy, celebrate the things, and then try to bring those, um, security focused individuals. Now you might need some tooling. Um, we do have it. There there are things that we've brought along in AWS, so you saw the screenshot of the security tracker, right? And these are editable. They have clear owners, they have clear action items, they have clear risk knowledge base. This can be a wiki. this can just be anything common where people who've learned through a security issue, remember you're using the security issues to drive that systemic change. We add it back to the knowledge base we add the solutions we have the problems, how to identify it. Scanning tools can help try to get them in the hands of engineers as much as possible and the number one thing you wanna be able to do is that any engineer or anybody in the company who identifies a security issue can escalate it. It's boring is they know what's gonna happen um and so and they're bringing in the right people. One thing that um Eric Brandwein has been really vocal about is that our security teams are around the clock, um, they follow the sun, so you're never pulling somebody out of bed and that's really nice so when an engineer does. But a security sub too and it is gonna be a long haul to fix it and all the things we have the right support that is um allocated for that and you have to really like consistently go back to say why wasn't this reported sooner who like when could this have been reported? I even actually just on Friday afternoon had an email come through at like 80 p.m. on Friday to my team and saying like hey if I'm an engineer saying hey I have this issue like can I. Someone on your team like help me look into it and of course I didn't read it until Saturday morning and the first thing I did it's like why hasn't this already been reported and luckily someone on my team messaged me and said I responded back immediately and said report it so like even us like we still have that happen and you know engineers are new so you just have to like consistently reinforce that and if you are a security person in the room and I know that some of you are, do not be the one that goes and reports it for them don't do that. That doesn't add value. That's not your job. Like that is their job to report it. Then you take you can come in and support the next steps, um, but like really try and encourage that the engineers and reporting it, yeah, so if you do all that, what type of culture will you bring to life? And so as an engineering leader I would want everyone contributing to identifying security risks and so how that would come to life is that they would constantly they would consistently know where they're gonna report it and how to report it. Um, you would give them a standard template for them to use so that they know exactly what information that they're gonna need and it'll drive this repetition of here are the things I need to look out for and be ready to report when I find something, yeah, and as a leader I wanna know about the security risk and I wanna know what the next steps are to address them or to chip away at them and I don't wanna be, um, I, I, I need to know about them, right? You wanna know that I do not wanna be surprised, um, so we. We like um uh leaders to be aware of them and so how do we foster that? So you need a regular consistent mechanism for your leaders to review and you need them to show up so if you're gonna go back and you're gonna say I wanna set up this weekly security meeting and your leadership says OK great you say I wanna make sure that you are always at that weekly security meeting like as like clear your calendar at that time or like let's not just go and like pretend we. Have one and you come for the 1st 3 weeks, um, so like set that expectation up front I think that's really important we even still I've had uh conversations with people uh over the past year where their leader wasn't showing up and it's like you that's a conversation that you need to have with them so that it really is in a mechanism that does what you need it to do. Leadership time and attention, it works, um, we want our engineering teams, uh, prioritizing the security improvements over time so you're constantly raising that bar. And this helps with the action items that we talked about how they come to life and then security clearly communicates security best practices. And I'll just kind of jump in here. One thing that like our teams have been really good, our security teams have been really fascinated like yes they communicate all the expectations of how to do security right, but in AWS they're taking it a step further and what they're doing is they're saying this year or for this quarter we're gonna focus on removing access to our or like trimming down access to our production systems or we're gonna work on uh cleaning up our logging right and by putting an intentional time and focus on a certain topic you actually move the needle rather than security being like. Do all the things, get them done now that doesn't help anybody. So prioritizing and choosing what the to go after has been really, really helpful from AWS security. Yeah, I think that's probably one of the most difficult parts of implementing any of these mechanisms is there's a lot that can be done and you know we would all love for all of our security risks to. Be taken, you know, like in a in a way that reduces like the likelihood of them ever surfacing again but the reality is is like there will always be risk um and so it's being able to facilitate the right conversation to decide what the right tradeoffs are and the right level of investment and there will always be a security backlog, right? And at Amazon we say security is priority 0 and I actually have a lot of engineers on my team come and be like well then we should drop our entire road map and just do security features, right? And so this is where the risk and the business need and how you balance it and are there other mitigations in place and whatnot um and so it is it is that's why you need leaders involved that's why you need engineers involved that's why you need security involved because it's a combination of all those three that make the right decisions. Yeah, I even had an uh software development manager come to me last week saying oh well I don't wanna go to the weekly security meeting because then I know I'm gonna have to drop everything and we're gonna have to like go and fix this whole issue and I was like that's not that's not the outcome that we're looking for from this meeting but the outcome is making sure that we have the proper discussion around what is the the right thing to do for customers and what's the right way to address it and having leaders in the room so that they don't have. To corral the leaders to determine what the right investment is. The best is when you show up at that meeting and then somebody gives you a simplified solution that's a lot easier and you get a bang for your buck. So sometimes that happens. It's exciting. Alright, so rounding this out, what to take back to your teams security is everyone's job. You don't get to say no, this is that's security they'll just fix it. It's security is everyone's job celebrate security first behaviors. This is how you drive culture of anything you want. Make reporting security issues boring, predictable and boring, and then use security issues to drive systemic change and tooling. This is where the flywheel actually completes. I think we're out of time. Uh, we'll probably be around if you wanna chat. I'm happy to chat about security culture at any point in time. Thanks everybody for coming.
