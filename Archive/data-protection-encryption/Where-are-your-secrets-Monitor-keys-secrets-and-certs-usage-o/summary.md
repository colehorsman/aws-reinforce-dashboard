# AWS re:Inforce 2025 - Where are your secrets? Monitor keys, secrets, and certs usage on AWS (DAP441)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=BgF6HEgPZq4)

## Video Information
- **Author:** AWS Events
- **Duration:** 55.2 minutes
- **Word Count:** 9,865 words
- **Publish Date:** 20250618
- **Video ID:** BgF6HEgPZq4

## Summary
The presentation focuses on monitoring and observability of cryptographic assets (keys, secrets, and certificates) within AWS environments. The speakers, Pravin Nair and Zach Miller, discuss a solution they've developed to help organizations track and manage these security components across their AWS infrastructure.
The solution addresses growing concerns around cryptographic asset management, including regulatory compliance requirements, post-quantum cryptography preparedness, and operational needs. It leverages services like AWS Security Lake and AWS Config to create comprehensive dashboards that provide visibility for different stakeholders, from security teams to executives and auditors.

## Key Points
- Organizations need better visibility into their cryptographic assets due to regulatory requirements (like PCI) and emerging threats like quantum computing
- The solution differentiates between logging, monitoring, visibility, and observability to provide comprehensive security insights
- The dashboard approach allows different stakeholders (operations, executives, auditors) to access appropriate levels of information
- The solution is available on GitHub under AWS samples for organizations to build upon
- Focus is primarily on three main services: AWS KMS, Certificate Manager/Private CA, and Secrets Manager

## Technical Details
- AWS Services Covered:
  - AWS Key Management Service (KMS) for key management
  - AWS Certificate Manager and Private Certificate Authority for certificate management
  - AWS Secrets Manager for storing sensitive information (passwords, API tokens)
  - AWS Security Lake for centralized security data
  - AWS Config for resource tracking
- Implementation Components:
  - Dashboard-based monitoring system
  - Integration with CloudTrail logs
  - KPI tracking for cryptographic assets
  - Metrics for certificate expiration
  - Resource usage monitoring
  - Role-based access controls for different stakeholder views

## Full Transcript

Welcome everyone. This is DAP 441. Hopefully you're in the right place today. Uh, we're gonna be talking about where are your secrets, where are your keys, where are your certificates, you know, we often see customers that wanna have strong monitoring and observability around how their secrets and their keys and their certificates are used, so that's what we're gonna cover today and we're gonna show uh a demo where I'm gonna talk a little bit about kind of to set the stage about what the services are. Um, and then we're gonna show a cool demo of these dashboards. So, uh, Pravin, you wanna introduce yourself? Yeah, um, hello everybody. I hope I'm audible till the end. Uh, my name is Pravin Nair. I'm a senior security specialist at AWS. I work with the customers in North America, uh, on their security issues, and this is one of the things that has come up a lot of times. So we built this solution. Uh, so that you can build up on top of it. Uh, we have published this in GitHub AWS samples, and we will share that link as well. But yeah, before we get started, uh, I just wanted to give you a little bit of background, but yeah, that's all. Thanks for being, uh, and I'm Zach Miller. I'm a principal security SA. I mostly cover our cryptography services, so if you have questions about KMS or private CA or keys and certificates, I'll answer those. I'll attempt to answer your, uh, security light questions as well. We'll see. Uh, I'm from Chicago, decided to rep that today. Um, so you know what we're gonna talk about today is, you know, what is observability first off, you know, how does it differ from like logging and monitoring and kind of throw a lot of those terms around so I wanna be crystal clear about what we mean by observability. Um, we're gonna talk a little bit about Security Lake Amazon Security Lake, because that is a key part of the solution. Some of the other services we use like AWBS Config, I'll, I'll touch on those a little bit too, uh, and then I'm gonna talk about, you know, what is our solution, what kind of KPIs or key performance indicators are we monitoring, uh, what are we looking at and kind of like how can you build on this to, you know, maybe productionize something like this in, uh, in your own organization. And then of course we'll leave time for questions at the end, but you know, want it to be interactive. I can see everyone kind of so please raise your hands if you have questions call them out happy to answer those any time feel free to interrupt. So what need are we trying to address? Probably everyone here knows this, but you know if you have a large organization, it's likely you're using cryptography somewhere. You're probably encrypting data, you're probably, you know, terminating TLS using a certificate. You have secrets that help you log into databases maybe. So oftentimes customers will have a lot of these different assets. And either like a regulation or um you know standard like PCI I think the new version says hey you have to have an inventory of your cryptographic keys, for example, right? And then you also have new uh I'll say trends or you know concerns like post quantum cryptography and, and kind of like a quantum computer potentially, uh, being able to break asymmetric cryptography like RSA, right? And so organizations now are thinking, OK, with post quantum coming, I need to have an understanding of like where am I using certs, what kind of key algorithms am I using? because I might have to go replace those in the semi near future, right? Um, but you also have things like operations, you know, maybe it's not a security thing and it's, hey, my operations team needs to know how often these keys are accessed because we're seeing like throttling or we're seeing, you know, um, potential issues or maybe there's a certificate that's about to expire, right? And you wanna be notified of that because if that certificate expires it might lead to an outage suddenly your, your web traffic, you know, uh, they're getting errors basically when they try to uh access your website so. Uh, security operations, just general security kind of, uh, you know, getting an inventory of what you have, but then you also have like executives oftentimes want to have some understanding like how cryptography is being used in their organization for the reasons I stated before and so we wanted to kind of create a dashboard with like high level things that your, your CISO for example could look at and say, OK, we have this many KMS keys, you know, we have this many certificates that are expiring in the next 90 days, things like that. Uh, and then lastly auditors, right? A lot of times you don't wanna give some auditor full access to your ADBS account to go see what's happening there so you can give them kind of a, a nice clean dashboard that shows what they need to see, give them more read only access to, you know, the kind of information they want to consume. Uh, so again, I, I talked about like kind of differentiating what is observability. If you look at this kind of spectrum here, obviously this is open to interpretation a little bit, but you know our, our view is you have logging, which is kind of like, you know, your cloud trail log it shows you this API happened it was a get secret value secrets manager call and so someone pulled a uh, you know, password to access a database maybe. Then you have monitoring which kind of gets more into like you have metrics and you're seeing like maybe you're starting to get to those KPIs visibility would be you know you're getting like performance and how the various pieces work together yeah I uh you know pulled this secret but then I used it to go access the database, right? Um, and then observability is like where you really get into like the more comprehensive. We have all these logs and we also are doing like some KPIs around what the performance looks like on these resources and maybe we're tying things together a little bit more, you know, I have this certificate is expiring and also it's, um, you know, associated with this load balancer, for example, right? And then we get into like what should we be observing I think there's a lot of answers here and we're not gonna cover all of them, but you know we we we we we wanna think about like I am roles and I am users how many do you have? How many are they or how are they used? things like permission sets and I um uh identity center and root user actions maybe again we're not covering all this, so just to be clear, but you know S3 buckets databases you have all these different resources, right? And this is where this talk is really gonna focus the cryptographic assets. Um, I think, you know, if you really were to build some of this in production you'd want more than just this, you'd want to get into IM roles and everything else, but you know, cryptography is my thing and I like talking about it, so that's what we're focused on. Um, and I mentioned some of these services earlier, but these are kind of the three main services that that we're monitoring, um, and kind of creating that observability around. One is ABS key Management Service or KMS. Probably a lot of you are hopefully actually who, who here is familiar with KMS or uses KMS? Hopefully everyone or close. OK, perfect. So you know that's our, our key management system. You almost think of it as like a key vending machine. It spits out these keys that other services like S3 and uh EBS can use to encrypt your data. Uh, we also have certificate manager and private certificate authority. These are for, you know, as it sounds certificates can issue certificates, associate them with load balancers, issue certificates from private CA for things like code signing, email encryption. And then of course we have Secrets Manager which can store really any type of secret but you know it's primarily by customers used for like database passwords and API tokens sometimes SSH keys things like that. OK, so let's look at like what a typical security journey or observability journey is for a customer, you know, maybe you start with a single application, maybe you're like a small business or you're a large business, but you've just started on ADBS and you have one app, a couple of rolls, maybe one KMS key, couple secrets for a database that's not too hard to monitor, right? You can kind of manually look through cloud trail or, you know, kind of look at the console to see what's happening. It's not too big of a deal. When you get into multi-application, you have 10 applications, a bunch of different roles, maybe you have 100 secrets. OK, you know, you could probably still maybe do that. You, you want some processes, but you might be OK to do that manually when you get into global scale, a bunch of different regions, this becomes a problem. You, you can't just go through and kind of manually rock through these cloud trail logs and say, oh yeah, I know everything that's happening with my secrets and my and my keys, um, and this is where you get into. You gotta start aggregating these logs and and trying to visualize them and understand what's really happening. So I think that this is kind of the the target we're we're trying to get to is, you know, somewhere in that multi application or or global scale uh realm how how do you monitor and how do you observe your assets in that world? OK, so the service that I, I think I've mentioned once or twice, but Amazon Security like, who here uses Amazon Security Lake or is familiar with it? Couple of people. All right. OK. So I will start by saying, you know, the problem that security like was set out to solve is this kind of world where you have all these different assets, all these different services, you know, I already mentioned like the cryptographic services, but you have a ton more, right? You have VPC flow logs, you have DNS logs you might have all these security agents including partner security agents, right? And they're all kind of making their own logs and you want to be able to aggregate those and have them understandable right? because they also probably have different log formats too. And so in the past you'd have to maybe create like custom lambda functions and pump all that into S3 bucket and try to normalize it yourself and like parquet or some other type of format and you know it became challenging for customers right because that's not even all that's a few of the things that you could have, but there's tons of partner solutions that have their own logs and things like that, right? So Security Lake was built again to address that need where it does a lot of the operational heavy lifting for you in terms of like setting up your data lake by creating a 3 buckets and glue tables and things like that, but probably most importantly it normalizes all the data for you. Uh, and I'll get into that a little bit more in a second, but that's kind of why, or one of the main reasons at least we picked security like for the solution we built is makes our life easy, right? Like we, we really don't have to do all that operational overhead to set it up. We don't have to like try to get every single log format from every single type of resource into, you know, the right format so we can run queries against it and Amazon Security like just makes that easy, right? You kind of click once, you turn it on and it starts gathering that data and aggregating that data. At least for the the resources and kind of streams that we are interested in. Um, I talked to us a little bit, but you know what's really happening under the hood with Security Lake is it's basically building those S3 buckets for you where you're gonna store the data. It's creating those glue tables that you're gonna use to kind of index the data and do ETL and all that stuff so that you can go and query those, uh, you know, that data. And it's normalizing it into OCSF and let me see if I can get this right. I always forget it's open secure uh open cybersecurity scheme of framework. So that is a, uh, framework that we built in collaboration with um Splunk and um I think 18 other partners that, um, you know, helps you to create this like kind of standardized format for your security log data. Um, yeah, and so I think like that again that's why we picked security or sorry, Amazon security like because it, it kind of makes our life easier in terms of normalizing that data. That's the main thing. It's not too difficult to go create those S3 buckets. It helps that it does it for you, but the normalization is really the key point. And so you know at the end of the day you come back to this model. If you remember the earlier picture it has all these crossing lines and confusion. Now we just have some data sources. They pump all of that into Amazon security like, much of it automatically if you don't have like custom sources. Ours is all kind of automatically gathered because they're all AWS services. And you can have subscribers. We don't really have that in this model, but you might, uh, if you were to do this on your own in production, um, and then you can use automation to do remediation. You can do visualization like we're doing here and you're gonna see in a second with Amazon Quick site, but you know, much cleaner model, much easier to kind of ingest all that data and use that data, right? One other thing I wanna call out is, you know, you might ask, OK, well I have a bunch of accounts. I have a bunch of regions that I operate in. Do I need to build this in every region? No, that is a nice thing as well about Security Lake is you can roll up into, uh, you know, one region basically or multiple. And so like on this slide for example we're showing, hey, if you have data residency requirements, maybe you don't want all the logs from your KMS keys in North America, you know, to go to some region in EEA or vice versa, probably vice versa and so. You know what we do here is everything's in in um North America and so we roll it up into USC one but you could easily have multiple roll up regions where OK all my EMEA data rolls up into one of the EEA regions and my North American data rolls up into say USCS one. So just wanted to put that out there that while we're not doing multiple roll up regions you can absolutely do that to have that um data residency in place or protections. Question, any questions so far? I didn't stop yet. No, OK, I know everybody wants to get to the exciting demo part. I'll, I'll be quick. So security lake sources, there's a, there's several of them here. We're really focused on cloud trail logs and security hub findings here. Um, some of these others weren't quite as relevant to our use case, but you can absolutely pull in, you know, DNS queries from Route 53 and your flow logs that tell you what kind of data is coming, um, you know, into your BPC. Uh AIS confix, so I didn't talk about this yet, but there are a few things that we wanted to get out of, um, you know, our logs basically that you don't get necessarily inherently in cloud trail. So as you probably know, Cloudtrail is focused on API calls. So when you know you call it decrypt action against KMS, that's in cloud trail. When you create a key in KMS, that's obviously in cloud trail, it's an API call. Same with get secret value and things like that for Secrets Manager, but you will not see in cloud show events that happen that are not an API call. So imagine, you know, you're rotating your secret and Secrets manager that, you know, creating or enabling the rotation, that is an API call, but the actual secret rotation itself, not an API so that will not show up in cloud trail. So there are cloudwatch events for that and we can get that data as well in in config and so Praveen's gonna talk about this in more detail but you know we created um custom config rules that would look for things like. Is this has this KMS key ever been used? When was the last time it was used? Things like that. And that's a pretty common one from customers is, you know, how do I see the last time this key was used because, uh, you know, one of the reasons I don't think I talked about it earlier that you might wanna do this is cost reduction, right? Because say you have, I don't know, thousands. Thousands or maybe more than that, hundreds of thousands of secrets and KMS keys, you know, these things can incur costs, right? Your, your customer managed KMS keys is $1 per month and so if you have hundreds of these or thousands of these or tens of thousands of these, you might see your costs start to go up in a way that you don't like, right? And so you want to, uh, reduce those costs, but you might be concerned, what if I delete this key and the data that's associated with is now gone, right? Um, so that's why we wanted to create something like this to show you, OK, this KMS key has never been used. That key is probably fine to delete, right? If it hasn't been used in, say, 90 days, I would say maybe keep it around a little bit longer to make sure no one's using it because there are services that don't call KMS very often like EBS for example because it only calls KMS when the volume is detached or reattached or the instance is restarted. So there are some caveats with this, but you know it does at least give you a good view of like how often are these keys being used and are there ones that, you know, maybe it's only been used once in the last year you can reach out to the application team and say like do you really need this key you know if it's a development key maybe they get rid of it, you save some money, right? Um, oh, so I guess to kind of follower, uh, there we go, to finish up on the config thing that that is why we brought in config is because it allows us to. Um, you know, create those custom config rules with lambda functions. They get you some of that data you can't just get from Cloudshare by itself. um, and then the KPIs we're really looking at for these different services. Uh, I'm not gonna read through all of them here, but you know we're kind of looking at what are the I IM rules that are, um, getting a lot of access denied because that might indicate someone's trying to access something they shouldn't or it's just an operational issue that you probably wanna fix, um. You know you have custom managed keys that rotation is not enabled. Uh, one slightly controversial thing, uh, that ABS does is we say, hey, you probably don't need to rotate your KMS keys unless you have a regulatory reason for it. There's a bunch of reasons for that that if you wanna get into it, find me afterwards, and I'll, I'll talk to you about why we say you don't necessarily need to rotate your KMS keys, but a lot of customers say, hey, I have to do this, you know, I, I have an auditor that tells me I need to rotate these keys and so, you know, we have a rule in there that's looking for where is KMS, um, where, where are your keys that they don't have rotation enabled. Um, again, I talked about the unused keys in 90 days. That one's really for like cost reduction. Certificates, you know, we wanna see what are your top secret operations. That's more of like a kind of standard operation thing just to see what kind of API calls are coming in. But then you also have things like when are my certificates expiring or I guess which ones are expiring within 60 days. Um, and so that that can help you understand, you know, where you might need to go out and manually replace certificates, you know, for ACM, uh, to be certificate manager, there's a thing called manage renewal, and so it will automatically renew those updates or renew those certificates, but that only works with what we call like integrated resources, so like application load balancer or uh API gateway. We can go rotate those certificates for you essentially. Uh, with no action needed on your behalf, at least if you use DNS name validation. Um, but there are cases where maybe you have that private certificate on like an EC2 instance. The for certificates, so yes, it will be in cloud trail because that is a new um certificate basically like when we rotate the certificate we're basically just issuing a new one and so you'll see an issue certificate call yeah exactly there won't be like a renewed it won't be a renewal API necessarily it'll be another issue certificate call but you will see that mhm. Um, a good question. I think there was a hand behind too. No, OK, um, yeah, so, so again, certificates, big thing there is, is expiring certificates because you wanna avoid outages, right? Secrets manager secrets um you know we do show the breakdown of like what how many or what percentage of your uh certificates are like get secret value versus describe secret and that can kind of be helpful in terms of like we have a, a standard kind of breakdown of what we expect that to be like you should probably see mostly get secret value of people kind of retrieving that secret if you're seeing like a ton of uh you know put secret value over and over again or these other things like I wouldn't say it indicates anything malicious but it's a little strange. So you might wanna look into that, but then you also have things like when are the secrets accessed which secrets are most frequently accessed and things like that, right? Because that might also give you an idea of like what are my, you know, crown jewels for lack of a better term, like what, what are the, the secrets that are really, really important, OK, we have tons of people accessing this all the time. It's an important secret, things like that, um, and then similarly we can look, you know, we're looking for unused secrets in the last 90 days again, maybe you can go out and delete that, reduce your costs, right? So there's some breakdown of what we're looking for and now I'm gonna pass over to Bravin. He's gonna talk about the architecture and then do the exciting part which is the demo. And I will also say we, we, we'll show this in a second, but we'll pull up a QR code here pretty soon. This solution is on GitHub, uh, so you can absolutely go check that out while Praveen's showing the demo, uh, and after, and, and, you know, use it yourself if you'd like to. Yeah, thank you, Zach, um. Hello, everybody. So I'll go over with, um, with the, with the architecture diagram, but before that, I know, I just want to emphasize once more like, Let's talk quickly about the scenario once more like what we are trying to resolve, right? Like imagine you're a security lead and you're working on an organization. You have an AWS organization set up that is growing and growing and you have multiple accounts and you want to make sure that your KMS keys are rotated, your secrets, you know, are not exposed, and your certificates, you are aware that they don't get expired before, um, and they don't expire and you don't go and then they go, they don't go unnoticed. So basically you need to be aware of what's happening there. Now, all this has to be done in a centralized way and obviously, you know that there is no direct out of the box way to do this centrally, right? So. How many of you actually faced, have faced this problem, or actually facing this problem? OK. So, that's the problem we're going to solve today, right? So what we want to talk about. Can I ask, like, how did, I'm just curious, how did you solve it? Or have you solved it? We so So. like automation to the APIs. Yeah. Sociographic Oh OK, yeah, I was just curious because I, I always wanna hear how customers solve these problems. Sure, OK, thank you. Yeah, and so we're gonna be using AWS Native Solutions, uh, which will help you monitor these uh metrics, uh, and uh assets, and we'll, we'll, uh, capture all that for all the key information, the certificate information, and the secrets manager information so. Just to go through a high level of the solution. This is the high-level architecture diagram of the solution, uh, that we are going to be talking about. Uh, it starts all the way, uh. From the right side, uh, where's the cloud trail logs. So we're gonna capture everything from the cloud trail logs, which is all the actions and API calls that are happening, uh, for your crypto services. Second, we're gonna use AWS config rules to identify some custom configuration changes in, uh, in your crypto services. Example, unused KMS keys. There's no direct way to get it. You have to actually call the API and get that data. Um, see, um, and then there are others like unused secrets, um, DNS validation pending, that's one of the things like I you somebody tried to issue a public cert. The DNS validation was not completed. The er is just lying there. it is pending, so you can identify that. How do you do that? You write a custom lambda config rule, and we'll talk about that as well in this session. All you need to know that AWS config doesn't have a direct integration into security lake, so the data from findings from config rules don't go into security. That's why what we do is we use security hub. So if you see the diagram. We are using security uh security hub to get that data in. So the funneling is the rule identifies non-compliance, and that goes into security hub, which goes into security lake. That's the flow we have done. The next thing is, what is security like doing here? It's normalizing all this data from different sources and it's doing all the ETL at the back end and it's kind of making it ready. It is creating a database. It's creating the tables that you require to query this data, whatever is collected, and you will be and we will be using Athena to query those. And once we use Athena to query those data and I'll show you the queries that are written. And you can use that to now visualize it in Quick site. So we will use those Athena queries that we create and query in security lake. We will put it in a quick site and we will visualize however we want to, and that we'll show you all that. Right. So any questions until now on the architecture and design right now? All right. One thing I meant to ask, and I didn't ask, is everyone here like familiar with cryptography and stuff like when I say DNS validation of a certificate, do, do you know what I, what we mean and everything? OK, perfect. If, if, if any of that is unclear, please raise your hand and ask. We can there's a question for that yeah, perfect. Thank you. All right, so. That's the codes. um, you can scan it, you can look up, uh, in the GitHub. It should be available now. Uh, we have created a detailed read me step by step explaining how you can install this solution and start working with it. It has the, uh, we have the cloud formation templates and everything, uh, in there. So I'll keep that up for a few seconds as I start my laptop. Yeah, and while he's pulling that up, one other thing I'd say is this is definitely, you know, a sample and not, uh, you know, not fully something that you would productionize necessarily and so what we want from y'all, if you don't mind is feedback, right? So like if you wanna, you know, make pull requests or comments on the GitHub for things you'd like to see or come up and find us after for things you'd like to see, we, we'd love to add more to this and continue to kind of build it so definitely let us know about that mhm. Mhm. Um, no, so, so we don't do any like cipher suite monitoring in this. I would love to add something like that. Um, yeah, that would be great. OK, this is a whole other topic that I could probably give an hour long talk on, um, find me after and we'll talk about it. My short answer is. It is a difficult problem because you have to look at the cipher suits from all these different services and all these end points, right? You might have EC2 instances running IAS that are using old cipher suits. You might have an ALB that, you know, you can set security policy on there. So yes, it is definitely a problem that customers are, are facing. We, uh, I will say are looking into ways to resolve that at AWBS. I don't know how much more I can say than that, but if you find me after, let's talk about it because yes, that is a, a big challenge coming up for customers. Good question. All right. So, um, let's get started with the demo. Um, the first part that we're gonna look at is the AWS confit side, and I'll walk you through the conflict. All right. So Well, let's look at uh unused KMS keys. So this is a custom lambda, uh sorry, this is a custom uh AWS config rule, and this rule is created uh to check if there are any CMKs that are not used in the last 90 days or if there are any CMKs that not that has never been used at all. And this is, uh, installed across regions and accounts. We have a lambda function at the back end that is being called and uh which is basically going to check and I'm gonna show you the code for the lambda function as well right now. So if you can see, this actually runs periodically every 24 hours right now, um, and it already has a couple of keys in our demo that it has identified that's never been used. um. And this actually directly goes into security hub findings. So this is the security hub side of the things, uh, if you see a new secrets will come up here as findings and you can see these come from these are coming from different regions because we have set it up to get the details from different regions and also multiple different accounts so unless, uh, yeah, so, so these. These two are 2 different accounts. You can see the last four digits and identify it. So it's multi-count, multi-region set up right now. Now let's look at the lambda function that is being invoked. This is the lambda function that we created, and this is available in the uh in the GitHub as well. Uh, what it's doing is actually it's using, uh, the first, it's using list KMS keys, and it's going to get the list of all KMS keys. And then after that, Uh, which is what it's doing in key evaluation section, and once it gets that data, it'll go and call describe KMS key to check, uh, when it was last accessed, uh, or whether it was ever accessed or not. Now I would definitely, uh, say one of the things that we would do in the next few weeks is change that never access to first check whether. That key was created 90 days before. We don't want somebody just created a key today or tomorrow to show up on the dashboard. So that's something you can change off and say, hey, you know, I don't want, I want to make sure the key was created at least 60 days or 30 days or 90 days behind back. And it's still never used, so that's a very good good important thing to filter out. So that's something that you can change. You can download this code and update as you want. So once it identifies that it tags it as, uh, it basically tags it as compliant and non-compliant. If it is not compliant, it goes and shows up in se uh in your security hub. Um, Just um. Once this evaluation is done, uh, this, yeah, no, it's not so OK, tag may not be. It would set its status that is an attribute status attribute which you can see here. Um, Thank It will set it up to noncompliant if it is falling in that direction, OK, so it's, it's basically, so every confit finding has a, uh, Jason format values and attributes, and that attributes is set to noncompliant. So once we have done this, the next question, um, the next question comes in like, how do you install this AWS config rule across multiple accounts, multiple regions. Within my organization, what is the easiest way to do that? Because you don't want to go into each account and region and install this, and you also want to have some control on how you pick and choose these accounts and regions because you may not be using all the regions that are available, right? So for that what we have created is a cloud formation template and we'll walk you through the steps on how to do that and those cloud formation templates are also available online, um. What we are going to do is we're going to use stack sets. So we are going to create a cloud cloud formation stack set. Everybody is, everybody's used cloud formation here anybody who all have used cloud formation. OK. Alright, so if for those who have not, like it's an automation infrastructure as a court service available in AWS and you can install stuff using that, uh, across, uh, your organization and accounts. So the next. Let's go to the cloud formation template. The only thing you need to know is uh to run the stack sets in cloud formation. You need to actually run it from the management account to create the sets. Um. Let's see. What I'm going to do now is I'm going to create a a stack set. So I have the command. So this one is actually going to create a stack set. If you look at this command, it does a couple of things. Uh, first, it creates an unused key stack set in your management account. It takes, it's asking for two parameter values, which is one is the primary region and uh the role, the name of the role that it needs to create to run these actions. The this is very important because when you create a config rule within an account across multiple regions, right, uh, IM rules should already be only be created once because IMs are global services, so you, you cannot create a role every time it runs in each region. So what we have done is we said make one region primary and just create your role while you're creating config rule in that region. Once it's created. Uh, you're good to go. You don't, in the next iteration of the same account, different regions, you don't need to again create the IMO. So that's basically what it is. So I'm just gonna copy this in. to the. And you can also look at the cloud formation template in the code, uh, in the GitHub library, which I'll walk you through. Yeah Who That's Uh, that. So that should create the tax set. in the wrong time. So So this is the stack that it just created. KMS on new demo. Now, what I need to do is make sure this is installed in every region and account. So for that, we have, and all these commands are also provided in the GitHub repository. So let's look at this one. we are using, um, service, uh service rules so that management account can install stuff in uh child accounts or member accounts. Uh, so what is, there is one thing that we need to be understanding is when you use uh managed service managed role uh for creating stacks across multiple accounts, you need to use your organization unit ID. And you need to make sure you give specific accounts if you want to only do it in specific ones. So what this command or that line of parameter is actually doing is Of all the accounts in that OU. I only want to install it in this specific account 3606. And that's why I put the intersection as the uh as the uh filter parameter. I can also do a union. So if let's say I want to do this or you all accounts and a set of accounts from other location, I can do that and I can just say create a union of all this and install it in those accounts. And then over here in the region section, I specify which regions this uh will go and install it. So all I, I'm doing is I'm gonna install it in this account in US West one region, and all I have to do is run this. Yeah And remember, this has to run in the management account. Once it's run. Uh, let's go to. It should be running in this account. This is the account. I. This is the US West one account and you can see this stack that is the stack is actually running in there. Once it's created, it will actually go in and create the config rule for you now while it's doing that, let's look at the. AWS sample. If you see, this is the config rule. And in this there are 3 very important things that we need. One is obviously The parameters that we are passing the primary region and that what we talked about. The second one is the IM roll. You need to make sure your IM roll has the right access. So if you see, this is the IM roll that the lambda function is going to use to scan through your KMS keys. So, make sure it has the list key and describe key uh available to it. I put the whole lambda function inside the cloud formation, you can keep it outside and import it as well. I And then This is where you This is, this is very important. You need to make sure you give the AWS config access to invoke that lambda and that's what that code does. And then this is the actual configuration rule that is in part of it. Now you can create multiple config rules like this which is specific to your requirement as well. Uh, let's go back and see, um. There you go. So this is create complete, that means it's created the resource that we need. So we have the config rule created. If you go to AWS config rules over here. You should be able to see. The unused game is key rule over here created. It just ran right now, so it just ran right now and it collected the keys that are not compliant. So now that we have the cloud formation we are able to uh install it multiple accounts. Now let's uh switch and go to uh go and see what the Athena side of it where we are actually going to run the queries. So like I said, when the data is created and everything is collected. You can see this database that is created by Security Lake. This is where all the findings is coming in and you can see these tables within that database that is created by Security Lake again. This is all done out of the box. You don't have to do anything. It's created on its own and then you can run the query uh that you want to identify. So what I'll do is. I'm running this query. And keep an eye on the table, right? So this table name is actually going to say SH or security hub findings 2.0. That is where all the configure details will show up. If you run that query right now and I'm saying. The name of the config rule that was run, it will actually collect all the data. From across region, and you can see this is kind of not something like readable, but all the data is in there. And this is across multiple accounts. And regions. And again, the reason we're taking the config data and putting in the security hub is because of that lack of integration, native integration with config and Amazon security lake so we put it in security up first as a finding and then that goes into the security lake. And similarly, you can also do the same with The cloud trail details. So this will have all the, uh, this table will have all the data related to X KMS. And all the actions that were performed on KMS. Once you do this, now you have the query, you have to build a query to actually meet your requirements. So this is a sample query that we created to identify all the unused keys across, and we have provided the sample queries that we used as uh in the code as well. This actually, uh, I always selected. This actually would give you all the details of unused keys. Uh, and also It's All right, so this is a little bit more formatted. We had to use some little bit of reg reg x and stuff like that to get the actual data we need, but you can see the data is more clean over here and you're able to see the data. But this is not enough. We want to go go ahead and try to use this with uh Quicksight, right? We want to have some visualization on top of it. So once you have your Athena query here and you have all the data, all the columns that you need, you have identified that for that visualization, we go to uh Quick site. And this is Quick site And over here we create, we use that same Athena query and create a data set. So in Quicksite, you'll have to go, so Quick site, how many of you actually are aware of what is Quicksite? All right, so for those who don't know what is Quicksite, QuickSite is basically an AWS service to visualization, creating dashboards and stuff like that, um, and it has direct integration with Athena, so it's just easier to build it. If you have any other services that can integrate and query and build dashboard on top of Quicksite, uh, on top of security lake, you're happy to use you can be use you can use that as well. There's no issue with that, but we just, we are using, uh, Quick site over here. Now, what I can do is I can actually create a data set. I'll say, create an Athena data set. And I'll just give the same name. Now when I created one thing you need to be aware, this can only work if your Quick site has access to your database and at the back end Security lake is actually using lake formation to give you access to the database so you'll have to do some configuration to make sure the right access is available once you create that. You will be able to see the uh security late database inside the code, uh, inside your uh dashboard like you're seeing right now. That means your configuration is right, and it has access. You'll use custom SQL, you'll put the query, you'll put the query that you created over here. Oh I will go to preview data. So this is where it creates is uh is it. I'll click Apply. There are 2 modes to creating data set in Quick site. One is direct query and one is spice. Direct query is every time your dashboard loads, there is a query that will run at the back end and will get the data and show on the dashboard. It's a little slow and I'll show you when I show you the dashboard how it looks. But if you use spice, It caches the data, it runs the query once and it caches all the data and keeps it for you. And once that data is there, it'll just directly show on the dashboard, so you, your dashboard won't have the buffering part of it. But the trade off there is it's not real time data, right? It's, it's at a point in time. Yeah. And you just save We And just save and publish. So now that this is saved, this means this data set is now ready to use. You can create a dashboard using it. Get back to that. So all you have to do is go to analytics, go. Unified dashboard. So this is the existing dashboard that we already created with all the data that we are gathering right now, right? So if you see quickly like this is for KMS, uh, we have the most operations that are being performed by KMS, uh, which are the top keys, uh, without rotation enabled, uh. Which I am role has the most denied? Access to like which one is getting denied when it's trying to access. So this is very important just to know. Um, there are like 7 unused keys and then we have tabularized the data at the bottom. Wherein it actually goes and gives you a little bit more details about what those keys are doing and stuff like that. Similarly, we have created for certificates as well. So if you see upcoming certificates in the next 60 days and stuff like that. And the same thing we did with Secrets Manager. one can you go back to the certificate screen? This is a real world example of something I've seen customers do that this might be useful for kind of an odd one, but the interesting one is like I, I'll see customers that say, uh, you know, we have, we've like kind of centralized our PKI and we only want certificates issued from this account, right? Like this is where we get our code signing certificates and where we get all these private certificates we use for our PKI and so. You know those customers put in place like uh SEPs or service control policies to say you know you can only create a CA in this account or you can only issue certificates from this account and get distributed elsewhere. It's not that common that the CA one is a little more common, but I you know I did work with the customer that wanted all the certificates kind of issued in this account, at least for private CA and so, you know, they might look at that and say I see other accounts issuing certificates in my environment. I see other accounts that are creating CAs in my, uh, organization, and I don't want that, right? So like I think. You know there are some interesting ways you could, you could use these dashboards or similar dashboards to have a detective control or or kind of uh a way to analyze how these are being used across your or and kind of vet your uh preventative controls right? like you always kind of want that detective control defense in depth kind of thing to catch anything that doesn't get caught by your preventive controls and so I do see customers use like dashboards like this for those types of things where what is the efficacy of my preventative controls I put in place, right? Right. Yeah. No, that's a good point. Um, now we can add the data set that we created. From here Yeah. You And I can't remember if on the post quantum question, did we, did we include key algorithm? Is that something we're looking at? I don't think it is, right? The algorithm like for certificates that you issue like if it's the RSA or ECC. We didn't, but you, you can modify the query to get that information. You have to write unless it's part of the two things you need to be aware of. If it is not being logged in cloud trail, you'll have to basically write a custom config rule or something to get that detail unless it's being published somewhere. So there has to be a way to get that data like so you could look for I mean. Today in ACM you can't issue post quantum certificates anyway because there's a whole other topic, but the, the industry hasn't really figured out what a uh post quantum certificate should look like because their size is really big and so creates problems so they're still kind of figuring that out but I think you know what you could do at the very least is create a custom rule similar to what we've done and look at the and the certificate field, you know, it tells you this is RSA key, this is the ACC key. Uh, ECDSA, I guess, and so you could look at, you know, how many RSA certificates do I have in use in AWBS, for example, at least from ACM. So you know, it kind of helps get you there. It doesn't get to all the cipherSweet stuff, but you could at least look at the types of keys you have, um, and I will, I will also call out on the post quantum thing. You may have seen a post last week. You can now issue, or sorry, you can now use MLDSA, one of the NT approved post quantum algorithms to, um, sign things with KMSs, which is great. There's a plug for that not related to the session. Thank you for so long He's I mean this is. Yeah. No, I, I totally agree. Um, I would say, you know, you're far from the first customer that has asked for that. We are a customer obsessed company, so it's something we're looking at. Let's talk after, um, but yes, I totally agree. I, I think while this is useful, I would much rather have a solution for customers where they click one button and they get this stuff, right? so. Yes, that is something we would like to build and we're looking at, but I can't say too much more than that, yeah. Can you come back to the secrets dashboard. Yeah, yeah, sorry, I kind of interrupted Praveen anyway, so I think he's gonna talk a little bit more about Secrets Manager too, but yeah, absolutely. Yeah, we try to simplify as much as we could on this with with cloud formation and security lake set up, but once you have security lakes set up, it's pretty easy. The only part where it gets a little uh work is formulating the query and showing it on dashboard to to the way you want. Actually creating the dashboard is also interesting. Um, you could actually use Q for Q, which is, uh, basically the GAI service for AWS. You can use Q for Quicksite and I can actually ask it. I don't know if I formulated the command correctly. I remember I don't remember, but it can actually create a graph or visualization for you as required, um, and it would actually do that for you, see. Yeah, I kind of love this because for that like executive kind of use case, I mean it'd be good for everyone, but I think like I imagine, you know, CIA is going in here and like uh uh I don't wanna look at these dashboards even right? like they can just type a natural language query how many key you know how many certificates are expiring in the next 60 days or I don't know, you know, some, some natural language to just tell me what I want or, you know, give me the information I wanna see, and it works quite well without really having to do any tinkering with it, so I kind of love this. So it could generally, uh, basically create, uh, create a dashboard which you can just directly integrate into your um dashboard site. So like, right now it just created one. All I have to do is click add and it'll add it. It's basically adding it. And this is what I was telling the buffering that you're seeing is because it's the direct query. And obviously, if you want to later change it, you can go here and change it. As well, the other good thing about QuickSite dashboard and Q integration is you could actually um get an executive summary of this whole dashboard. So if I click here, it would actually go in and give me an executive summary for Secrets Manager based on the findings that we have on the dashboard. So it's actually generating one right now. And this just gives you easily instead of going in each dashboard and checking what is happening, you can actually go and check the executive dashboard and get the details of what is happening. So it's a quick high level overview. So those are the key uh things that we wanted to talk about. So this project is a sample for how for you to get started on building uh a dashboard or monitoring capability for your crypto resources and we want, we want to make sure it helps you. Produce uh do cost optimization for finding by finding unused resources and also you should be able to um see if there are any risks like if there is certain kind of operations that are happening too much in your account, you need to be aware of those things. So those are the stuff that um that are the key, right? So it's it. thing. Yeah. Yeah, so I think, you know, like Praveen said. Kind of marquee takeaways we want you think about our, you know, think about what you know if you're building something like this yourself or using a partner solution. Uh, you know, think about what are the important important metrics for your business that you wanna monitor, uh, you know, focus on like specific goals that you have, we wanna clean up our resources to reduce costs or just reduce complexity. We wanna make sure we're being compliant and are able to easily prove that compliance auditors, you know, maybe, um, you know, whatever, whatever really your, your kind of key goals are, think about that beforehand so you can adequately prepare your data and your queries and things like that. Um, you know, follow our existing best practices for logging, centralize your security logs into one account, um, is, is one of our recommendations, and then, you know, kind of my obligatory tip as a cryptography person is encrypt everywhere, use encryption wherever you can. Encryption is offered at every in every AWBS service where you store data and almost all of them are integrated with AWBS KMS, so please do that. And lastly I wanted to plug another good reinforced session that is happening later. I forget the date. I apologize, but if you click that or if you go to that QR code, it'll it'll be the event catalog, and that session is really about monitoring your permissions on KMS keys and so it's kind of similar. They have some similar um dashboards and things, but you're able to actually see like when are the key policy or the, you know, the access policy on my KMS keys, how are they changing and who's changing them and, and so it's a pretty cool session, so check that out too. I'll leave that up for a second. And then lastly, thank you for joining. I really appreciate it and please take the survey and tell us what we can do better and what we did well, uh, and again like feel free to go to the GitHub page and and do pull requests or give us comments and tell us what you'd like to see us at and we definitely wanna keep building this and and adding to it to make it a more full fledged solution. So again appreciate your time thank you very much. Thank you.
