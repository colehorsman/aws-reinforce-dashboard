# AWS re:Inforce 2025 - Taming the alert avalanche: Cutting through SOC noise (TDR325)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=hZGJCAaS1f4)

## Video Information
- **Author:** AWS Events
- **Duration:** 15.5 minutes
- **Word Count:** 3,070 words
- **Publish Date:** 20250619

## Summary
This AWS re:Inforce 2025 session (TDR325) addresses the critical challenge of alert fatigue in Security Operations Centers (SOCs) and provides practical strategies for reducing noise while maintaining effective threat detection. Delivered by Rich Murphy from Greylog, the presentation tackles the reality that security analysts face thousands of daily alerts, with over 67% routinely ignored due to overwhelming volume and lack of proper context.

The session emphasizes that traditional approaches of ingesting and indexing all security data create unsustainable workloads for SOC teams, leading to analyst burnout and missed threats. Murphy explains how breaches often go unnoticed for 200+ days not because alerts weren't generated, but because they were buried in the avalanche of false positives and low-priority notifications. The presentation challenges the conventional "capture everything" mentality of SIEM implementations in favor of intelligent data routing and contextual enrichment.

The core methodology presented involves five key strategies: intelligent data routing to warm/cold storage tiers, contextual enrichment through asset and threat intelligence integration, risk-based prioritization scoring, multi-dimensional alert grouping (by user, asset, and attack patterns), and AI-assisted analysis for investigation acceleration. The approach transforms SOC operations from reactive alert processing to proactive threat hunting with significantly reduced noise levels and improved analyst efficiency.

## Key Points
- SOC analysts face thousands of daily alerts with 67% routinely ignored due to overwhelming volume
- Traditional SIEM approaches of indexing all data create unsustainable analyst workloads and contribute to 200+ day breach detection delays
- Alert fatigue leads to industry-wide analyst burnout with 10-15 minute manual triage times allowing only 4-6 alerts per hour processing
- Over half of security alerts are false positives, crushing teams with unnecessary information and investigation overhead
- Intelligent data routing to hot/warm/cold tiers reduces noise by storing non-critical logs (like DNS traffic) in standby data lakes
- Contextual enrichment with asset inventory and threat intelligence provides immediate context about affected systems and attack relevance
- Risk scoring mechanisms combine asset criticality, user importance, vulnerabilities, and threat intelligence into prioritization frameworks
- Multi-dimensional alert grouping by users, assets, and attack chains reveals coordinated campaigns rather than isolated events
- AI-assisted analysis accelerates investigation by providing remediation steps and attack pattern recognition when given proper context
- Effective SOC transformation requires moving from reactive alert processing to proactive threat hunting with intelligent automation

## Technical Details
- **Data Architecture**: Hot/warm/cold tier storage with intelligent routing based on log criticality and investigation frequency
- **Contextual Enrichment**: Integration with MS 365, AWS, and other inventory systems for real-time asset and user context
- **Threat Intelligence Integration**: Automated ingestion of detection rule sets, Sigma standards, and live attack campaign indicators
- **Risk Scoring Framework**: Multi-factor algorithms incorporating asset criticality, user privileges, vulnerability exposure, and threat intelligence
- **Alert Grouping Strategies**: User-centric, asset-centric, and attack chain clustering for coordinated threat detection
- **Data Lake Integration**: Standby storage for DNS logs, verbose network traffic, and other high-volume, low-priority data sources
- **AI Analysis Implementation**: Contextual prompting for remediation guidance, attack pattern recognition, and investigation acceleration
- **SIEM Optimization**: Reduced indexing overhead through selective data ingestion and intelligent storage tier management
- **Threat Hunting Capabilities**: Historical analysis against data lakes when investigating coordinated attack campaigns
- **Watchlist Management**: Automated blocking and alert suppression for known hostile IP addresses and attack sources
- **Detection Chain Analysis**: Pattern recognition for reconnaissance → exploitation → data exfiltration attack sequences
- **Vulnerability Correlation**: Integration of asset vulnerability data with active threats for prioritized remediation guidance
- **Investigation Workflow**: Structured triage processes combining automated scoring with human analyst expertise
- **Performance Metrics**: Transformation from thousands of daily alerts to manageable, high-confidence threat notifications

## Full Transcript

Thank you very much. Hi everybody, how we doing? Um, my name is Rich Murphy, as I said, uh, we're gonna talk a little bit about, uh, how many alerts uh security analyst gets in a day and what we can do to make that number smaller because it is quite an avalanche as you'll see. um, so just talking a little bit about a day in the life of security operations, um. Typically you have a SIM, lots of data going in, handfuls of detections that you need to tune, uh, in order to get some accuracy out of them, right? You're gonna want to see, uh, less false positives and obviously detect only the most relevant information, but a lot of times you're coming in unclear. You don't actually know the data that's coming into your environment so you have. Context around it, uh, it takes you a couple of minutes to get your bearings when you see an alert come in. um, so, so a lot of this is, you know, people tune their way out of actually detecting things because they don't want to see that much noise, right, which becomes a bit of a problem. uh, and even after all that tuning you still end up getting thousands of alerts. So, uh, just if you imagine. operation center with 5 or 6 people and it takes you know 5-10 minutes to do one of these triages to see if it's relevant or not and then if it is relevant you maybe have to spend more time investigating, analyzing, remediating so that time adds up and you can't go through thousands of alerts so a lot of it gets dropped on the floor, as you can see here, over half of these end up being false positives a lot of the time. Um, so, so what, what happens is you're just crushing yourself with unnecessary information and so it's just not a great, not a great way to do things, um. We also then manually triage most of these and like I said, about 10 to 15 minutes per alert, which gives you like 4 to 6 an hour. Obviously you're never going to get through thousands of them unless you really know what you're looking at, and that's why we have so much burnout in the industry, right, especially in the sock teams, you know, people don't want to handle this crushing weight all day, day in, day out. So, so we obviously want to try and make these things better. Uh, there we go. And, uh, that's the reality of the alert overload, right? We're, we're seeing thousands of alerts a day. Uh, 67% routinely ignored, which is a crazy number. I mean, uh, that's just some of that might be false positives if you're lucky, but other chances are it's, it's relevant information that you're letting slip away. And that's why a lot of times when there's a breach in an industry, you see that that breach isn't noticed for 200 days because you know you might have been alerted on it, but you're not actually going to see it because it's just too much burnout, too much stress, uh, too many alerts. So what's causing a lot of this avalanche? Why are we getting thousands of alerts? I mentioned we can tune them as best we can for an environment, but you know, obviously we do have that rule sensitivity issue where we want to tune them. Um, the lack of context for is big in my opinion because, uh, if you don't know what you're looking at, you're gonna spend so much time trying to figure out is this an important alert, is this not an important alert? Is the machine or the user it's affecting, is that somebody, uh, in a test environment doing a lab thing or is this like an actual uh workstation or laptop where like email is compromised, right? You, you sometimes you just don't know until you dig into it. Um, so, because of all that noise, um, it's, it's very difficult, and then, you know, the, the triage process, what to do after we detect an alert is sometimes lacking. So that's, um, you know, just unfortunately a lot of the problems that we have to face and, uh, what can we do to reduce it, right? um. Here here's what we're going to go through today. It's basically a little bit data routing, so managing the data as it comes into the pipe so that you can understand what's necessary, what's not necessary to index, to parse, to analyze, um, getting that context into your into your system so that you can properly understand what the alert is telling you and and what we should do about it, prioritizing those alerts so for all the ones that are relevant, which ones should we tackled first versus which ones we should maybe wait till later. Um, triaging it from different angles. This is another, another thing where you can not necessarily have to look at the list of alerts as they come in, you know, the most recent time stamp or or oldest time stamp, you know, maybe we look at it from a user perspective, maybe we look at it from a machine. Perspective something like that so we can consolidate groups of alerts in ways that make sense. So um kind of like if there's smoke there's fire you'll probably see a handful of things attacking one user or one machine and so it's not like you have to troubleshoot those individually. You can look at them as a whole. Uh, and then last, it's 2025, so I have to mention we should probably leverage AI to also assist with some of this analysis and remediation, so. Uh, so we'll start with filtering at the source, um, and, uh, this is, this has become kind of a big topic, but basically, uh, most of the time historically Sims would try to capture all of your data, index all of your data and store all of your data, right? Full log management, full capability, um. More recently we've started routing information depending on how important it is. We have the concept of like the hot and the warm tier where the warm tier might be logs that are not necessarily as important, but you may need them, so we keep them on slower discs and pull them when we need to. We also have these concepts of data lakes where we have standby data in the structured lake and so a use case for this. Would be the DNS traffic, right? So you might not want to know every single local DNS request and response that is going in in your environment. So maybe we'll route that to the standby and then later on we see some alerts, some investigation where it's like, oh you know what, this was affecting internal assets. Let's take a look at those DNS logs and then you can pull them into the system and continue your investigation. So, uh, you know, I work for Greylock. Greylock does does this in-house. You might need third party tools to do some of this routing, but, uh, but the idea is still the same, where you're going to take that data and move it where appropriate. If you need it, you can pull it back into the system, but, uh, but it's just sitting there, not being indexed, just kind of doing its thing and while you look at kind of the more relevant day to day alerts. Um, getting the context, this is another important thing, and, and there's a lot of ways to do this. You can start basic with the asset and user information in your environment. So, um, you know, just if you're already using tools that have this inventory like MS 365 or AWS or or what have you, and so we want to get all of that information and have it. Alongside the log messages, so when you see an IP address, it also says this is this machine. It has the services on it, you know, it's running a web server and it's maybe got these vulnerabilities that we haven't patched yet, right? So you have a lot of information about the machine without having to know, oh that IP address is this right? It's just there with you, um, and so that's one way we can enrich with that asset data. The other way that we can enrich is with threat intelligence, and I realize that's a broad topic, but you know this can be anything from detection rule sets that are found across the internet that you can import, um, you know, things like open detection standards like Sigma or you know some of the others where you can, you know, grab something that you've seen other people detect and import it in. Um, we also can talk about watch lists here, uh, you know, certain known hostile attackers. You can immediately eliminate some of the noise by just, you know, I, I, I know that these alerts are coming from IP addresses that are known to be hostile, so we can treat them accordingly or just block them out right before they come into the network. That'll help to eliminate a lot of those alerting um that that we see. Um, the known attack campaigns or live attack campaigns is useful as well, because, um, what's relevant what's relevant and happening in the wild, you'll obviously want to be on the lookout for. So, so you can have these kind of temporary targeted. Campaigns to detect certain certain attacks you can actually do historical analysis looking for it when it's happened in the past. So, so just, just being better informed about the data you're seeing is a huge help in reducing a lot of the noise and a lot of the stress because I know now this workstation is in a lab that is actually a honey pot, so we don't need to worry about it or this machine is the database with. All our financial information maybe we should look at that first, you know, so that's uh that's that's also another great way to just prioritize uh as you're triaging these things and you know once you have all that information in it becomes a lot easier to prioritize and triage because you know, uh, you know what's most important and what's what can just fall to the wayside for the time being, right? I would never say ignore a security alert, but you know you don't necessarily have to tackle it, you know, as the most important thing in the day. Um, another way that we can prioritize most SIM tools have a risk scoring mechanism. Uh, this will allow you to again take all of those factors we're talking about, um, who, who that person is in your company, what machines are they accessing, um, what vulnerabilities do those machines have, uh, any, any other additional information. You have from your threat intelligence from your, you know, the campaigns that are out there, um, one, all of those factors contribute to some sort of scale or score where you can, uh, you know, the, the more, the more severe alerts, the higher the score and then you tackle those first, right? So that is um. Immensely helpful in taking all the information I'm talking about the data routing, the threat intelligence, the context from the assets, um, and just wrapping that up into an easy to read number. So, so essentially once you have the SIMs configured in a way that does this, you know, you don't necessarily have to know all the context, you have the score and then you can dive in from there and and extrapolate so um. That is a little bit of that and then. How we look at these assets, the angles in which we, we retrieve them, um, I mentioned this before, but uh we have uh the asset and the user, which are great ways to group, uh, these, these alerts, so. If we have a machine that's got, you know, 15 alerts attached to it, you know, they're probably common or related in some way, so they're all kind of on one screen, sorted out for you by by user. We can, you know, sort them by the risk score as well to see what the most important is, um, same thing with the users and and any any other information that you have about that asset, about that user, about that machine. If we can group that all together, the vulnerabilities that they're exposed to, the the alerts that we've seen, um, it gives us a much better picture of why that machine or user is so risky and what we can do to remediate it, right? If we know they're wide open, that machine is wide open and we keep getting attacked from the same, uh, ports or exploits or what have you, then we know what we have to do to shore that up, um. The other thing is I, I talk about grouping the machines and the users, but we should really also group some of these alerts together as well. Um, one alert may be important, but an alert for like recon followed by uh some sort of exploit followed by data leaving your site, right? These are like a pattern. This is behaviors that indicate like a severe attack and so. Finding those chains and those those detection chains that we have, um, you're you're able to then see OK, this is a coordinated attack. We actually could probably get information about the attack from the web because these are kind of well known and published in, you know, Miter and what have you, um, but, but the idea being, you know, OK, I know I now know we're being attacked by this particular campaign, so let's find out the information about that campaign, figure out how to remediate it, figure out how to resolve it. Um, I'm going very fast, so I'm just gonna slow down, but, um, the last thing I did want to mention was leveraging AI for analysis, um, so. Obviously we get a lot of information. We have to be a little careful about what we what we do with the AI tools, but it's a very useful way to say I'm I'm seeing all of this information. Uh, here are the logs I've seen, here's the alert that triggered, here's the information about the machine. What can you tell me about what this is, what I can do, right? So, so supplementing your contexts and all this other information with um. Details about what the AI is telling you, basically what it knows from gathering the information across the web that's going to be a very helpful tool as well. I'm not saying let it take over necessarily, but but it's just another piece of evidence you can use as your compiler. all the information in an investigation in a bucket, whatever, however, you know, you do your triage and you do your work flow. So I, I treat that as like another useful set of remediation steps set of set of summary about the alert, that sort of thing. Um, and, and, and we found them very useful, uh, you know, when you, when you restrict the set of data you're giving it and when you are, um, you, you, when your prompts are thoughtful in terms of what you're looking for, right? So I'm looking for, uh, a set of remediation steps around this type of attack. It looks like this is happening. What can you tell me additionally, you know, about, uh, about the attacking question or about the machine in question. So that's letting uh the I I do the work for you and uh that's basically what I wanted to go through were those kind of five topics, right? routing the data so that um You can eliminate a lot of the noise right at the ingestion point. You don't need to ingest everything and read everything and index everything, right? Let's take some of the noisier logs that we don't need every day. Let's put them in our kind of standby, or warm tier, and that will eliminate some of the noise. We get from the alert detections, uh, adding the context so that uh you have your asset information, uh, maybe including threat intelligence on top of that so you have those that alert knowledge and kind of that internet database of, you know, the the most known attacks and the stuff that's out in the wild, um, prioritizing with risk scores and other, other, other kind of formulas to understand what's the most important, uh, and then leveraging AI finally so. Um, but yeah, you can't eliminate the noise, but we can do our best to try and reduce it using a lot of those techniques. Um, I, you know, you start with reducing that data set that you're actually looking into, only focus on the most important and then enrich that with the, with the context, um, prioritizing it and, uh, you know, just all of this is going to lead to faster triage which when you have thousands of alerts is going to be crucial when you're trying to solve these, these problems. So, um. And, and that's, that's my talk. I have, I love time for questions, but they've told me if you have any questions, uh, please come visit us at the booth. Uh, we are in the 400 row, uh, so, so stop by if you want to learn more about Greylock, if you want to learn more about, you know, just SOC workflow, uh, we have a few folks here who are very well versed in, uh, in SOC and, uh, security analysis, so happy to help you out, answer any questions you might have, and you know demo some of these techniques we've been talking about so. Uh, that is it. Thank you very much. If you have any questions, I'll be here for a few minutes, I guess.
