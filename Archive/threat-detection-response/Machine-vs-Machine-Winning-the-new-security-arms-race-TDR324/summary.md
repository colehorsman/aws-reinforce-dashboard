# AWS re:Inforce 2025 - Machine vs Machine: Winning the new security arms race (TDR324)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=P-8x_W2uiOk)

## Video Information
- **Author:** AWS Events
- **Duration:** 16.3 minutes
- **Word Count:** 2,394 words
- **Publish Date:** 20250619

## Summary
This session from AWS re:Inforce 2025 was delivered by Josh Camju, founder and CEO of Sublime Security, focusing on the evolving security landscape where both attackers and defenders are increasingly leveraging generative AI and autonomous systems. The presentation explores how adversaries, from nation-state actors to e-crime groups, are adopting AI tools to maximize their ROI while operating under various constraints.

The speaker addresses the technical challenges created by this new "machine vs machine" security paradigm, particularly in email security. He introduces what he calls the "security agentic AI trilemma," where organizations can only achieve two out of three desired outcomes: speed, efficacy, and low cost. This creates significant challenges for real-time threat detection and response systems.

The presentation concludes by presenting a solution architecture that combines a two-layered approach using a domain-specific language (MQL) for high-volume filtering, followed by agentic AI for deeper analysis. This system includes feedback loops for continuous improvement and autonomous adaptation to new threats, representing what the speaker believes is the future direction for security systems that need to operate at scale while maintaining effectiveness against AI-enhanced threats.

## Key Points
- Adversaries are increasingly adopting generative AI tools to enhance their attacks
- Google's threat intelligence group has confirmed AI adoption by Iranian APT, North Korean APT, and e-crime actors
- The barrier to entry for sophisticated attacks has been lowered significantly by AI tools
- Security systems face a trilemma between speed, efficacy, and cost when implementing AI solutions
- Real-time classification problems cannot be solved directly with agentic AI today
- Alert triage use cases are more feasible for current AI implementation
- A multi-layered approach combining traditional rules and AI is necessary for effective defense
- Continuous adaptation and feedback loops are crucial for maintaining effectiveness
- The future of security will be increasingly machine-vs-machine
- Traditional point-in-time model training is insufficient for modern threats

## Technical Details
- Message Query Language (MQL) - Custom domain-specific language for email threat detection
- Two-layer architecture: DSL-based filtering (Layer 1) + Agentic AI analysis (Layer 2)
- System components include natural language processing, computer vision, risk scoring, and behavioral analysis
- Deployment environment: AWS-based infrastructure
- Automated feedback loops for continuous system improvement
- Chain of thought reasoning implementation for transparency in AI decisions
- Integration with human analyst workflows for uncertain cases
- Autonomous generation of new Layer 1 detection coverage
- Real-time processing capabilities for high-volume threat detection
- Built-in enrichment functions for comprehensive threat analysis

## Full Transcript

All right, how we doing? We still awake? Got our afternoon coffee in, ready to go. Uh, rad, all right, so let's get started. Security is in adversarial space. We all know that we've been in the community for a while and we know that our adversaries have objectives, whether they're nation state, whether they're financially motivated, nation state might be collecting intelligence, e-Crime might be, uh, obviously financially trying to gain financial returns. One thing that is I think not as often discussed is that our adversaries are also constrained in in many ways similar to how we are constrained as defenders they have budgets they have people constraints and they are always finding ways to maximize. their ROI regardless of what their objectives are and so we're in a new world now where generative AI agentic tooling enables them to maximize their ROI in many different capacities and so we are seeing adoption of this tooling in many ways and. Um, so we're gonna be talking about a bunch of what we're seeing and where I think we need to go as as defenders to be prepared for kind of this new arms race. So I'm Josh Camju, the founder and CEO of Sublime Security. We do email security and so a lot of the insights that we'll be sharing today are from our in the wild kind of observations on what we're seeing adversaries adopt. So we're gonna start with an evolution of, you know, what, how the landscape is evolving. We'll talk about what we're specifically seeing and how adversaries and which ones are adopting generative AI tooling. I think one thing that is often discussed as of late is how do we as defenders or the infosec community adopt generative AI for our defensive applications, but one thing that isn't as discussed as much as what are actually our constraints, how do we actually apply it, what use cases can we actually solve? So we're gonna be talking a lot about that today and how we think that can be solved, um, as, as an industry. So This is the new world that we find ourselves in. We have had the first two here for a very long time, so commodity fishing has always been, uh, has, has, uh, effectively been, um, uh, high volume. It's customized and, and it's templated, I should say. Uh, spear fishing has always been, uh, tailored. It's conducted by a human operator. It's very low volume. Um, and then you've got Gen AI that is now the worst of both worlds here. It's tailored, it's high volume, uh, and it, and it adapts very rapidly. So. It's the worst of both worlds. Google Google's threat intelligence group put out a great report recently on adversary adoption of Gen AI, and they specifically called out a few actors. One is Iranian APT and how they are using Gemini to craft phishing campaigns. Google has a really interesting. Uh vantage point because they own Gemini and so they have all the telemetry around how that's being used so they can attribute the actual specific activity to specific actors. So really interesting, you know, something that we've been seeing on downstream on the email detection side but. Here's Google giving us confirmation on the adoption by our adversaries. They also call call out uh North Korean APT leveraging it for researching advanced fishing techniques, uh, developing malware, evading defenses. And they also call out e-Crime, leveraging. LLMs to augment business email compromise operations and so I think that this is gonna be the highest impact in terms of what organizations see like enterprises see in the wild. E-Crime today makes up most of the volume of phishing attacks, email attacks, but in particular, e-crime actors, unlike nation states. This very much lowers the barrier of entry for e-Crime actors who historically have not had, you know, translation capabilities on hand or interpret interpreters on hand. And so, Uh, very much lowers the barrier of entry and it allows them to make their attacks much more sophisticated, targeted, well researched, seeming. We're even seeing, uh, jailbreaks of LLMs that are that don't have any sort of, you know, defense mechanisms built in. So we're, we're seeing this downstream on the email detection layer as well. So we're seeing this in our customer environments. I gave a talk on some of the more sophisticated stuff that we're seeing at besides Las Vegas, um, and we, we've written about this at length at our blog as well. So if you're interested in seeing more examples, you can check out our blog. And we wanted to know how quickly would it be to actually do this as an adversary. I'm an offensive guy. I spent my career in national security doing offensive cyber stuff prior to Sublime, and so this was fun for me to just kind of replicate as an adversary, how do, how, how easy or how hard is it? And I can tell you that uh. It's, it's not very hard. So in about 1520 minutes, I'm able to give some prompts to chat GPT and it's able to generate a very timely, uh, very targeted, seemingly well researched and perfectly grammatically correct phishing attack. Um, so it's happening, it's real on the adversary side. What this means for defenders is that over um we, we continually we're gonna need more and more adaptive defenses, right? Because the, the threat landscape is going to be shifting. They're gonna be finding new ways to evade and so the rate at which we can adapt is gonna be key. We released a threat research report kind of looking at our telemetry in Q1 and one of the observations that was that we seen in the data is that. Uh, more messages are being more and more, uh, customized per recipient. So we've seen this gone up quarter over quarter. So, it's happening in the data. We need defenses to be contextwa, adaptable. So We, we talk a lot about kind of as an industry, there's been a lot of talk about, you know, agent this, agent that, use it for all these kind of defensive use cases. So this is what I like to call the security agenttic AI trilemma. So I'm coining it here, you've you've seen it here first. If you see it out in the wild, I want uh I want to check in the mail. So, uh, the reality is in terms of how this can be applied defensively. Is that there are constraints, and you can only really have two of these three things at once. You can't have all of these 3 things today. You can't have, you can't leverage agentic AI such that it is really fast in terms of like inference and and verdict and rendering a verdict and high efficacy and low in cost. It is only two of the, you can only have two of these three things at once. You can have something that's really fast, that's really cheap, but it's gonna be. Low efficacy, right? And so what that means given these practical constraints, is that the use case, what you're trying to solve for is actually gonna drive a lot of this, right? And so for email security and, and just like some use cases in general, it's impractical to be solved. So for any high volume, low latency, high efficacy problem, you can't directly use agentic AI to solve for today. And we wanted to break down some of these use cases that we as a security community are thinking about and there's a lot of discourse about leveraging these capabilities for. And break it down into whether we think it's feasible or not today. And so on the left here, we have the real, real-time classification problem. So this is email threat detection, this is network threat detection. So, super high volume. Uh, needs to be super high efficacy and has to be very low latency, right? You cannot solve this directly with agentic AI today. Alert triage, this second category here. This is basically like our AI sock, right? We're seeing a lot of, a lot of top, like a lot of discourse around this, um, which is relatively low volume. It does need to be high efficacy and latency is not as important, right? Even today if you have a, you know, tier one, tier two analyst, meantime, the remediation is not subsecond, right? It's, it's tens of seconds or maybe minutes. And so this is actually feasible to solve directly today. Obviously, given, you know, the volume and kind of specifics. And there's a couple other use cases that we threw out here may or may not be solvable today. So How do we solve this? Right? We want to design a system that's gonna be able to rapidly adapt and keep up with the pace at which our adversaries are innovating. And so we think the key to this is a multi-layered system that has, that can leverage feedback feedback loops and learn over time. And so the way that we design sublime is a two-layered system where layer one leverages a DSL, a domain specific language. It's a language that a computer can speak effectively. And that runs over high volume uh data. It's super low latency, it's super cost efficient, and it acts as a filtering layer to decide what should be promoted basically to layer two. And at this point, once you reach layer two, you you're basically back at the alert triage problem, which we know is solvable. Um, and then what we can do is we can, we can have a feedback loop where upon a misclassification or triage of a verdict, we can feedback into layer one, we can update the logic, and we can autonomously improve the system over time. So, What is this, what are some of the specifics here? So the DSL that we created is called Message query language. This is what operates at our layer one. It's purpose-built for describing complex email attacker behavior. And this is ultimately the language that's used by our agents to improve and to investigate. And so this is an example of what the DSL looks like. So who here has used like clawed code or, you know, Chachi BT to like write some code or like a signature, like a, a rule or something like that. Yeah, a few. Nice. OK, so this is effectively what we have created, but it's purpose built for email detection, real-time detection use cases. We created a language that computers can speak and it's, and it leverages kind of these table stakes enrichment functions, things like natural language processing, computer vision, risk scoring, behavioral analysis, all of these things that you really need in order to do detection well. And it, it's, it serves at that that uh layer one filtering mechanism. So once we pass layer 1 to layer 2, we now have effectively our alert triage problem, which we know is solvable, where we can leverage um agenttic capabilities with, you know, full chain of thought reasoning for transparency. We use MQL as a way to further investigate messages um and ultimately produce a final report. And so this is architected, so this is like fully contained within AWS environments and the feedback we've gotten, this is like released to our customers is that AA is more effective than the human analysts at uh at our cus at many of our customer environments. So it works, feedback has been pretty, pretty rad. And this is what AA looks like in products where it's, it's rendering a summarized judgment explainability, there's full chain of thought on how it arrived at that decision for transparency if and when an analyst ever wants to review it. And so you can think of this as an augmentation or even a replacement for tier one tier two analyst use cases, um, and then. In any, any scenario where it's uncertain, it'll escalate to a human for for review. So the next and final part when we start to get about the feedback loops is a day where, um, if you think about one of the key reasons why defenses today are not rapidly adaptable is because models are trained in in a point in time, effectively, right? And we know that. The target is moving. This is not like hot dog or not hot dog, right? Like the threat landscape is moving and so you, you need to be able to retrain models as new techniques and things come to fruition. And so that retraining process is what is a lot of the reason why there's lag time, um, and it's a lot of the reason why it's a very one size fits all approach when you start to get to deploying these systems at scale. And so A day solves this problem because it can generate new layer one detection coverage autonomously leveraging the same signals that our models have access to. So we really believe that this is kind of like the future of where the industry is gonna need to go, not just for email problems but for all kind of real time detection problems. So at the end of the day, we think that this, this architecture is able to solve these real time detection and prevention problems, but most importantly, be able to adapt autonomously as attackers adapt and, and keep up and and move even even more, more rapidly. So. At the end of the day, we're adversary adoption of agenttic capabilities still very nascent, right? I mean, we're still at the very beginning stages. I think that we are increasingly moving towards a like you got machines on one side, you got machines on another, and they're just fight dueling it out, right? And so as a community as defenders, we got to be able to adapt rapidly. So, um. Yeah. That's all I got. We got some time for questions, I think. Yeah. What we'll do actually is we got um. We've got a booth, so 525, you got questions, you wanna nerd out about this stuff more, I'll be over there.
