# AWS re:Inforce 2025 - From incidents to insights: Creating a security learning organization (TDR224)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=vK4TYf8Ie9E)

## Video Information
- **Author:** AWS Events
- **Duration:** 19.5 minutes
- **Word Count:** 3,104 words
- **Publish Date:** 20250620
- **Video ID:** vK4TYf8Ie9E

## Summary
This session explores how organizations can transform security incidents into long-term organizational improvements. Using Amazon’s “Correction of Errors” (COE) process as a foundation, the speaker outlines a framework for post-incident analysis that avoids blame and focuses instead on uncovering systemic causes, identifying preventative actions, and building a culture of resilience. Through structured retrospectives, tagging, and data analysis, companies can evolve into security learning organizations. The talk also introduces metadata tagging of incident reports for trend detection, and offers guidance on fostering psychological safety and executive engagement to support continuous improvement in security operations.

## Key Points
- **COEs (Correction of Errors)**:
  - Amazon’s structured post-incident retrospectives
  - Focus on objective, anonymous root cause analysis (no blaming or shaming)
  - Action items must be SMART: Specific, Measurable, Achievable, Relevant, Time-bound
  - Include *success criteria* to measure effectiveness

- **COE Structure**:
  - Executive-friendly “elevator pitch” summary
  - Timeline of events and customer impact
  - 5 Whys to uncover root causes
  - Lessons learned → Action items → Owners

- **Visual Tools**:
  - **Fishbone diagram**: Maps contributing factors across People, Process, Tools, and Systems
  - **CDAC (Cause and Effect Diagram with Addition of Cards)**:
    - Pairs each cause with a proposed improvement
    - Helps identify who should be involved (e.g., HR, system owners, service teams)

- **Example Scenario**:
  - Incident: Developer accidentally emailed credentials in code
  - People: Training gaps
  - Process: Runbook missing email guidance
  - Tools: Email system lacked guardrails for sensitive data

- **Strategic Use of COEs**:
  - Tag COEs with metadata (e.g., attack vector, affected system, mechanism)
  - Aggregate data to identify trends across business units
  - Use trend data for *information arbitrage*: spotting emerging risks early
  - Track improvement over time with dashboards (e.g., QuickSight)

- **Cultural Principles**:
  - Psychological safety is critical—focus on mechanisms, not people
  - Escalation should be encouraged and rewarded
  - Sharing learnings broadly (e.g., leadership reads COEs weekly at Amazon)
  - Use collaborative documentation systems, not email or chat-only workflows

- **Broader Applications**:
  - Trend analysis can inform not just security, but also product decisions, CRM investments, and training programs
  - Integration with GenAI can extract qualitative insights from COEs

- **Call to Action**:
  - Start small: pick a recent incident and document a COE
  - Focus on learning, prevention, and sharing—not blame
  - Use visuals (fishbone, CDAC), tagging, and executive engagement to scale

## Technical Details
- **COE Process at Amazon**:
  - Retrospectives are submitted into a centralized UI (backed by a data lake)
  - COEs are visible to all employees, regardless of org (e.g., AWS, Prime, Stores)
  - Executives (Andy Jassy, Matt Garman) review key COEs weekly
  - AWS Ops COEs are reviewed in large meetings with thousands of attendees

- **Metadata and Reporting**:
  - Tag incidents by theme (e.g., IAM misconfig, credential exposure, blind spots)
  - Tags feed dashboards for trend analysis and reporting
  - Example metrics: conversation volume, reduction in repeat issues, time-to-detect

- **Use of GenAI**:
  - Can generate markdown reports and summarize qualitative insights
  - Supports security knowledge management at scale

- **Collaboration Systems**:
  - Must support:
    - Document versioning
    - Search and filtering by tags
    - Cross-org visibility
    - Export to analytics tools (QuickSight, Bedrock)

## Full Transcript

All right. Hey everyone, thank you for being reinforced in this session. It's been a busy couple days uh for everyone here, so I hope you made a lot of connections and learned a lot from peers and colleagues and all the sessions we offered for this last session we have today. It's about transforming security failures into organizational strength. Now as we're wrapping up, how about we end with a chuckle, so. Let's start with this um comic. I'll give a few seconds to look at it and. And just it I love this. This is the awkward Yeti comic strip. You're welcome to take an image of the QR code and follow more. This is in particular brain and heart. So in this case they're going through life, going through the same mistake swamp, and asks the heart, did we do it wrong again? and the brain says we may never know today we're gonna learn how we can know so we don't do it wrong again. In today's agenda we're gonna talk about security incidents and how to address the aftermath um we can analyze do post incident analysis we'll walk through the components to include in this um we're gonna do simple case study, uh, how to build resilience and how to replicate this at your own company, so take it back with you. Alright, if you're in security incident, you may all, we've been there where we have a 3 a.m. call. We have frantic, um, slack messages war rooms trying to resolve this, and as soon as we resolve it, we might have to pass. We either are relax and think like, hey, high five everybody. Close this ticket, be ready for the next one. Or you take the step to evolve, you learn, adapt, and make the next attacker work harder. So at Amazon what we do is we take step 2. The second half of this, we, um, with a retrospective which we call the correction of errors. So what is the COE and and why should we care? So post-incident analysis, it is a type of it is a retrospective, which is a correction of errors we'll call it COE from now on. The intention of the COE is to objectively and anonymously document what happened. this type of retrospective is not about naming, shaming, blaming or asking for forgiveness. You really just wanna document the incident to learn from what the event you wanna dig for the root causes, not just the symptoms and. When you have enough insights, you wanna create um uh smart uh action items that are specific that are measurable, uh, achievable related and time bound. What I'd like to add to this is you wanna make sure that you include success criteria. And the reason why we have this is because you wanna have the opportunity to measure your action items in the future. Did they produce intended results? So with success criteria you could also include um enablement campaigns and awareness campaigns for this. All right, so what should your COE answer once you go through your instant response, you should address how we can detect uh the failures faster. You really want to work on reducing the mean time to recovery with this information that you collect and prevent similar failures from happening again and at the end, uh, control the blast radius and reduce the future impact of incidents similar to this. Well, what should a COE include? I'll start with at Amazon our COEs are actually reviewed by our our CEOs Andy Jasi and Matt Garin. Matt Garman has a weekly security meeting every Friday which includes reviewing COEs, and the reason why I say this is because you want your COEs to be. Reviewed at the executive level as well. So for an executive, you wanna start with an elevator speech, something that your, uh, your executive can quickly stand and know what happened, who, what, when, where, why, how did it happen and how do we intend to prevent this from happening again. So that is the elevator speech high level if your executive wants to go into more detail, you provide the rest of the information starting with the impact to the customer. What is it that we want to prevent from happening again? Well, and you want to prevent show this with coquantifiable metrics and the timeline of events sometimes the incident you might just focus on that single incident that you encountered and but you really want a detailed timeline of how far back maybe what contributed to the incident happened days before, hours before minutes before, and maybe we didn't realize we're going through this threat detection or incident. Until much later, so your timeline should be pretty thorough so that by the time you get to your 5 Ys is when you start understanding the um going past the symptoms, the root cause. So when I talk about 5 Ys, let's just give an example of a data plane failure. So let's say um you ask well why weren't responders paged? Oh well because there was a misconfigured event bus OK um why are there no alarms for the event bus? Oh, we, uh, had no integration for the event work flows. Why were there no tests then? Um, we're depending on downstream monitoring. Oh, OK, so why did the downstream monitoring fail? Oh, well, we had infrequent canary runs. Why do we have infrequent canary runs? Because we were relying on default configuration. We did not question if the default configuration should be followed. See how I kept asking and asking and asking until we got to the root cause. So you wanna get to that same approach that way you get to closer to prevention beyond just mitigation. Once you ask others why then you get to the ah that's what I that's what we're doing wrong that's what we missed that's what the mechanism was gapping. So those are your lessons learned and from your lessons learned then you got to take your action items. What are the commitments you're gonna make so this doesn't ever happen again. 4 Now this allows you to visualize this. You might have seen this before it's a fish bone because then you hear I mentioned earlier an incident might not be just due to one area. It could be multiple things that contribute to it. So a fish bone, think about it, your, your incident, your problem, think about it like a math equation. Your problem is a function of X. In this case, the problem or the incident you encounter could be a result of, um, when I speak of people it's not the individuals. I'll get to what I mean by that uh people process tools in the system. So let's think of a simple, simple scenario. So one of them would be like your colleague emailed you um code and the code included credentials, so that raises a security incident. If I look at this and think, well, how do I um what area should I start with? Well, let's start with the area of people from any people perspective, let's assume your colleague is rather a new employee so maybe there are some training gaps and maybe we had alert fatigue. So in the area of people, the cause is training gaps in the area of process, the cost could be maybe the wrong book didn't explicitly say. To communicate code excuse me, to communicate code, don't use email. So now you put that under area process. The cost is the run book has some gaps. And then finally, uh, maybe you received this over Microsoft Outlook email and you there could have been some guard rails to check for code or check for credentials so the email wouldn't sent. So in the area of tooling and systems, the cause is the gap of missing guard rails. Notice. In all of this, I never spoke of the individual. In none of these areas it's never so and so made a mistake. It we the point is not to talk about the individual but talk about processes that might have impacted what occurred. Um, this takes the fish bone to a higher level, more dynamic. Um, this transforms the static analysis into dynamic improvement road map, very similar to what we saw earlier. The CAC is also known as the Toyota method. CDAC is short for cause and effect diagram with the addition of cards. So now next to each of the um facts we encountered earlier, the causes, you can put your corresponding improvement. So in the people area we covered about lack of training, so now I know my training is I need to improve the on boarding and so maybe I need to include HR and training and communications to help with that. In the area I spoke earlier of uh processes so the fact was the run book had some gaps so maybe it's the systems team, the the service team we need to the improvement is the round book fix and finally in the area of um uh tools and systems we talked about my emails so I would include the systems team by having the visual of the improvement you're able to see um who should I include as well as part of your solution. All right, so. This is actually my favorite part about COEs being able to leverage the data to understand the stories behind this. So let's assume that you work in a financial organization really large conglomerate, and you have a commercial business, you have a wealth management business, credit card business and other types. So if you have a COE across and again I emailed a code. Because these businesses might be intentionally ring fenced, we might not know the issues that occur across even though they're similar, so they become point in time events there and technical improvements there. However, if you meta data tag your COEs, now you can aggregate them for strategic intelligence. So if you tag, you can aggregate these names to see maybe you aggregate by attack vendors, attack vectors, apologies, um, like credential theft or, um, affected systems or even the mechanisms that worked or didn't work. Create according tags and you aggregate by themes to be able to see trends. Um, so what I'd like to see from here is consider information arbitrage. Do any of you guys, um, trade? If you do trading, have you used, um social media like tagging social media stories to see what is up and coming, what to invest in. Uh, not the best comparison, but like GameStop, right? GameStop became super attractive due to Reddit conversations and so people were pretty smart at tagging, seeing the metadata there in our, in our case we're gonna use that differently, but information arbitrage is when you capitalize on information before it becomes widely known. So from our perspective on security, you want to use information to identify emerging threats and vulnerabilities before they become widespread within your company or maybe even externally that impacts customers so. In our case, so here the COEs because we wrote about them, provide qualitative insights that quantitative information will miss and you can use all that for information arbitrage. um, let's say we sampled an analysis and the conversation volume revealed that we saw a spike in API misconfigurations and that allowed us to see, um, proceed a major incident or. Again we saw similar IM issues across business units that don't necessarily talk to each other, but due to those tags I can see that at the large corporate level and try to address that and we're able to maybe see early detection of security tool blind spots. So by leveraging this information, you can track themes in the COEs over time. And you can uh monitor the conversation tags and maybe a decrease in conversation volume means that you're improving your security posture and an increase in volume of these tags maybe testing marching risk. And we don't only have to use this for security. Let's say for example you have a CRM and there are a lot of tags about that like concerns with it. You can start using those tags to determine maybe resource allocation or capital investment decisions or annual operating planning insights. So once you tag these things, you can use like bedrock AIML and measure the conversation trends to see the success of your mechanisms you introduce. Alright, so I walked earlier about COEs, which are retrospectives for Amazon, and what to include in them. The intention is to be able to leverage qua qualitative data from the incidents that you encounter and be able to use that as information arbitrage for within your company or to get ahead of security threats or vulnerabilities that might impact externally by leveraging the data. So how can you take this back to your company, so. The first thing you wanted to do is to create psychological safety. You wanna make sure your teens feel healthier and highly supported once they work with the COE and and not beat up. Earlier I mentioned that COEs are not intended for shaming, naming, blaming or asking for forgiveness. It's really about celebrating the a comfort that we're willing to share this information that we're willing to learn and by reading it with your executives, it's another level of celebration and acknowledgement for anyone who brings this up, create psychological safety to learn from this and help your peers, your employees feel comfortable to escalate and um promote a culture of escalation. You want to use um collaborative documentation platforms it's probably not a good idea to do all those learnings through email because you can only include so many people on that and we might get uh email fatigue um or maybe like slack, right? we have limited uh audiences there so what we do at Amazon. Is we have a user interface where we enter these narratives, the COEs retrospectives, and anyone in Amazon can see it. I work in AWS security side global services. I can go read the ones from Amazon stores, from Prime, from data centers, and I can learn what other folks are encountering. So you want such a a collaborative documentation platform that has a user face interface and it'll store in a data lake. And plus anyone can have access to do um like quick site dashboards from it as well and now with Gen AI you can use Gen AI to write qualitative information from it. You wanna set clear timelines of of both writing the document and your action items and um you want to involve the right people in the earlier example of emailing, let's say code. The people involved in the incident aren't necessarily the best ones or the right ones to to. Implement the solution right? so by understanding what the improvement is you might involve the right people for enablement for awareness for training for improving the mechanism that is out there now so always keep that in mind again focus on systems and processes and not uh necessarily on the individuals and share the learnings widely. Um, I, I'll reiterate that our, our COEs are, are read at the, at Andy Jasi level at the McGarin level in their meetings, and, uh, De Santos has his own for AWS Ops where we two hours reading COEs and C. Employees and there are thousands of employees that join those calls and we get to learn from incidents and take it back to our teams and even smaller teams have a reading. The intention is to make this public, share the learnings and celebrate the culture of escalation. All right. So our takeaways today I talked about how whenever we encounter incidents and and address threat detection and incident response we want to transform these security pains into organizational games. How can we make our company better, our teams better as a result of what we have encountered, um, how to really get to the root causes of why an incident occurred. I want to highlight that in this we talked about 5 Ys we talked about a fish bone visual and we talked about the Toyota method which is CAC. These help provide a structure analysis. And I, I'll reiterate that never did I mention the individual in any of those visuals. I think that really helps the individual know when I walk into this conversations I don't have to feel bad that that I'm messed up. I just know that I'm gonna we're gonna focus the conversation on the mechanisms that led to this, maybe what gaps in our existing mechanisms need to be improved as a result of this incident so it's not about the individual, it's about processes. Um, my favorite, using the information for intelligence, um, we want to aggregate insights for to get ahead to, uh, uh, securities and security vulnerabilities and also within the organization or maybe externally. Embrace the Belfast, uh, culture. When we have an incident, we quickly address it, we try to resolve it right about the COE, move on to the next thing. So fail fast culture helps us fail fast allows us to build a culture of resilience. OK, so I gave you a lot of information. I hope you have found it useful, and I think we're at a good point where we can start now and um we can look at your most recent incident and try to apply this process. I'm Maria Wrap it up with this visual again here heart is asking brain, hey, let's address life. Let's bring it on, go through the same mistakes. Did we do it wrong again? We may never know. I think now I've demonstrated to you, you can know. You can not only know but you can do something about it and avoid going through the swamp again and um take a snap at the car code so you can follow the Awa Yi for other fun stories. And thank you so much for your time. Please, um, take a look at the survey, give us some feedback. I'm happy to help anyone if you're interested in implementing this at your company. I do this for Amazon and I enjoy sharing this learning, so thank you for your time.
