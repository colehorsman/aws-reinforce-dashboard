# AWS re:Inforce 2025 - Managing cloud risks at scale with Autodesk & Orca Security (TDR202)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=lFLmtMa2q7k)

## Video Information
- **Author:** AWS Events
- **Duration:** 35.9 minutes
- **Word Count:** 6,001 words
- **Publish Date:** 20250619
- **Video ID:** lFLmtMa2q7k

## Summary
This session featured Autodesk and Orca Security discussing practical approaches to managing cloud security risks at enterprise scale. Shri Truvihu from Autodesk shared how their global design and manufacturing SaaS platform leverages Orca's agentless security platform to handle vulnerability management, risk prioritization, and compliance across their multi-cloud AWS-heavy infrastructure. The session covered Orca's 2025 cloud security report findings and demonstrated real-world attack path visualization for lateral movement prevention.

## Key Points
- **Vulnerability Management at Scale**: Average cloud asset has 115 vulnerabilities; 1/3 of assets are neglected (untouched for long periods)
- **Attack Path Visualization**: Orca provides 360-degree view showing lateral movement risks from public-facing assets to sensitive data
- **Agentless Scanning**: Autodesk uses Orca's agentless approach to scale across all cloud subscriptions without sensor deployment overhead
- **Risk Prioritization Framework**: Combines vulnerability context (CISA KEV, active exploitation) with asset context (production, internet-facing, crown jewels)
- **Golden Image Program**: Autodesk maintains CIS-compliant, vulnerability-free AMIs and container images for downstream teams
- **AI Security Posture Management (AISPM)**: New capability to identify AI services, libraries, and vulnerabilities in ML workloads
- **Reachability Analysis**: Agentless capability reduces container vulnerability alerts by 50-60% by identifying which packages actually run
- **Data Security Posture Management (DSPM)**: Scans for sensitive data across workloads, storage, and includes OCR for image scanning

## Technical Details
- **Autodesk Architecture**: Multi-cloud with heavy AWS adoption using EC2, ECS, Lambda, S3, DynamoDB
- **Security Use Cases**: Telemetry visibility, misconfiguration detection, golden image creation, vulnerability management, risk prioritization
- **Orca Platform Features**: Agentless scanning, granular exception management, attack path correlation, shift-left integration
- **KSPM Implementation**: Kubernetes Security Posture Management with automatic public cluster onboarding and Helm chart connectors for private clusters
- **Integration Capabilities**: GitHub/Bitbucket repository correlation, CI/CD pipeline integration, custom compliance checks
- **Prioritization Logic**: Weighs vulnerability severity, asset criticality, network exposure, and data sensitivity for dynamic risk scoring
- **Multi-Cloud Support**: Single solution spanning AWS, Azure, and other cloud providers with unified risk management

## Full Transcript

Hello everyone, uh, thank you so much for joining us, uh, to today's session. I'm excited that we have an intimate group here today, um, which allows us to really get into the content. Um, my name is Keith Moriss, VP of marketing at Orca Security, and I'm thrilled to be joined today by Shri Truvihu, uh, principal engineer at Autodesk, and Gus Evangelaos, VP of solution engineering at Orca Security. And after I set the stage, um, in a couple of minutes we're gonna dig into ultimately um you know how a company like Autodesk is approaching, um, global risk management, security, and other important themes in the cloud here on AWS so very excited to ultimately bring Sri up here in a couple of minutes to unpack what that looks like and then talk about you know how Autodesk and Orca Security are partnering to manage risks and prioritize issues at scale. So one of the things I wanted to do to set the stage is Orca recently published its 2025 state of cloud security report. We had a separate session on that roughly 90 minutes ago, and I wanted to kind of peel back some of the layers as we looked at over a billion different cloud assets across the five biggest cloud providers around the world. And one of the, you know, things that I pulled is that vulnerability management is still a huge problem in the cloud, and that's something that we'll definitely talk about today. And one of the, you know, important statistics that was in that report was that um the average asset has 115 different vulnerabilities on it. So as you can imagine, um, finding out which vulnerabilities are most impactful, most important, and. You're going to work with your development and DevOps teams to rebuild and redeploy applications is a gigantic challenge not only on the prioritization side but on the friction and efficiency side to make sure teams are spending time, you know, ultimately making their environments more secure. Um, another big area of the report that we looked at was what we call neglected assets, and ultimately neglected assets are assets that haven't been touched over a significant period of time. Um, these are assets that might have a very outdated host operating system, for example, and we found that 1/3 of all cloud assets are neglected. And this can lead to things like plain text secrets being embedded um within code repositories um so source code repositories can be a huge gateway you know for attackers if they're not monitored and looked at securely um. And then as we think about neglected assets and how they can be interconnected to other risks, um, one of the things I highlighted was 76% of organizations have a cloud asset that's public facing and could enable lateral movement around their environment. And so if you're an attacker, this would be something that would certainly be a target for you to not only connect to that asset and see what might be available there, but to see what else you might be able to jump to and connect to. And when we work with, you know, prospects and customers at Orca Security, we find that they have a wide variety of unique challenges and it's great when we can talk about our view of the world paired with, you know, a real world customer, uh, like Shree and his team and what they're trying to look at and solve day in and day out. Um, I think one of the things that can be a big challenge that people underestimate is we're at a conference here, AWS reinforced, obviously focused on security. But I think about all the AWS conferences I've gone to going back 7 or 8 years and all the new not only security tools AWS is releasing, which is awesome, but all the different infrastructure services, um, I remember being at the conference where managed Kubernetti's felt like the next big wave of opportunity for organizations. And then things like Fargate and AWS Lambda came about and security teams are really challenged to understand these new technology stacks not only in how they work, but what's the, you know, risk posture of these services, how do I work with the development teams or DevOps teams that are utilizing these services. As you think about the world we're in with Gen AI, um, you know, development and DevOps teams are flocking to Gen AI for a lot of different reasons when it comes to their, you know, coding practices. This can obviously present a huge challenge for security teams, and I know we'll plug into that a little bit today. Um, I think compliance requirements are obviously important whether it's an external regime or an internal process that you're trying to meet. And I hope that some of these other challenges that we see resonate with you, um, in your, you know, kind of view of the world as well. And I think this ultimately brings us to, you know, what are the different needs of developers and their security counterparts and so there's different needs when you think about how do you secure your applications as they're being designed, built, and deployed, um, and then how do you at run time or in production think about monitoring this very big attack surface and ultimately I would think of this kind of bar or connection point underneath where it's like how do I trace things. From right to left, so if I have a risk in a production environment, how do I go and find the developer or DevOps team responsible for that application, responsible for that infrastructure, and ultimately ensure it's more and more, you know, secure and again this can be a huge challenge from a team efficiency point of view. Um, one of the things that, you know, there's 2 more slides I have before I, you know, hand the mic over to Shri. And I think it's important to think about cloud native architectures because I think the world, you know, some people live in is we kind of assume we deeply know all the different needs of these architectures, um, and I would certainly not come here to AWS reinforce and lecture anyone on you know the needs for, you know, securing, you know, modern virtualized servers like EC2 in the cloud. I think everyone would have a really good understanding here of virtualization. But when you think about containers, Kubernettis, serverless applications or paths depending on how you like to term it, um, you start to get into more and more lightweight applications that are deployed at a higher and higher velocity in a more and more event driven way. Um, and this means that understanding these architectures and how it fits into your organization's overall risk posture is really, really important, and there's ultimately different considerations that you might want to take based on the different, you know, risk posture or threat levels or how you think about your organization using these applications. Um, I've certainly come to understand that there isn't a one size fits all approach for any organization um in today's world, almost everyone is using a combination of these architectures in some capacity. Um, I'll go back. There's someone trying to take a picture there so we can totally pause it. It's no big deal, um. And ultimately again this kind of feeds into the last slide for example um when you think about all the services that have been released, you know this is just one of the layers, the application or workload layer that AWS is obviously working to be a leader in in releasing these, you know, two customers. And then this is, I think being at AWS a really good way to think about the different areas of getting cloud security right um I think it can be really easy to just make cloud security a foundational data security problem, you know, you don't want PII corporate information, um, personal information of customers leaked into the outside world. So how do you make sure you understand where your crown jewels are, what might be accessing them. And if they're ultimately secure, um, then you have to think about your infrastructure layer so how have I configured all of the different services that I'm using on AWS? What applications are then gonna run on top of that infrastructure and then one of the I think biggest challenges can be identities and entitlements entitlements might be the roles service accounts or permissions um that I may get access to if I'm running in the cloud. And then certainly as we highlighted a little bit ago, getting into the pipeline and thinking about how do I secure my applications or infrastructure as code templates that I'm gonna provision earlier and earlier in the application life cycle rather than being reactive in production. This ultimately brings me to uh introduce Shri Thurihula, uh, hand the mic over to him as he drives through, you know, the real world use case at Autodesk, and Gus will be joining him. Thank you. Great job, Keith. OK. Thank you. Thank you, Keith. Uh, so before I start, I just want to share that all the statements and opinions that I'm going to share are my personal opinions and do not represent the views of Autodesk. So with that said, um, I'll quickly, um, explain what Autodesk, uh, does. So Autodesk is a global leader, uh, platform, uh, SAS platform for, uh, design and make industry. So we have products and software for, for, uh, entertainment industry, for, uh, design and manufacturing. We also have products, uh, in, in architecture and construction. So, anything and everything that um people can think of in terms of design and make, Autodesk has a solution for it. So, uh, we, we, uh, we have a wide range of products, major, majority of them deployed on AWS and as I'm from a security, uh, background, we wanted to secure most of, most of our solutions. So we work with developers, product managers to, uh, to drive down risk in terms of vulnerabilities, in terms of misconfigurations at scale. So that's what, uh, we are going to be talking today. And with that said, uh. Uh, a quick, uh, high-level background on the architecture of Autodesk. We are multi-cloud, um, as previously mentioned, with a heavy adoption in AWS and, um, a, a commonly used or highly adopted AWS services include uh EC2s, uh, ECS, Lambdas, S3, and also Dynamo DBs, uh, so things like that. So anything which is uh very high in the industry where, uh, in terms of adoption, Autodesk has uh has a presence in terms of its usage. Um, coming down to the security use cases that Autodesk had, um, uh, in terms of cloud was, uh, we wanted to identify, uh, telemetry visibility in in all the, all the subscriptions that get spun up and all the assets that that get created and uh configured in in the respective uh cloud subscriptions. And we also wanted to identify the misconfigurations in the cloud. So once, once we get the telemetry, we also want to look how the specific service is configured, how the specific asset is configured in the cloud, so that does it create any lateral movement, does it create any attack path, and all those type of asset context as well. Uh, we also have a golden image program where we build out, um, secure, uh, hardened images, uh, both for AMIs and container images where where we check for CIS benchmarks and also make sure that the image is free of any CVs, so that is free of vulnerabilities. So, so the downstream product teams can consume them and build in their pipelines for their respective services. And, um, another core uh security use case is uh the vulnerability management program at Autodesk. We want to scan all, all our uh cloud assets, uh, make sure that they are free of vulnerabilities, so we wanted to have a solution which can. Scale, so we use Orca's agentless platform to onboard all our cloud assets and cloud subscriptions so that we'll be able to get uh all vulnerabilities and share that across teams so that they can uh drive down uh vulnerabilities and uh cloud misconfigurations. And with that, uh, there, there was the final uh use case of risk prioritization. So once, once we operate at scale, there comes a huge number of alerts, uh, vulnerabilities. So how do we ask teams to prioritize? So Autodesk partnered with Orca in terms of a risk prioritization framework where we look into the vulnerability context, uh, where we look into the asset. Something like if it is present in CISA cave, if it is actively exploited, uh, a CV and also look into the asset if it is in production, is it like internet facing, so things like that we we weigh in, we come up with a uh logic to score a specific vulnerability so that we provide guidance for uh product teams. So that's been very useful for our product teams. Uh, they, they have seen. Uh, current guidance and appropriate direction in terms of reducing, uh, um, vulnerabilities and misconfigurations in the cloud. So the key challenges that we that we face were like alert fatigue, as previously mentioned, without proper context, there were too many alerts in terms of vulnerabilities and misconfigurations, so we needed a solution which helps us prioritize in terms of being valuable to developers' time and also making sure that we Uh, pinpoint the critical risk for uh for our developers to drive down risk, and, uh, we also wanted a solution which could scale and at the same time, uh, be, uh, Uh, very less in terms of false positives. So that, that agentless uh scanning from Orca has been really helpful in, in making sure that we, we will be able to scale in terms of any, any new subscriptions and also uh working uh with exception management has been very helpful in terms of driving down false positives or any acceptance risk. And uh prioritization is one more key factor that we wanted in terms of um. Priority for vulnerabilities and misconfigurations. So uh when, when, when we uh bubble up all, all of these findings, there are there are too many for developers to handle at once. So developers have very limited time in their sprint cycle, so they can't focus on all alerts that get. Identified in tools, so we, we work with developers in in making sure that they label they label their asset in terms of production, dev, stage and also making sure that if if it is a crown jewel, they they mark it so that we, we calculate all of that into our uh prioritization logic and uh lack of context is when, when, when an alert doesn't look into the 360 degree of, of its uh deployment in the cloud so. Uh, does it create any lateral movement alert or does it create any attack path issue so that we, we need to make sure that we bubble up these findings so that teams drive down the critical risk as as soon as possible. And we needed a solution which is multi-cloud so that uh we'll, we'll, we'll be able to scan using one solution instead of many. And uh with that said, um, uh, Autodesk was able to uh mature. The vulnerability management program at uh at uh in the cloud, uh, using Oca, um, mainly with the help of agentless scanning, so we'll be able to scan all new subscriptions, uh, new assets in the cloud as they get created. And uh granular exception feature is very helpful where we can point out a specific CV, specific asset, specific file path, and we can also drill down and also make sure that how many days do you want the exception to be lasting for. And as previously mentioned, prioritization is really helpful for developer teams in terms of, uh, prioritizing their remediation. And uh shift flap security, uh, will, will tie with our golden image program where we check for uh all the CAIS benchmarks for AMIs and then at the same time, uh for our container images. And, uh. Uh, these, uh, hardened images are also free of vulnerabilities. So they, if there is a fix available, we make sure that the fix is applied before we share to the corresponding product teams for, uh, downstream, uh, applications. And uh for cloud misconfigurations, we look into uh the entire 360 degree view of the cloud, making sure that there are no lateral movement alerts, uh, storage misconfigurations. Uh, it could also be identity misconfigurations, uh, network misconfigurations where, where we want to, uh, highlight those for the respective product teams to work. And uh risk prioritization, uh, the, the context of the asset and also the alert is really beneficial in terms of highlighting which one needs to be prioritized and. And remediated uh as soon as possible, given, given the respective SLAs. So, uh, here is an example from Orca uh dema account, uh, where you can see, um, uh, the attack path or uh the entire, uh, TTP, if you, if you can look at here, where there is a public facing EC2 instance, uh, which has malware could also have more uh vulnerabilities or issues. Uh, so it's kind of a critical risk posing processing asset, and it, it is tied to an, uh, it has an SSH insecure key on its on its disk which could allow an. Hacker if exploited to laterally move to a dev EC2 instance and that Dev EC2 instance has access to a corresponding data which is potentially could be a customers, could be something sensitive, which is at risk. So this entire flow of action could be very risky if an attacker from the internet exploits the first EC2 instance which is public facing. So this kind of risk is something that that is really valuable, where we can pinpoint uh what is the What is the immediate action, a developer or an engineer needs to be doing. So either they fix the malware alert or they make sure that they, they remediate the insecure SSH key to drive down the lateral movement a risk here. So things like this are, are really helpful for, for security engineers to, to get the 360 degree context and also uh look at, look at what is uh important for uh for, for the service. Uh, with that said, I'll pass it on to Keith, uh, for the upcoming features and also a few features that are already in production from Orca. Thank you, Shri, and thank you everyone for, uh, for having us here. So as far as uh Orca's vision for customers like Autodesk, one of our key things is continuously helping prioritize and just making teams more effective. Um, the ways we've done that has been through attack paths, through dynamic risk scores as risk, um, sorry, as Shri mentioned, and just continuously adding more and more context to help customers make quicker decisions and with less false positives. So one of the new capabilities that we launched um about a month ago is Ailist reachability analysis. Um, you know, a lot of our customers have and love the agent list vulnerability scanning. We're reporting vulnerabilities on containers, on images, but sometimes, you know, you send an alert or an issue to a developer and you usually get possibly. A response back saying hey this is part of the build file but when that runs it's not gonna be in the container, right? So one of the things that our CTO team set out to do is understand how can we do this agentlessly because you know there are ways to do that with sensors and looking at memory, but let's be realistic here, right? You can't always deploy thousands of sensors on every system. So we did set out a way to find how we can do this statically, how do we do it agentlessly. And one of the things that we were able to identify is, you know, starting points, entry points for containers, and what actually will launch once that container runs and the reachability analysis helps reduce vulnerabilities on containers that you would report just like any other prioritization on vulnerabilities, so. You know, many customers use criticalities fix available, um, you know, other components to prioritize, but this piece to say will this package be loaded when it runs and if you can answer yes or no to that, when you're sending these issues to developers, you are less likely to get a response back of this is not gonna be a problem, right? And that is one of the key focuses of the reachability analysis that we launched agentlessly. And that has really helped uh reduce vulnerabilities by as much as like 50 to 60% on containers that are being reported by simply just saying is it reachable, yes or no, um. You know, sure, I would love your comments to see like, you know, how would this help you guys at Autodesk and any other customer. This would be great because the, the best thing about this is this is can be achieved without a sensor. So driving teams to install a sensor would uh would would take time and also not scalable, but doing this agentlessly is is is very good and uh given that this can. Uh, drive down risk in terms of pinpointing which can be reachable will help product teams focus on the uh very important stuff in their, uh, sprints, so they have very limited time in their, uh, in their sprint, uh, depth cycle. So just focusing on things that are really critical would be something that would be helpful for security teams and at the same time, uh for uh for product. Fantastic. Yeah, and if you, the other part to this is like, you know, Sri mentioned before tying this into like GitHub scanning, right, and being able to actually, you know, one of Orca's key components here is when you do tie your GitHub repos or bit buckets, we're actually able to correlate deployed assets back to those repositories through different Docker files or terraform files. And being able to just see the full cycle of being able to click on a container and alert in production, seeing which repository it's coming from, what's in that code, what risks are there, and ultimately being able to tie the pieces together and say yes, this package belongs here. It came from the Docker file. It'd be best if we can just prevent it from being pushed out vulnerability. It also allows a conversation from security to dev opps because you can show the evidence, right? You can actually say here's what is going to actually run. And um yeah, this has been a great addition. I can remember Shree's reaction when we said it was agentless so it was great. Um, one of the other, uh, you know, key components here is AI SPM, right? Gen AI and everyone using different AI services. Um, as we spoke to many customers over the last few months or a year or so, one of the key factors is not even knowing what AI is actually deployed, what services, whether it be bedrock or open AI, just understanding the inventory part to know is anyone in my organization using AI services. And furthermore, part of this is not just so much about the cloud services which you can typically get via APIs and you know there's many capabilities to understand the inventory, but one of the bigger risks is also on the actual workloads themselves uh when you're installing, you know, Lang chain or all these other libraries that are related to that. Many customers don't understand that there's vulnerabilities just like any other package, right? And so the full component here is not just necessarily understanding the inventory or the configurations of the cloud service itself, but also how many VMs are out there that are using that have AI applications loaded that might have sensitive data that are being trained on. And also are any of these, you know, packages vulnerable that might allow an attacker to compromise a data model or a VM, for example, um, so that is something that Oca is very, you know, very well, um, full on road map. We also have obviously existing things we also use AI ourselves, uh, in a lot of different parts of the product, but, um, you know, I would love to hear your thoughts on. The AI components and how we've helped from that aspect. Yeah, ASM would really help in terms of let's step back and analyze what organizations want in terms of security. To start with, everybody wants to know what packages and libraries are deployed. Uh, at scale because we have so many developers who, who use the new stuff which gets uh available every day. So it, it gives amazing opportunities for companies to build and also at the same time gives tremendous challenges for security teams to catch up. So the first use case for everybody's. Symmetry visibility into GA applications and also libraries and packages. So getting that would itself be a huge benefit. And on top of that, getting vulnerabilities and alerts and risks for air related packages and libraries would really help given that there are so many. Uh, incidents that are happening out in the, uh, in the industry around AI, it's better that we have the right visibility so that we can, uh, drive down risk for everybody. So it'll be a huge benefit in terms of AISPM. Yeah, I mean, it's definitely been very helpful for uh many, I mean the, the most important conversation for most customers that we get asked is do I have any of these services in my environment, especially when customers have 500, 1000 accounts across multi-cloud, it's usually a challenge to understand what's even enabled. Um, which leads to the next topic which is also data security, um, posture management, right? Uh, obviously there's a lot of talk about this. Part of that relates to the previous slide which is AISPM. A lot of the workloads have sensitive data, right? There's training data and that live on these workloads and. You know, the easy part of this of doing DSPM is analyzing the services themselves, right? A database is supposed to have data. OK, what kind of data does it have? Is it publicly exposed buckets, etc. A harder part too is also on the workloads. A lot of customers that we typically, you know, work on. With data security posture management don't realize how many secrets, keys, dumps of, you know, exports of databases might actually live on their VMs and how they're exposed and how all those components actually add to the risk scoring. So when Sri earlier was talking about risk prioritization, part of Orca's goal here is to really raise the risk to the business, not just the risk, you know, for a vulnerability. And the, the part of the dynamic risk scoring that Orca does, especially with data security posture management, is when we do generate an alert for, for example, for a VM with a vulnerability, part of the other context that's added in there is that we find sensitive data on the system because that could determine if it's a critical. high, right? I might need to fix the vulnerability based on some factors, but if it also has sensitive information that could possibly cause a data breach or anything like that, I would want to escalate that even higher, and this is part of the whole dynamic process of Orca and constantly looking at changes in the environment to help increase scores and severities. And as far as data security posture management itself goes, like, you know, we have customers even recently where. Use cases come up all the time. We had a customer in India where they asked us, hey, we really need OCR scanning in the cloud because we have an application, we are, you know, asked to upload customer driver's licenses to the cloud. We store it somewhere. We have no solution. For it, so we were able to do everything else so you know we work with customers with partners like like Autodesk, and we actually created an OCR scanning where now we can scan image files for this type of data, and these are kind of the use cases that keep coming up based on what customers are building. Um, so we're constantly evolving in what we're actually scanning for, uh, for data, but part of this is the configurations understanding I have a bucket that's public, you might not care because you have another 30, but also understanding, is there anything important on that that can help say, you know, uh, just a misconfiguration check gets elevated to a critical because it's a public bucket and it has credit card information or something along those lines. Any comments from you? Yeah, the ability to scan different asset types like storage storage buckets, Azure blobs, or maybe even expanding into past databases, and again going back to the fundamentals of VMs and containers if they have any storage attached to them like a block storage, elastic block storage, if we, if we want to scan and identify issues. That would be really helpful and also Orca provides the ability to customize your scanning logics like sometimes the, the sensitive is a relative term, right? Like something that that is sensitive to a a medical industry might not be something sensitive to a different customer in a different industry. So the ability to fine tune your scan scanning logic and rules is very beneficial. And to tie all this together, it also bubbles up using uh the risk prioritization you mentioned. So we also want to be uh. Uh respectful of developers' time, so we want to only highlight the, the things that we want, uh, teams to really prioritize. So the previous example of an attack park that I showed, um, on, on one of the earliest slides, uh, which had an insecure SSH key on, on, on a EC2 instance. Would would again tie back to the DSPM module because it has an insecure SSH key which is sensitive, shouldn't be there using orca's risk prioritization, it would bubble up so that teams can focus on things like that. So DSPM again tying back to AISPM would be really beneficial. Yeah, I mean, data security is obviously one of the biggest concerns having worked in on-prem world around data security, who's accessing what it's obviously. You know, where everyone's putting data storing data, customer data, whatever it might be, so understanding its exposure, where it lives, who has access to it is obviously a key uh capability and prioritization, and it is all native within Oca uh scanning capabilities. Um, our next subject here is KSPM and how do we manage native applications. So Kubernetti's obviously is very prevalent, uh, in the cloud in many different flavors. EKS is definitely very popular, um, but there also are risks here, right? There's risks from the endpoint itself being public. There's service accounts, there's vulnerabilities that are part of the containers, so KSPM really helps um. Be proactive in how you manage, um, I guess your deployments within clusters and what applications are running with them, understanding the name spaces, the pods, and actually what everything you know relates to each other. How do we identify, for example, one image is being used for multiple clusters that are running, you know, thousands of containers and all we really need to do is really patch that one image that everyone is. From this is the kind of context that Orca can help with uh Kubernetes and containers and being able to, you know, even from a compliance perspective give you best practices, helping you understand lateral movements when there's service accounts linked to IIM roles within Kubernetes and how you can elevate privileges, you know, vice both from the cloud to the cluster and from the cluster back to AWS, right? So those are all the types of context and correlation that we're doing. Um, and in some cases we also do have sensor deployments where customers actually want to monitor real-time threats with Orca and do deploy on Kuberner clusters to like privilege escapes or escalations, um, from the containers themselves. So KSPM for us is very big. Obviously many customers use it, uh, including, you know, running on, um. Just what do you call, I'm sorry, uh, not managed services but just self-service like OpenShift and stuff like that so. So, uh, the added benefit that I would like to add is Orca has the ability to, uh, on board, uh, public clusters automatically. So, uh, with the agentless scanning, uh, Orca is able to onboard any public clusters and for private clusters, that's where the sensor that you mentioned, which is done through a connector and the ease of use is through help chart, so it should be easy for your, uh, DevOps teams to onboard orca connector as part of their build pipeline. So once we have the connector, I think we'll be able to look into all the risks and misconfiguration on the control plane data. So that would include any network misconfigurations, identity, or on the, on the, on the admission controller, uh anything that that we want to prioritize, uh, coupled with the data security scanning that that OA offers. That's a good point. The one, the one good thing that many customers see. Is that because we are completely agentless and a lot of the containers that are, you know, running on nodes are basically EC2 instances, right? So there is no actual requirement to on board any of your cluster K API to actually scan your containers. So one of the biggest things that customers get when they do connect Orca. I actually get visibility into a lot of containers that are running that they have no idea because sensors have never been deployed to those clusters and they get that visibility instantly without ever connecting to Kubernetti's API end point because all the underlying infrastructure is EC2 for the nodes and we're automatically scanning those you know without agents using snapshots. All right, and uh just to close this up, uh, we at Orca, you know, I've been around for 5 years. We are deeply integrated with AWS. We run on AWS and we have many uh services and extra checks like you know we have customers of all sizes. And a lot of the requirements can range, right? Some of our largest customers have asked us just because they want to build their own compliance checks to model additional information or additional checks that they need for their own compliance, uh, checks and what they want to meet, but the big point here is from a. Scaling perspective from just inventory and risk, one of our biggest, you know, integrations with AWS is all the different services that they have and being able to model allow you to build queries, uh, export whatever you want, and obviously provide risk and, uh, and reporting and things like that. And thank you, thank you all for your time.
