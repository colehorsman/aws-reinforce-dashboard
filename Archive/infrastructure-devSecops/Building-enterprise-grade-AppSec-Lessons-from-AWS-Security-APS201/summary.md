# AWS re:Inforce 2025 - Building enterprise-grade AppSec: Lessons from AWS Security (APS201)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=idGGQ74Scag)

## Video Information
- **Author:** AWS Events
- **Duration:** 54.7 minutes
- **Word Count:** 8,439 words
- **Publish Date:** 20250620
- **Video ID:** idGGQ74Scag

## Summary
This session from AWS re:Inforce 2025 is delivered by Leah Vader, a security engineer with 10 years of experience at AWS AppSec, focusing on how organizations can scale their application security practices effectively. The presentation addresses how AWS manages security reviews at scale while maintaining business velocity, and shares transferable practices that can be implemented across different organizational environments.

The session explores the evolution of application security from traditional "department of no" models to modern DevOps practices, emphasizing the importance of embedding security throughout the development process rather than treating it as a final gate. Key technical concepts addressed include risk-based security reviews, automated guardrails, and the implementation of security controls, while business challenges covered include scaling security without solely relying on headcount and maintaining development speed without compromising security.

The presentation offers several key solutions, including establishing a strong security culture, implementing a guardians/champions program, and utilizing AWS services like Config and Security Hub for automation. The speaker emphasizes that successful AppSec programs should focus on enabling teams to move faster while maintaining security, rather than just identifying vulnerabilities and ensuring compliance.

## Key Points
- Security cannot scale through headcount alone - focus on implementing practices and mechanisms
- Take a risk-based approach to security reviews rather than reviewing everything
- Security must be an enabler and partner, not a blocker to development
- Executive support and distributed security ownership are crucial for success
- Psychological safety is essential for encouraging security-related communication
- Implement a guardians/champions program to embed security awareness in development teams
- Clear criteria needed for what requires security review versus what doesn't
- Security controls should be standardized and automated where possible
- Focus on security outcomes rather than arbitrary rules
- Security culture is fundamental to successful AppSec implementation

## Technical Details
- AWS Config and Security Hub used for implementing automated security controls
- Custom Lambda functions and guard rules can be created for specific security requirements
- CloudTrail and S3 security controls built into account provisioning process
- IAM Access Analyzer used for principle of least privilege guidance
- Well-Architected Framework's security pillar provides baseline security controls
- Security reviews focus on authorization changes, sensitive data handling, and new endpoints
- Conformance packs available for standardized security rule deployment
- Automated guardrails implemented to allow fast development while maintaining security
- Detective and preventative controls used in combination
- Security standards incorporated into knowledge base and threat modeling processes

## Full Transcript

OK, awesome, welcome, thank you so much for coming. So we're frequently asked by customers how we at AWS can scale and operate at scale while performing security reviews for everything we launch. So today I'm gonna focus on the practices that you can apply to your own organization. So my name is Leah Vader. I am a security engineer in our AWS AppSec org. I've been with AWS for 10 years and doing multiple different roles for the last few years, working with our internal service teams, helping them build and launch securely. So, there's a few things I want to cover today. One, like some, one of our first learnings is that while we are a large security organization. We can't scale just by head count um I mean you can but it's very very expensive don't recommend it instead we focus a lot on implementing practices and creating mechanisms that allow us to maintain security and speed simultaneously. One thing before we move on, I do want to address is like I understand that not every AWS ASA practice that we have will translate to your environment. So I've curated this talk today by pulling out the things within AWS ASE that we do that I think will scale across almost all of our customer environments. So there's a few things I want you to get out of today. Um, one, I want to talk about the mechanisms and processes that we use for scale and creating good security outcomes. I want to talk about how we embed security into the development process with secure design principles and building automated guard rails. And then I wanna also talk about actually the first thing I'm gonna talk about is establishing a security culture all maintaining business velocity. I was chatting with a few of you guys earlier and one of the things I heard was we want better tooling to make sure that like one we know what our developers are doing and to stop them from doing silly things. I want you to change your mindset a little bit with that security culture um so we'll talk more about that because ultimately good application security is enabling innovation rather than hindering it. So let's first just start with where we are today and how we got here. Alright, when we look at the evolution of application security we can break it down to several phases, most of you have probably experienced this. First we have the traditional security model. This is like the gates and the guards. This is when security is the department of no. So apps at the end of the development cycle, then we conduct the review once all the development's done and then we find vulnerabilities we have findings and we send it back to the application team for rework. This creates friction. It's slow and frankly it doesn't have good security outcomes. So then came the DevOps era, and that came with new challenges. DevOps teams are moving faster than ever and security teams were still using old models, so it created this false choice between speed and security. So you move quickly and accept risks or be secure but slow to market. So we've learned security must be an enabler and a partner. Security teams should provide tools, automation, and guard rails to help builders build securely from day one. We embed security throughout development, not just at the end. The most successful ASE programs today. We're not focused just on vulnerabilities and compliance, we're focused on enabling teams to move faster and launch securely. So how do we do this? The key is being strategic about where you focus your security resources. I think you guys already know you can't scale ASAC by manually reviewing every line of code. It doesn't work at scale and you're not gonna build trust with your builder teams. So first, You want clear criteria for what needs a security review and what doesn't. So when I talk with customers this is a really common question is do you actually review everything? And the answer is no, we don't review everything, but we have clear criteria of what. Needs a review and what does not. And you, you want to be very explicit about both sides of that equation because you want to eliminate guesswork and prevent any unnecessary delays. So instead I suggest taking a risk based approach to app like reviews and focus intensely on changes that impact your customer trust. So these include things like modifications to authorization changes to how you handle sensitive data or introducing new end points. These are really like obvious ones there, but those should require a security review. And lower risk changes, things like UI tweaks or bug fixes that don't affect things like authorization. Like you still apply your security checks, like your scanners and your guard rails, but you don't necessarily need a manual security review. This allows your security engineers to focus on things that need strong security judgment. I also suggest empowering your teams, your developer teams to self-identify what needs review. Train them to recognize security sensitive changes. And then give them tools to make informed decisions about when to engage your security teams. That said, you should be looking at significant changes in your AWS environment and your code base because large changes often warrant a closer look and you want to ensure that your process is not circumvented. And lastly, this is not a static process. It should be dynamic and data driven, just like your business, and it's going to evolve over time. And even within AWS ASEC, it's continuing to evolve and improve, improve, excuse me. All right. So let's walk through a fictional Ae review. So we're gonna launch a new AWS service, and this is called AWS Sock Matcher. It's like we're at a security conference, right? We've got the expo hall, and whenever I go to these conferences, there's always socks, right? You collect all these has anyone gotten socks yet? Oh my gosh, like half the room, yeah, so we, we collect all these socks, we go home, they're all different sizes, all different like shapes, colors, whatever, and they don't match. So we're gonna build a service that will create an inventory of our socks. We'll use Gen AI to match it. And this will be our new AWS service and we're gonna walk through that process. Now, to be clear, this is fake. This is not a real AWS service. We absolutely don't need this service, but it'll be a good example service for us to walk through. So let's start with what I think is the most important part of our security process. And that's our culture of security. And this is what I was talking about at the very beginning where. I think if you focus a lot on your culture of security. A lot of your other apps like processes. will become a lot easier. But this will take time, but let me talk through how we think about it. So at AWS you often hear us say security is our top priority and security is everyone's job. The first thing is Executive support is non-negotiable. The idea that security is everyone's job can't just be a poster on the wall. It has to come from and be consistently reinforced by senior leadership, and when your CEO and leadership team prioritize security in both words and actions, it'll cascade throughout your organization. Second, you need to implement truly distributed ownership. So don't just say security is everyone's job, make it actually everyone's job. Like in our job wrecks requirements for SDEs, we actually include security as a part of that. Your security team should advise on risk for the organization. But your business units and your product teams must own the risk and risk related decisions for those respective areas like the developers own the software, the developers own the threat model, and they have strong ownership of the security of their systems. And 3rd is foster psychological safety in your organization. I know when I first started AWS this was like a weird one for me to wrap my mind around, but your people need to feel empowered to speak up about security concerns without fear of repercussions, so you can build the most advanced and sophisticated security tooling in the world. But it won't help if you have a security engineer who sees a concern and doesn't speak up because they're afraid of delaying a launch. So we celebrate those who speak up, whether it be a security engineer, whether it be a developer, because we wanna hear those concerns. And there's no repercussions even if they're wrong, even if they speak up and say, hey, I think this is a problem and finds out it's it's not a problem. There are no repercussions because we want to encourage that behavior. So finally, we invest in communication and education. There's a lot of ways we do that in AWS. But in APEC one way we do that is through our guardians program. So let's talk more about that. Does anyone here have like a guardians or champions program? OK, good number of you cool so I don't know if you learned about that from AWS, um, but I'm gonna talk a little bit about how we do it. So we are seeing more and more customers do this successfully, which is great. These are members of service teams who volunteer to be consistent champions for security within their own teams. Now I want to be clear about this. These are not replacements for ASEc engineers, nor are we trying to shift our workload by our workload, I mean ASEC workload onto the service teams. What they do is embed security early in the development process. So we spend a significant amount of time training these guardians on security principles, practices, how to threat model effectively, anything relevant to their work. And this pays off by bringing security awareness directly into the team's daily conversations. So we have guardians attached to like one or more guardians attached to every service team. And they participate in design discussions from the beginning, and they're asking the right security questions because we've trained them. And so when the ideas are still forming, We're bringing security early, and they also know when to engage AStec engineers if they need deeper guidance. Because AStec engineers for us actually get involved at the design stage. And again, the point here is not that we're pushing ASE work onto service teams. It's rather we're creating a collaborative bridge that helps helps teams think about security earlier and making the right design decisions from the start. Now at AWS our guardians don't have the authority to sign off on ASAC reviews. This remains the responsibility of us, the APEC engineers. That said, like I understand we operate as a pretty large scale and we have a lot of engineers and not all organizations can operate at that scale. So some of you may find it works better to empower your security champions to conduct and sign off on certain types of reviews. So if you choose this approach, my strong recommendation is to be explicit and intentional about when and where this happens. Document it clearly. And document which reviews require AStec engineers and which can be handled by trained guardians because implicit rules will create confusion. OK, so we covered our security culture. Let's start building our soft mattress service. So I'm gonna break this up in the process of uh our service team's development life cycle. I think it's important to note that this isn't a completely linear process. Like if you've built software, you know that occasionally you're still designing components while you're actually coding other components and you also know that like threat modeling is happening throughout this process. And lastly for us, the security engagement is happening from the design phase up until we sign off on the review. So let's dive into the design phase first. We're gonna talk about security controls. And actually before I dive into that. Has this group all like defined sets of like security controls of like this is what good looks like in our AWS environment are we still doing that? OK, I saw like one tiny little hand like maybe. Alright, so let's talk a little more about that. So AWS we developed security standards for our services that we are that we believe are central across nearly every environment. And we incorporate these standards into our appsite process. It's in our knowledge base for our developers or our builders to to review. It's part of our threat modeling process and oftentimes these standard security controls serve as mitigations in our threat modeling. They're not arbitrary, they're very intentional and thought out. And when we're creating these standards, we focus on the security outcomes and what we're trying to achieve. And then we ask, how can we make these these security faults? How can we automate them? And how can we build detections around them? So I'm gonna give you a few examples. We have Cloudril and S3. So for audit logging with Cloudril and ensuring S3 buckets have proper access controls, we've built these directly into the account provisioning process and then we've enforced them automatically through both preventative controls and detective mechanisms. And however, for the principle of least privilege, this requires a little more human judgment. So we can use things like IAM Access Analyzer to help guide these decisions, but we still do use human judgment to ensure we've actually achieved least privilege. Now I noticed there weren't very many hands raised when I said, does everyone have their standard set of security controls of what you want in your AWS environment. Uh, there was like a half a hand raised. So if you want to start developing your own security controls, I suggest looking at the well architected pillar or a well architected framework, and there's a security pillar in there. It's a really great place to get started with practical guidance on what good looks like and. It's based off of like what our security architects who work with customers every day have found works for our customers. Let's talk about how you can effectively automate these controls in your environment. So AWS config and AWS Security Hub are services that can help implement a similar approach to what we use internally in AWS. So config begins by recording and normalizing changes in your environment. And then you can apply rules and conformance packs to evaluate the compliance of your environment. These work as guard rails, so you can let your teams move fast while staying secure. You can also build your own customized rules with your logic using lambda functions and guard rules. So that means like if you don't see a managed config rule that works for you or that aligns with the security standards that you've set, you can go write your own. We don't necessarily have to do this from scratch. We've packaged a lot of these in the conformance packs, but also Security Hub uses config, uh, and they have their own sets of security standards like the AWS Foundational best practices, and they can deploy config rules for you that probably align with those security standards that you're you're looking for. And then finally you can automatically remediate using config if that makes sense for your particular control. It's like a good example of where you might want some automatic remediation would be like if you found a resource that's unexpectedly open to the world, you may want to remediate that immediately and automatically. All right, so we covered our initial controls, defining and automating those. But our sock match service is still in the design phase, and we need to start threat modeling. So for us in AWS I mentioned this before, our service teams have strong ownership of the security of the services and they're the experts of what they're building. This also means they own the threat model and the guardians are deeply involved in this process. But our AStec engineers, we help review the threat model, we make sure we have the appropriate threats and the appropriate mitigations, but the overall ownership lies with the service team and the guardian. And there's many ways to do threat modeling. You should choose what works for you and your organization, but our approach starts with show stacks for question framework. So first, what are we working on? This just helps understand the system you're building and what matters for security. We ask teams to create a diagram, like a data flow diagram, and then we also have them document the key assumptions too. This keeps everyone focused on the same thing and avoid was wasting time on things that you can't control. Next, we ask what can go wrong. This is where you find the threats in your system and there is no perfect list of threats. You would need to think deeply about your service and brainstorm with your team of like what really could go wrong. If you need help with this methodologies like stride can help give you categories to think about. And then what are we gonna do about it? These are your mitigations. Now when you're thinking about this from an AWS infrastructure standpoint, each AWS service has a security chapter in its documentation with guidance that can help you identify what those mitigations are. And then lastly, did we do a good job? The goal is to get better at threat modeling over time. This comes from practice and learning. We also have a threat modeling workshop called Modeling the Right Way for Builders. We ran it this week, I believe that was on Monday. So if you missed it, you can find it online. Also, to help with our threat modeling process, we built a tool internally called Threat Composer. So we, we found a lot of value in Fret composer internally. And so we ended up releasing it externally actually the same thing with that workshop we ran the workshop internally. Our AWS service teams really liked it and we realized that our customers would like it too, so we started running that externally. So Threat Composer, it's a tool that makes threat modeling faster and more consistent. I really like it. My favorite part about it is it helps you write clear and useful threats, and I'll show you what one of those looks like in a moment. And and it's a full tool so you can store all your threats and at the end you'll get a threat model and a human readable format and a machine readable format and then there's a dashboard to track your progress and identify coverage. So here is an example of threat modeling the sock matcher tool. This might be kind of small print, so I'll read it to you. A threat actor with a network path to the cloud front distribution can submit a large number of resource intensive requests, which leads to the API being unresponsive to callers, resulting in reduced availability for the sock match or API. And then you can notice in this tool we can. Link one or more mitigations to this threat and the service team would then go and implement those and attach any useful metadata at the end you have a full threat model. And this is an example of the dashboard I mentioned earlier. Um, and so this is, and there's a QR code if you're interested in this tool, this is, uh, this will link you to GitHubb and you can go actually host this yourself. I see some phones, so I'll pause for a second. OK, we're good? All right, so let's check in. Sock match update. We have our security controls. We're in active conversation with our security engineer. We're continue to work on threat modeling. But we need to write code. So let's talk about how we do this securely. So we often talk about paved paths. These are paved paths, you might hear this term as like golden paths, uh, also secure defaults. There's different ways to think about that. So we have teams that work with our builder experience organization and our builder experience organization is our internal org that creates all the builder tools. And so they we have teams that work with them to build paved paths and secure defaults and you can do something similar, you using tools like CDK constructs and cloud formation templates or whatever your preferred tool chain you have. Um, actually, is anybody using CDK today? OK, handful of you. I do wanna do a quick call out because there was a recent release. Um, I don't think they made a big deal about it, but I'm super excited about it. It's called CDK Blueprints. So this actually allows you to inject secure defaults or properties into your L2 constructs. so like your S3 bucket, you can inject specific properties, um, and creating thereby secure L2 constructs. So if you use CDK, look this up afterwards. It's very cool. So the goal isn't perfect standardization, it is making the secure way the easy way, not forcing a rigid secure pattern. So this kind of goes back to our security culture. We're not trying to force service teams down a specific path we're just trying to make security easy for them, and then we have guard rails later. So think about it this way, every service team has unique set of requirements, especially in AWS, right? We're launching everything from like contact centers to IOT services and so on. And if your paved paths don't work. Your development teams will simply work around them. And frankly, if it's not working, you want that feedback. You should be asking why doesn't this work? And what can we change to give the flexibility while meeting our security bar. And you can look at tools like cloud formation guard, cloud formation hook as guardrails, but the key is flexibility. You want the guardrails, but you need to also give flexibility for your teams. Teams may need to modify your patterns for specific needs or step outside those common patterns. For example, You, you may have a paved path for Dynamo DB as a data store. And our sock matchers team may want to use S3 for that data store instead. Allowing this flexibility while having guardrails to catch the buckets open to the world is a better experience for everyone and will help you move faster. And finally, measure and report on the effectiveness of your paved paths. It's common for ASEC metrics to report on findings and risks, but we also want to have metrics around the success of your APSEC teams. And this means establishing open and continuous feedback mechanisms. Are your teams using payAS? Are they finding ways around them? Why? And are they reducing friction and solving for the security controls they're meant to solve for? This data will help you refine your approach over time. Cause if you do take this this route of creating paved paths, you're not gonna get it right for the first time you're going to need to iterate, get feedback from your builders and continue uh with your process from there. So let's walk through at a high level how the development flow works for our builders. Remember, we want to meet the builders where they are and build security into their preferred and existing flows. And I say that is so, so important because if you don't and you force them down specific paths, they will just work around you. So for us, the builder rights code, and when they're ready, they use our standard development tooling to submit a code review. And a few things happen here. We have static code analysis that runs its purpose built for our AWS services. And once it's complete, the code goes to peers for review. So we always have one or more team members look at it, comment on it, and eventually approve it. And after any requested changes are made, the code can be merged. So let's take a step back into the development process. We're gonna go over how we're bringing some of our internal security practices directly to you through Amazon Q developer. So as we talked about, static code analysis is integrated into our builder tooling. But we've always operated under the principle that when we build something ourselves, our customers need these capabilities too. We've consistently heard from our own builders that they really like the feedback from our tooling, but they want that security feedback sooner, like right in the IDE as they're actively coding. And that's exactly what Amazon Q developer security scans can do. It brings real-time security analysis directly into their development environment. So you may be familiar with it from like the real-time code suggestions, but there's also security scanning built in there. So I'll show you a really quick example. So we have the infrastructure for sock mattress service. This is just CDK code and we got a download DB table. We've got a S3 bucket and I ran slash review, and we can see on this left hand side here that I, I have some code issues and this is security or otherwise, so all in one place so developers can get early feedback and I can hover over identified code and get an explanation. And this is an example of that. So you can get guidance on how to fix with appropriate code samples, and you have the option to generate code. This is great. And this is the IDE for the developer. And they like this, but we also recognize that security needs to be embedded throughout the entire development life cycle like in the pipeline, which we also have. So you have options to doing this in your own organization. One approach is using Amazon Q developer in the pipeline. So Que supports GitHub and Preview and Git Lab Duo. Or if you prefer, we have lots of partners who provide excellent stat code analysis tools that can integrate with your preferred pipeline. Alright, if you haven't noticed yet, we haven't talked a ton about the actual security engagement. So this is ongoing from design to launch, but let's dive in now. Alright, so at AWS we've learned that effective ASA begins before a single line of code is written. And our review process, I've said this quite a few times now, but our review process starts in the design phase. So first, we provide tools early. We recovered paved paths and tooling in the IDE but we also have an extensive extensive knowledge base. All of our security controls are in there along with additional like secure coding guidance and so on. And our our builders can browse that or they can interact by a chatbot that we built directly into our security review tool to get the help they need. We also ask that our teams engage us early. Early engagement allows us to shape security decisions which reduces friction for our builders later on. And we actually consistently hear from service teams that they get better outcomes with this proactive approach. As technology progressed, we've adopted a model where our engineers specialize in sets of domains and services. So for example, we have security engineers who focus specifically on Gen AI applications and services, and they're focused on understanding the unique security challenges in that space. We also have a team that focuses on the customer side of the shared responsibility model, diving deep into how our customers build on AWS and incorporating that into the appite process. The specialization allows us to provide deeper and more relevant engagements rather than generic security advice. And perhaps most importantly, we don't hope for security, we build mechanisms to ensure it, so we create processes, systems and tools that make security outcomes predictable and consistent. This approach scales far better than relying on heroic efforts or perfect execution every time. So I want to tell you about one of my favorite mechanisms. And that is escalation. Has anyone heard us talk about our escalation culture or escalations before? OK. Couple hands. Cool. So when I talk about security culture with customers, I often get skeptical looks when we talk about ownership and like the skeptical looks are often because. They don't necessarily they they normally say something like I don't believe that your service teams always agree with ASE or that ASE always agrees with the service teams. And we don't. So The next question is like what do you do? And for us the answer is simple. If something doesn't look right and we can't agree on a path forward, we escalate. But let me be clear what that means at AWS. Escalation isn't about conflict. Creating a mechanism for escalation isn't about who wins an argument. It's about ensuring that we make the right decisions with the right input. And I acknowledge that sometimes escalations is a bad word in some organizations where I worked before prior to AWS, it definitely was. And if this is your situation, my advice for you is still create the mechanism but give it a name, something else that's not escalation, at least initially as you develop your security culture. So effective escalation gets the right decision makers involved because sometimes these security disagreements happen because the people in the room don't have the authority to make the decisions and your escalation path should lead to those who do. Equally important is bringing the right data to these discussions. Escalations should be data driven conversations about risks, potential mitigations, and the customer and business impact, and everyone's working from the same facts, creating better outcomes. And the goal is to always create the right security outcome for your customers. So we found that escalation creates faster feedback loops in the appset process because escalation shouldn't drag on for weeks, adding people to CC on these long email threads. You want to get the appropriate parties in the room, virtual or physical with the right information so it should be the background of the service. What are we building? What's the problem? What's the risk? What's the impact? What are our propose or what are our paths forward? We should have several and then what's the proposed path forward? This is the ASE engineer writing this is what I think we should be doing and then the group goes and considers it. At AWS we view escalation as showing strong security judgment and ownership, not a failure, and we recognize and reward that behavior. So we just talked all about that, but you may want a practical example. So let's go back to sock matcher. So we already know sock mattress Service is like this fictional service that we are creating inventory of socks. Probably getting pictures storing an S3, so on. Um, And AWS we we enforce strong authentication authorization. And as a customer, you can observe this through IAM, right? But the stock mattress service team wants to implement their own identity model outside of IAM. If you worked with our AWS services, you already know like this goes outside the bounds of how we normally operate. But there may be business reasons to do that. Like I want my dad to use sock matcher service. My dad does not have AWS creds. But this is not a decision that should be taken lightly. We want the right people to understand the service, we want the right people to understand the identity model. And this will all help to an outcome that's secure and makes sense for the service and the customers. We need this fast and that's why we have escalations. This allows us to make the decisions. So AStech engineer, in this case it would be me. I'm gonna write up the background. What what is this service? What data are we we dealing with? What's the uh risk, the risk of creating a new identity model, what's the impact? What are our various options and a recommended path forward. And I may say it's this is going to be recommended path forward is we do support IM maybe we also support some OIDC flows, and then we follow our escalation path. We found that this gets us to the best security outcomes faster. But there's other mechanisms that you can, that we've actually talked about that you can implement. And the power of mechanisms is that they make security systematic and scalable. So think about it as a way, think about it as operationalizing intent. So examples include creating a definition of launch blocking risks, building that into your security review tooling, and then building a mechanism in your tooling to ensure that launch blocking risks are actually resolved before launch. And then you're secure by design or paved paths or mechanisms to start securely. Your automated guard rails are a mechanisms that allow your security engineers to focus on more high judgment problems. So we talk about how we measure success and improve processes through through metrics. I want to dive a little bit deeper into that. So first, We're talking about metrics. My first advice is focus on security outcomes, not just activity measure things that show better security, not just how busy your security team is. We set up metrics. They shape how people work. So pick metrics that encourage the behavior that you want. And avoid metrics that encourage the wrong behaviors. It's like counting security reviews might push teams to rush through them and hit targets. That's not a good security outcome. And tracking total findings might stop teams from reporting issues and keeping numbers down. And those numbers alone don't show your ASA program's impact. So let me give you some examples of metrics. Look at patterns in your findings. What are the common findings across teams? Like total finding counts, I as I mentioned before, doesn't tell you much. And finding issues is good, it means you're aware of the problem and you can fix it. Also be aware as you improve detection because you're gonna be consistently over time adding more detections, more scanners, and so on, you're naturally gonna find more issues if you were to graph that out like over time you'll see spikes like, oh, I added this detection and we see a spike uh when that new detection is released and that's a good thing. What helps most is seeing which problems keep coming back. Why do they happen? Is it just in certain cases? Is it certain teams? Are we all making the same mistakes? And then track how many teams are using your pay pass. This shows people are using the tools that you provide. And then ask Why aren't some teams using them? Are the tools helpful? Do they not work in certain cases? And when metric reveals issues, treat it like a system issue, not a team failure. Again this goes a little bit back to like our security culture, but this helps teams be open about the security challenges. And as you build your metrics, ask yourself, do these drive the results that we want? Do they encourage good behavior? These questions help create metrics that actually improve security, not just fill dashboards. OK, so we're gonna check in and go over some quick takeaways. So first, start the security review process early with your builders. Engage during the design phase when changes create less friction and architectural decisions can still be influenced. Build tools and mechanisms for builders to get started securely. Remember mechanisms operationalize intent. Don't just tell your teams to build securely, give them the tools, templates, and guardrails to make the secure path the easy path. When security is built into your builder's development environment workflows, becomes part of how work gets done rather than an afterthought. The define clear launch criteria, be explicit about what constitutes a launch blocking security issue versus what can be addressed later. And then create a mechanism for escalation paths. Disagreements will happen. That's normal. What matters is having a clear, efficient process for resolving them and bringing the right decision makers with the right information. And then track metrics on your business value, which we just went over. And finally remember the goal is imperfection. It's building mechanisms that continuously improve your security posture while enabling innovation at cloud speed. Security is a journey, not a destination, and the most successful programs focus on continuous improvement rather than achieving the state of perfect security. OK, let's move on. We're working through our review, we're getting findings attached to our review. This is part of our soft mattress service. We have guidance on how to resolve these and we can start to work to address these findings, like, let's look at the tooling automation that's creating these. So we're moving on to our security focused tests, our scanners, and pen testing. So I'm commonly asked when I talk to customers about our ASA processes, do you use centralized or decentralized tooling? And RAWS security teams own and maintain the core security tooling. The centralization ensures consistent security standards across the organization. It also means that we can rapidly deploy updates or add new detections without involving service teams. We learned that security tools are effective when builders when we meet builders where they are. So remember how I talked about like staying within the builder's workflow? This is one way we do that. So rather than forcing them to contact switch, go to separate security systems, we integrate that directly into their environments and their workflows. And we try to avoid any extra onboarding for teams. This integration dramatically increases adoption and effectiveness. As you're aware, The reality is that manual security reviews, while valuable, can't keep pace with the velocity of our modern development, and that's why we've invested heavily in automated scanners and tests that run continuously in our environments. This would be in pre-prod and prod. Obviously I'm talking about pre-prod because I'm an ASEC. We're pre-launch. And we have way more than I can fit on one slide, but I wanna give you some examples of how you can achieve a similar result. So we do authorization testing. And one way we do this is through automated reasoning with tools like Zelkova, and we actually turn around and give that back to you as a customer for you to use through IM Access Analyzer. We also have continuous scanners looking for configuration compliance and you can achieve something similar using security hub and config with config rules and no anything can be customized and can be done through a custom config rule. So if you don't see like configuration compliance or any other like tests that you wanna run in your AWS environment, you can create that in a config rule or just schedule it as a lambda function event bridge. But you should also be adding your own detections, and you should be continuously learning from your past incidents. So we have processes in Amazon when something goes wrong, security or otherwise, where we ask the five whys, why did this happen? And we have an answer and why did that happen? And at the end. We start to ask ourselves how do we detect this again and if it ever happens, how can we remediate and you should be doing the same thing is if you have a security incident, start digging into it. Why did this happen? What failed? How do we make sure this never happens again and then go write code to detect that again and remediate if at all possible. Now let's talk about security focused tests. So this is a practice that can be overlooked but it's really, really valuable. These aren't generic detections. These are canaries that you're writing specifically for your service and your threat model is going to inform what these should be. So when you ask the question, what could go wrong, that's the question that should drive part of your testing strategy. Write tests that prove that your service behaves correctly, not just in normal conditions, but especially in conditions when someone's trying to do something they shouldn't. And then it's so important, test the negative because that can get forgotten really easily. So let me give you an example. I've got my sock mattress service, and we asked what could go wrong. Well, somebody could get my sock data. I'm storing pictures in S3. We've got metadata and a Dynamo DB table. I need to write a test that verifies that an untrusted identity cannot access my SOC data in S3 or Dynamo while a trusted identity can access my SOC data, and we need to test both outcomes. And these can be can canaries running continuously because if I ever push code or there's unexpected change, I want to know if any of that caused a regression in my security controls. And you can schedule these on your own with AWS lambda functions and with AWS vent bridge. OK, now let's talk about findings. We built a system where findings automatically linked to reviews and they have risk-based prioritization. This automation ensures nothing falls through the cracks and teams focus on the most important issues first, we fix any launch blocking findings. But we also recognize that automated tools don't have the full context. That's why we allow engineers to use their judgment and influence the severity of a finding based on the context of the service or the data that we're handling. For example, like a finding might be medium severity in one context, but could be launch blocking in another depending on like the sensitive sensitivity of the data that we're dealing with. Launch blocking findings require resolution before service can go live. For us there's no ambiguity here. If it's launch blocking, it must be fixed. For non-launch blocking findings, we still maintain accountability. Each finding has an explicit owner and has an estimated completion date. This prevents the, uh, we'll get to it later, go on the backlog syndrome. What I believe makes our approach particularly effective is that apps like engineers are actively involved to ensure resolution because we solve problems together, not in isolation. Security isn't throwing issues over the wall. We're rolling up our sleeves and working together with our service teams to implement these solutions. So overall this leads to better security outcomes. So our sock match service is now written. We're working through findings and we need to complete our penetration testing. AWS we have predefined criteria for when pen testing is required. This removes the ambiguity and ensures consistent application across our services. That said, we still value engineer judgment in this process to decide ultimately if a pen test is necessary. And then next, the OStec engineer and the service team write the scope for their pen test, and that goes to the pen testing team. Additionally, penetration testing for us isn't a one-time event. We are continuously looking for changes and validating known good states because systems evolve over time and we want to valid validate that. Now this is one of those things where like I acknowledge we have many security engineers and we can operate at scale. So if you're building or improving your own ASte program and you don't have dedicated pen testing engineers, there are partners who specialize in this work and there's many qualified security partners who can help you and implement that pen testing. You're probably in an expo hall and you can probably get some free socks. OK, so we made it to AS like sign off. Now what? So we went through our development we used security defaults, we use paved paths we worked on a threat model we built our mitigations. We wrote security focused tests based off our service and the threat model. We had all our scanners run, static code analysis run. We had pen testing completed. We had findings and they got attached to our review. We worked with our AStec engineer to resolve those findings and now we're ready for the review to be signed off. So we move on to continuous monitoring and testing and improvement. So this is a really good point for a retrospective, asking what what well, what did not? What could we do better? You want to build that feed that those feedback loops. It isn't about finding problems, it's about making the entire process better. If we see recurring findings or issues, we ask how can we build this into the ASA process from the beginning. And then we also for us at AWS we deploy mechanisms at scale. For every solution we develop, we ask how can we build this for all of our services because this multiplies the impact of our security work across the organization. And each of these components must be measurable, repeatable, automated where possible, and they must be aligned with our business and customer objectives. If you're a smaller organization and don't think this applies to you because of scale, it probably still does, but maybe it's just not like a different scale. It may not just be like the number of services you deploy, but also your builders. Not all not all developers write code or it's not just the developers that write code. Consider who else in your organization will be using these mechanisms that you're building and make sure they're included in those mechanisms. All right, I wanna leave you with a few parting thoughts. I'm including the next couple of slides because honestly I do get every get asked this in every customer rea uh customer interaction lately. And the number one question I get is, are you gonna replace your security engineers with Gen AI? And so I, I may have a little bit of a bias here. I'm a security engineer. I work, but I work in this space and I think generative AI can amplify human judgment, but it's not gonna replace it. Let me be clear about this, it's a powerful tool and it is changing how we approach security, but it's not gonna be the entire solution, and we still need human oversight. However, it does allow our engineers to focus on really interesting problems that only a human can solve. So when should we be using Gen AI? Which actually, are you guys using Generative AI in your application security process? A couple. OK. So this is an evolving space and we're going to see it change over time. Um, so first you might find utility in using something like Amazon Q for security tests to identify those test cases. Remember I was, we were talking about like you want the security focused tests and you, you're gonna use your threat models to identify those, but. AI can be helpful in finding those those specific tests and also finding the negative, right, because humans are really good at creating test test cases for happy paths or identifying like yes, I do need to test this, but we forget to test the sad path or the negative and generative AI can be very helpful in finding those. And you may also find use cases for identifying threats that you didn't think about before in your threat model. Now I wanna be really clear, this does not replace strong ownership and deep understanding of your service. But it may be helpful with asking the question what could go wrong, but you still need that human judgment to determine if those supplied threats are actually applicable to your service. And I also find that Jenni Tavea makes a great assistant in the review process. It's really helpful for creating data flow diagrams so you can get a really quick high level of like what is this piece doing? And then also asking questions based off the code base that you want to dive deeper into, so you may know like working with that service team and working through the threat model that we probably need to do some validation and you can use generative AI to see if that's actually happening in that code and I can point you to where you need to be looking really quickly, but you need to use your security judgment to one determine is this truly effective? Is it working the way I expect it to? And are we doing this validation everywhere we need to be doing it? And all that said, keep in mind your results may vary based on the complexity of your application code, especially as you're working across multiple packages, but. AI enhances but doesn't replace security expertise. When combined with strong human judgment, it delivers better security outcomes. And then the very final takeaways. First, I've talked about this a lot. The culture is the foundation of how you scale. Builders own the services and the security of those services, and ASE enables them. We don't own security for them. This mindset must start at the executive level and flow throughout the organization. And then create a clear escalation mechanism. This allows decisions early and gives visibility into the risk during the review process. Automation is how we scale. Look for every opportunity to automate routine checks and controls. This frees your security engineers to focus on the complex problems that truly need human judgment. And then use risk-based prioritization. This ensures you're spending your security resources where they have the greatest impact. And then capture metrics for visibility. If something matters, it needs to be measured and then improved over time, because without data, you're just guessing at what working, at what is working and what isn't. And finally, build feedback loops for continuous improvement because we're never done improving our appsite processes. Thank you so much. I hope this was helpful. Thank you.
