# AWS re:Inforce 2025 - Building secure development into Amazon Stores (APS221)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=A52-Cb0abT4)

## Video Information
- **Author:** AWS Events
- **Duration:** 19.7 minutes
- **Word Count:** 3,020 words
- **Publish Date:** 20250620
- **Video ID:** A52-Cb0abT4

## Summary
This session by Will Voorhees, Principal Software Development Engineer at Amazon Security, shares lessons learned from building security into Amazon.com's development processes. With 13 years of experience securing Amazon's operations (300+ million items, 750,000 fulfillment robots), Will discusses transitioning from reactive security enforcement to proactive integration. The presentation covers Amazon's distributed team model challenges, the failure of "brute force" security approaches, and successful pivots including two-way dialogue with development teams, automation investments, and technical direction influence. Key focus areas include host patching elimination through serverless adoption (AWS Lambda preferred, Fargate secondary, EC2 tertiary) and AWS account configuration security through limited SCPs and infrastructure-as-code promotion with build-time validations.

## Key Points
- **Amazon's Scale Challenge**: 300+ million items on Amazon.com, 750,000 fulfillment robots, distributed teams with wide technical latitude creating security complexity
- **Failed Brute Force Approach**: Reactive engagement, becoming background noise, relationship deterioration, security team burnout
- **Successful Pivot Strategy**: Stop talking, start listening; understand team obligations; negotiate reasonable timelines with business context
- **50% Time Reduction**: Two-way dialogue approach reduced security remediation time by nearly 50% while improving relationships
- **Automation Investment**: Auto-discovery of application data types, software inventory, AWS service architectures before AI era
- **Prevention Over Reaction**: Embedding security into SDLC, becoming opinionated on technical direction, influencing design decisions
- **Host Patching Strategy**: AWS Lambda first (no hosts), AWS Fargate second (easier container patching), EC2 last (instance replacement preferred)
- **Technical Direction Alignment**: Security goals aligned with company direction toward serverless, cost optimization, and availability
- **AWS Account Security**: Limited SCPs for critical controls, infrastructure-as-code promotion, secure constructs sharing
- **Shift Left Implementation**: Build-time validations using CDK NAG, CFN NAG, CloudFormation Guard before AWS account deployment

## Technical Details
- **Tooling Integration**: Internal ticketing systems with business obligation communication, automated time request processes for security work
- **Auto-Discovery Capabilities**: Application data classification, software inventory scanning, AWS service architecture analysis
- **Host Patching Hierarchy**: AWS Lambda (no patching), AWS Fargate (base image updates), EC2 (AMI refresh with ASG instance replacement)
- **Container Patching Strategy**: Base image updates with routine container replacement, code portability enforcement for easier patching
- **EC2 Patching Options**: In-place patching or instance recycling with latest AMIs, emphasis on host replacement tolerance
- **AWS Organizations Implementation**: Service Control Policies (SCPs) for critical security controls like IAM role deletion prevention
- **Infrastructure as Code Benefits**: Code review processes, change history in commit logs, shared secure constructs for common use cases
- **Build-Time Validation Tools**: CDK NAG for AWS CDK, CFN NAG for CloudFormation, AWS CloudFormation Guard for policy validation
- **Security Controls Scope**: Public S3 bucket detection, encryption configuration analysis, AWS account configuration monitoring
- **Development Guidelines**: Documentation pointing to Lambda, starter packages using serverless, compute choice guidance hierarchy

## Full Transcript

Hello folks. Welcome to the very last presentation of re:Inforce 2025. I appreciate the massive turnout. Uh, so you're here to at building secure development into Amazon stores. My name is Will Voorhees. My pronouns are he him, and I'm a principal software development engineer with Amazon Security. I've been working on various security tools at Amazon for a little over 13 years and like many of you, I've developed a passion for security. But it is, oops, wrong button. There we go. But it's also my profession. Like many of you, I spend my work day obsessing over security. In my case, that is specifically how we can ensure that Amazon.com's customers and employees are protected, whether that means keeping credit cards safe for the people shopping, uh, for on the over 300 million items on Amazon.com or ensuring that our 750,000 robots in fulfillment centers are doing exactly what they should be doing. And then critically, how can we do all of that with minimal cost and software builder toil? So, if you spend your day thinking about the same kinds of concerns, or even if you just want to be more of a champion for security in your organization, you're in the right place. Today I'm gonna talk about some of the things we've done to embed security into our development process and build a culture of security from the ground up. I'll also talk about a few things that completely failed. So, let's get going with that. To understand our goals though, we need to know a little bit about how Amazon.com operates. As you may have seen in Andy Jasi's 2024 letter to shareholders, we call ourselves the world's largest startup teams and organizations around the company and literal world are empowered to fully own and solve problems and to move super super fast. Each team has a wide latitude in how they do this. From a technical perspective, this means teams get to choose the best tool for the job. They can pick programming languages, frameworks, infrastructure and dependencies that are the best way to solve the problem they're trying to solve. Unfortunately, this also means the paradox of choice kicks in. The Paradox of choice is a book published in 2004. In very short summary, it talks about how having more freedom to choose increases anxiety. The bad news is that this impact isn't limited to just the team trying to solve a problem. It bleeds over into security as well. As a security person your life is much easier if you can put bounds around things define a perimeter if you will. Having all these different teams making all these different technical choices gives them the ability to move fast, but it also increases the complexity of our job as security folks. You might need to end up worrying about PHP, Java, Protobuff, and any other number of technologies. That's certainly where we're at. So, how do we approach that situation? Well, for a long time, our answer was to just brute force the problem. Anytime we identified some kind of security concern, we'd engage with the teams via our internal ticketing systems and generally just make a big stink about doing the work. We were also forced to become security experts on whatever technology was in use. Now this is an effective strategy, but only to a point. People do listen to you when you do this kind of thing, but we ultimately found some key flaws with this approach. I'd like to talk to them, talk to you about them a little bit just as a cautionary tale. First, this approach is entirely reactive. By the time we're showing up, decisions have been made, a path has been chosen, and if there's a foundational security concern with the technology or system architecture, it's expensive for the team to undo. Much like software bugs, security problems are way cheaper to fix if you can catch them early, and even small problems multiplied over an entire enterprise can really add up to some measurable cost. Second, people eventually put in earplugs. That big stink from security just becomes background noise. Engagement drops and the relationship between security and the business starts to suffer. In the worst case, a team completely tunes you out and when we're talking about security problems, that is the last thing we want to have happen. And finally it is tiring bringing that kind of energy every day day after day it eventually just becomes too much and people start to burn out not a healthy state for a security organization, let alone any other organization. So we pivoted, we had to change things up. We recognized that we need to rethink how we were engaging with the business. Our ways of operating were beginning to work against us and the company was moving and growing faster than we could scale. So we had to change a few things. Our number one change was to stop talking so much and to spend more time listening. When we did that, we found the teams were super overloaded. The security work we were asking them to do was just one small part of their day. They also had to deal with availability work, general maintenance and all of that on top of trying to deliver value for customers when we showed up and started unilaterally setting due dates on security work, the business just saw one more thing being thrown on their plate. I'd imagine that's something a few of you at least can relate to. So we created a new model where the business could communicate back to us their non-security obligations and have a discussion on how to prioritize that security work. Our tooling introduced that ability to request additional time for security work with a description of completing obligations. We introduced a process where we could meet with organizational leaders that had large backlogs of of security work, go through, help prioritize the list and agree on some reasonable due dates for when that work would be done, all while trying to make sure compensating controls were in place. Now, this has proven to be wildly successful, which with the benefit of hindsight really is not that shocking. Everybody loves to be understood. But not only have we received positive feedback from the business, we've also found that the time needed to address security work dropped by nearly 50%. Yeah, it's crazy. It's like we were having a prime day sale on security work. It was kind of an incredible result. By spending time with these teams and helping them prioritize things, it redefined our relationship. We started to find that teams would proactively plan more time for security, turning us from an interrupt that was hard to plan for into just a normal part of their day pretty cool result. But that's not all we've been doing. We've also started pushing heavily on automation and despite this image I don't mean robots and fulfillment centers on this one. I mean removing humans from the day to day security work we invested in building tooling that could auto discover a bunch of information we used to rely on humans to tell us things like what kind of data an application was handling, what kind of software teams are building, or even how they were architecting with AWS services. This investment increased our visibility into the state of the world since we could just inspect way more things than our humans ever could. That enhanced insight has allowed us to frame and prioritize where we focus our attention into the areas with the most security risk, so we've got efficiencies too. And we did all of this before AI was started really taking off in the industry, so I'm just super excited to see what the next generation of all this looks like. Speaking of the future. One thing we're always doing is raising the bar or set another way. We're always working to improve our state of the art and make that a thing of the past. Engaging with the business and investing in automation have helped build trust and reduce toil, but ultimately these are investments in reaction speed where we really wanna get is full prevention. So we're continually investing in banking security into the software development life cycle or SDLC. Our biggest focus here is becoming more opinionated on technical direction and influencing the business we wanna give them more direction on their technical options specifically through the lens of security right when they start designing in their SDLC. Because of that distributed nature of the company though, we rarely invest in top down mandates to get things done, but we will do that when we need to. Instead, we need to incentivize making choices that align with our preferred direction. Now a key element to that is that we need to be aware of the technical direction of the company as a whole in other dimensions like availability or cost and then if possible align our security goals with that direction so everything is pointing the team one way. Let's do a case study on that, post patching. Purely in terms of volume, host patching is our single largest source of security work that we ask teams to address. That's not terribly surprising. We operate quite a few hosts. There's a lot of things to patch. So that mean host patching a prime candidate to try to find ways to influence team technical choices. And fortunately, the technical direction for the company aligned well with security outcomes. Specifically, we don't want teams using hosts. Instead, we want them to go serverless. And now also not surprisingly, we rely on AWS services quite a lot, so there's a natural technical choice here. A to be a slam dunk. Now in terms of host patching AWBS Lambda is pretty much the perfect solution. There are no hosts. You don't need to worry about patching something that doesn't exist. It's great. So this has become our de facto answer for compute options the team should choose. All of our developer documentation points DaS Lambda. Our starter packages to bootstrap new services use AWS Lambda. In all the places where where we have guidance on compute choices, 80B lambda is right at the top of the list. But obviously not every workload fits well on AWBS lambda, so we have secondary and tertiary choices as well. Essentially we say if you can use AWS lambda if not. Use AWSargate. This is a great choice for heavier weight workloads, but it also introduces more host patching complexity, so it's second on the list. AWSargate is actually pretty interesting from a host patching perspective. You don't actually have hosts to manage, so a lot of people think that AWS Lambda, AWBS Fargate are the same when it comes to host patching. The bad news is containers still need host patching. The good news is it's a lot easier. Containers naturally enforce a lot more code portability than directly installing applications on a host. Because of that, host patching can often be accomplished just by picking up the latest version of your base image. So as long as a team is routinely getting a new base image and is routinely swapping out their containers, they can effectively effectively remain fully patched with no manual work at all. But obviously not every workload fits well on AWBS Fargate. So when all else fails, use Amazon EC2. Here host patching is really fairly traditional. You can patch in place a running instance or you can recycle instances with the latest version of your preferred OMI to get them patched. Now when we have teams running on Amazon EC2, we encourage them to get to a point where they can tolerate host or instance replacement. Systems that are tolerant to host replacement have way more flexibility in how they can approach host patching. This does require investment though the system needs to be well tested and have appropriate startup validation to ensure that when a new instance comes up, it's ready to go before being put into service. Once the system can get to the point where it tolerates host replacement, patching can just be as easy as updating your OMI and running an instance refresh cycle on your ASG. That's it. So summarize all that host patching business. We're influencing team technical direction on compute to emphasize AD boost lambda serverless as our first choice. When that doesn't work, use AWBSargate. When that doesn't work, use Amazon EC2 and bias towards supporting instance replacement. This guidance has been in place for a few years now and we're finding those teams build out new services and adopt these recommendations they can virtually eliminate their host patching workload. I can attest to this firsthand. I'm a technical lead for my organization, and we've been building new tools exclusively on AWBS Lambda and AWS Fargate for about 5 years. I effectively spend 0 time worrying about host patching. It's pretty great. I'm maybe not quite as relaxed as this cat, but I'm close. So if we can be successful in socializing this with the rest of the company we're gonna see a sizable reduction in the time teams are spending on this whole class of security work it'll be great. All right, I want to touch on one other kind of security work, AWS account configuration. Amazon stores is an AWS customer, much like many of you, and as you know, there's no shortage of ways to build a system using AWBS services by putting them together in different ways. Following the AWS shared responsibility model, we take security in the cloud very seriously. We want to ensure that all of our distributed teams know and follow our preferences on how to use AWS safely and securely. I imagine you have similar goals. So what are we doing there? I mentioned earlier that we tend to not do top down mandates except in rare situations. AWS account configuration is one of those situations partly. We use AWS organizations to add some limited hard controls on what can be done in our AWS accounts. AWBS organizations has a feature called Service control policies or SCPs that allows you to set permissions that block certain actions and put controls around configurations you just never want to see. So when we provision a new AWS account for our team, we automatically enroll them in our AWS organization and set up some basic security infrastructure. But our use of SCPs only cover a handful of situations, things like deleting IIM roles used for security instant response or monitoring. Because we empower teams to move fast and have ownership of problems, we don't proactively block most ways of using an AWS account. This tactic is reserved for only the most critical security controls that we just can't miss. Now you might be asking, well, what about everything else? Excellent question. While SEPs control the most important aspect of ABS account configuration, there's a much larger set of possible configurations that we're opinionated about and want to inspect for and potentially ask teams to change things like public S3 buckets, encryption use in various places, stuff like that. Now because the because we have teams solving a wide variety of problems we're just not comfortable proactively blocking these kinds of configurations across the board. We inspect for them, have a conversation with the team and see what their use case actually is. But here again, this is reactive. Someone's already built something now we may need to ask them to roll it back. It's not fun. We believe that prevention is really the better path, so we've been pushing on all of our teams to use infrastructure as code or IAC. Shifting teams to IAC immediately gives us a number of security benefits. Since it's code, all of our code review processes immediately kick in. We have more than one person looking at the code, so there's a good chance there this extra person will catch some problems. We also have history on changes and reasoning for those changes in commit histories, which is an incredible asset when trying to understand how teams operate. And going even further, we can share pre-reviewed constructs for common use cases that teams can optionally pick up to get going in a default secure configuration. But most interestingly, we can actually start making build time validations on the security posture of infrastructure that will be built using tools like CDKAG CFNAg, or AWS cloud formation guard. You may have heard the term shift left, which means putting security and other configurations earlier in the SDLC. This is a prime example of that. All right, our time together is quickly coming to a close, so let me recap a few things. So first thing we did, we invested in relationship building with the business and established this two-way dialogue about what other obligations exist. This was wildly successful and actually ended up reducing remediation times by nearly 50%. We've been integrating security into design decisions, becoming more opinionated on team technical directions, and by doing this we can actually eliminate whole classes of security work like the host patching thing with AWS Lambda. We're moving teams to infrastructure as code. It's allowing us to completely prevent security problems through secure constructs, build time validations before anything ever actually gets created in an in an AWS account, which is great. Now we know there's still a lot more work to do on this, but these changes have already started to prove very beneficial, and they're just gonna be paramount in our ongoing mission to keep Amazon stores secure. So thank you everybody for your time today. If you want to chat about anything here, I'll be around afterwards, maybe see you at the party later. Do please complete the survey and thank you for attending Reinforce 2025.
