# AWS re:Inforce 2025-Advanced network defense: From basics to global scale with AWS Cloud WAN(NIS305)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=1C--MJMGllk)

## Video Information
- **Author:** AWS Events
- **Duration:** 55.9 minutes
- **Word Count:** 9,074 words
- **Publish Date:** 20250620
- **Video ID:** 1C--MJMGllk

## Summary
This comprehensive session by Sid, a Principal Solutions Architect with 11 years at AWS, covers advanced network defense strategies using AWS Cloud WAN for global-scale security. The presentation focuses on the CIA triad (Confidentiality, Integrity, Availability) with deep emphasis on confidentiality through network authentication and authorization. Key topics include network isolation using routing boundaries and private connectivity, traffic filtering through purpose-built AWS services, and centralized vs. decentralized inspection architectures. The session demonstrates how AWS Cloud WAN enables segmented global networks with automated service insertion for deep packet inspection, and concludes with an innovative demo showing how Amazon Q Developer can automatically configure Cloud WAN policies and service insertion through natural language prompts.

## Key Points
- **CIA Triad Foundation**: Network security built on Confidentiality (focus of session), Integrity (encryption in transit, configuration validation), and Availability (DDoS protection, load balancing, redundancy)
- **Network Identity & Authentication**: VPC provides inherent IP address authentication through network mapping service, preventing IP/MAC spoofing unlike traditional networks
- **Two Authorization Approaches**: Network isolation (routing boundaries with Cloud WAN segments, private connectivity with PrivateLink) and traffic filtering (security groups, firewalls)
- **Cloud WAN Segmentation**: Create isolated routing boundaries (production, development, hybrid) with policy-driven configuration and automatic route population
- **Service Insertion**: Single-click insertion of AWS Network Firewall or third-party appliances using Cloud WAN network policies for centralized inspection
- **Traffic Flow Patterns**: Internet egress (centralized vs decentralized), East-West VPC-to-VPC inspection, North-South hybrid connectivity, and Internet ingress protection
- **Scaling Considerations**: 100 Gbps per VPC attachment per AZ, 100 Gbps per firewall endpoint, with linear scaling by adding AZs and endpoints
- **AI-Powered Configuration**: Amazon Q Developer demo showing automated Cloud WAN policy creation, service insertion setup, and CloudFormation template generation through natural language

## Technical Details
- **Cloud WAN Architecture**: Core Network Edges (CNEs) are regionally deployed, highly available endpoints that form a fully meshed network using eBGP for route exchange
- **Appliance Mode**: Required for stateful firewalls in East-West inspection to maintain flow symmetry using flow hash state across availability zones
- **Cross-Region Symmetry**: Two modes - Single hop (one inspection VPC for both directions) and Dual hop (both regions inspect traffic)
- **Network Function Groups**: Special Cloud WAN segments dedicated to hosting inspection VPCs and firewall appliances with full routing visibility
- **Service Insertion Policies**: 'Send to' policies for internet egress, 'Send via' policies for cross-segment inspection with automatic route population
- **Edge Overrides**: Manual control over traffic routing decisions when Cloud WAN's predetermined algorithm doesn't meet requirements
- **NAT Gateway Offset**: Free NAT Gateway hourly and data processing costs when deployed alongside Network Firewall in traffic path
- **Private Link Integration**: Three connectivity types - AWS services, cross-VPC service access, and VPC resources (Aurora, RDS) via resource gateways
- **Firewall Manager**: Centralized policy management across multiple AWS accounts for consistent security rule deployment
- **Q Developer Integration**: Uses MCP server for real-time AWS documentation access and CLI permissions for automated configuration

## Full Transcript

Hello everyone. Welcome. My name is Sid and I'm a principal solutions architect with been with AWS 11 years. And as we gather here at Rainforce, we are actually embarking upon. A new era. A new digital world which is fundamentally shaped by artificial intelligence. And in this era, we no longer just protect network security parameters. We have to secure the very conduits that connect our applications to these transforming AI technologies. This connection is more vital than ever, and it's of great importance. But before we dive into advanced network defense, let's take a step back and look at the fundamental pillars of network security. Our mission at the core aligns with CIA, and I don't mean international espionage. I mean confidentiality of integrity and availability. Now, in this session, we will be focusing primarily on confidentiality. But before we dive into that, I want to briefly mention what network integrity and availability means and the best practices there. Network availability. We need to make sure that the network is available when needed. So we need to stop traffic attacks that overwhelm our networks and make it unusable for genuine traffic. We can do that by throttling. Now throttling as a capability exists in many AWS services like API Gateway by default, or you can use AWSA web application firewall on your load balancers and cloud front. We also have DDoS protection through AWS shield distributed denial service of attack. Now it's also important that we take genuine traffic and optimally distribute it. That's where load balancing kicks in. Now we in in region load balancing we have application load balancer, network load balancer, gate load balancer. For global load balancing, we also have A global accelerator which can distribute traffic across regions. Now when we take a step back and go into the network layer, we also have BGP ECMP which can optimally distribute traffic across site to site BPN A Direct Connect. We also have GRE-based tunnels where you can load balance when you're setting up SD-WA peering. And finally, we also want to make sure that we have network redundancy. So if your network fails, then you have something to fail over to. That's where you want to use multiple AZ availability zones, and not just that, you want to maintain AZ level fault isolation so that a failure in one AZ does not impact all the other AZs, well, basically your application. And you can leverage zonal shift on load balancing to shift traffic from one AZ to another AZ within your applications. Now looking at our next pillar, network integrity, we want to make sure that our network remains accurate, complete, and unaltered. Now, there are 2 ways to achieve it. First is to ensure network traffic integrity. We do this by encryption in transit. So for client to server to server to server communication, we have TLS. Taking going one layer down, site to site connectivity, we have IPEC, which is IP security protocol for VPN and then on Direct Connect, we can leverage MacSec or Mac Security, which is even a layer down at layer 2. By default, we encrypt all traffic between supported instances in an AZ. You get that by default as long as you're using the supported instance types and as traffic leaves AWS secured facilities, we are also encrypting the traffic by default. So you get that out of the box. You can also leverage techniques like checksum, where you're inserting a checksum into your packet header, which is, which then gets verified on the receipt of the packet. Uh, an example of that is object integrity in S3. The next is network configuration integrating, making sure that your network configuration is unaltered. That's where access control is really key, making sure that you have the right IM permissions and restrict who can make changes into your network. You can also do configuration validation. We have AWS config change tracking network access analyzer, and BPC reachability analyzer which can help you with that. Uh, just yesterday we announced, uh, AWS Shield network security director which can look into your network, identify misconfiguration, and, uh, give you remediation options as well. Finally, you want to monitor and detect in case any configuration changes happen, which you were not expecting. Again, Aless conflict change tracking is a great way to do that, but you also have cloud trail logs and guard duty which also has network findings which can uh uh alert you on that. All right. Let's jump into confidentiality. Now there are two main pieces to confidentiality. Authentication and authorization. Now when we talk about network authentication. We need to focus on identity because you are authenticating an identity. In the secu in the network security realm, what's an identity? Well, the answer varies based on where you look on the TCP IP stack. Typically when we write firewall rules or we define identity, it's based on IP address. This host, this IP can talk to this IP. The, the packet is coming from that IP address. So IP like inherently is an identity of a network host. But then we also have other identities. MAC address is an identity which we typically don't use a lot. But then we also have ports and we have application level identity. Now how do we prove that identity? Let's focus on IP address and ports. Well If you look at how networking works. When a host comes online, it sends a broadcast packet to a DHCP server, asking, Hey, what's my identity? Give me an IP address. Now what people can, what attackers can do is spoof and run a DHCP server, a malicious one, and then give the host a wrong identity. Or there's also AP, Addres edition protocol when a host wants to send traffic to its next hub, it says, who, who is this IP? Give me your MAC address. And that can be spoofed as well. Not in AWS. So VPC is not a traditional network. It does not support broadcast. So how does it handle DHCPNR? Well, there's a mapping service, network mapping service, which basically absorbs all the requests. It's a big database, all verified, and then it sends a response back. So it does not work like a traditional network. So there's no way you can spoof IP addresses or Mac in a VPC, right? So that's how you prove identity. Now this is a screenshot of a session from 2013 where we talk about this. There have been subsequent sessions at Reinvent talking about this so you can go and have a look. There is a flag, ENI source destination check, where our hypervisor, our backend is actually checking the source and destination and verifying it with the mapping service and blocking traffic if that happens. You can disable this. We we enable this option because if you want to run routers or any, you know, networking services, you may want to disable it. So just keep keep that in mind. And finally we also have application level authorization at ALB and BPC latters. Now application level authorization is not technically a network identity, but then a lot of our networking services like ALB and VPC letters are understanding application level identities and using that to make authentication decisions. OK, so now we have authenticated our network, but how do we authorize it? How do we control access? How do we give permissions to our networks to talk to each other based on the identities? Multiple ways to do that. One is by creating network isolation and second is by traffic filtering using firewalls. Let's dive into these two and also we have application level authorization where you're using actually uh policies on an application layer through uh uh through services like VPC letters. But we'll focus on network isolation and firewalls today. So let's talk about network isolation. Here what we are saying is we will restrict access to entities, authenticated entities within isolated boundaries and within this isolated boundary, everyone's allowed to talk to each other. How do we do that? We can do it two ways. One is by creating routing boundaries, right? So we create a routing boundary and all hosts within the routing boundary can route traffic to each other. And the second is by creating private connectivity. So we'll create private connectivity between two hosts, and only those two hosts can talk to each other because they are connected by this private connectivity. How do you implement routing boundaries in AWS? Well, if you look at a VPC, that's inherently the most fundamental routing boundary. Everything in a VPC can talk to each other by default, right? But then in reality you have multiple VPCs and you want to and and they're different routing boundaries by default, but you want to connect them together so you bring in VPC pairing transit gateway, cloud van, single. route table and then you basically are enabling traffic flow from any to any in these BPCs, so you're creating a single routing boundary out of multiple VPCs. So the way to look at this will be you bundle BPCs into isolated routing boundaries or trust boundaries, and then you connect these routing boundaries by isolated routers. Traffic cannot flow across these routing boundaries. Traffic can only flow within the routing boundaries, right? How do you implement that in AWS with the help of AWS Cloud one. Now Ali Cloudvan is a service highly available globally distributed, which lets you create the segmented global networks. You start by creating a network policy. You define where you want your cloud van infrastructure to be deployed into which regions. Here we select 3 regions. When you do that, behind the scenes we create CNEs or core network edges which are regionally highly available, highly scalable end points. These CNEs are fully meshed with each other and exchange routes using EBGP. Next, we create segmentation, right? These isolated routing boundaries. Again, everything in cloud one happens through policy. So on the right you can see I'm defining the policy and then everything on the left is automatically implemented by the cloud one back in. So we create 3 segments production, development, and hybrid, and we say hybrid only can exist in two regions. Now by default within these segments everything can talk to everything, right? These are logically isolated routing boundaries, but you can enable a flag called isolate attachments through and when you do that, these routing boundaries become completely isolated so nothing in production can talk to each other and so for development and so for hybrid, right? So we're basically. Deleting the routing boundary and making everything isolated. So the next step here is to attach our networks to cloud one, and that's done through cloud one attachments. So we have VPC for VPC attachments, then we have GRE-based attachments for SD-WAN connectivity where we also support tunnel less connect where you don't really have to create tunnels anymore, so no more GRE tunnels if you want. We, you can also connect transit gateways to Alis Cloudan. You can connect direct connect natively now to Alis Cloud one as well. We we enable support for this at last reinvent. And also site to site IP site connectivity directly to cloud one. Now, once you have everything attached to the cloud van, you still cannot route between them and they are not associated with any routing boundaries or segments yet. That's where attachment policy comes in. So I write an attachment policy where I'm saying. Look at the tags of the attachments and then use that information to automatically associate them to the right routing segment. So once you do that, Tags are looked at and they're associated to the right segments. You can also add an additional human approval. For example, you can say for production, I don't want my attachments automatically associating to my production segment. I want to add a human approval in there and that's how this works. Now, when you do that, uh, dev can talk to dev, Prod can talk to prod. But you cannot cross segments because they're isolated. So production cannot talk development, hybrid cannot talk to production and development. That's where segment sharing comes in, so you can share routes between segments. And when you do that, then you can enable traffic flow between different segments as well. So we saw how you can use A cloud band to create these isolated routers and then connect different BPCs which belong to different trust boundaries or routing boundaries. To is isolated segments. Now coming back to our network isolation story, the next is private connectivity, right? Now, in the real world, in the physical world, you can take two hosts, connect them with an Ethernet cable, and that's private connectivity. So what does it look like in AWS? In AWS, it's powered by private link. Now Private link enables three kinds of connectivity. One is to AWS services. This is where you can, your clients or hosts in your BPCs can access AWS services. And here the traffic is only enabled to the AWS services for which you create the private link endpoints and nothing else. So no access to the internet or anything like that. The next is you can enable private connectivity from your clients in one VPC to a service provider VPC in other VPC. This is where you can deploy a load balancer and have your servers behind it, and the clients only get access to what's behind the network load balancer and they don't get access to the entire VPC, right? So you still have that isolation there. And finally we added support for BPC resources. Now we heard a lot from our customers saying this is great, but we want to share our database across BPCs and only give access to some hosts to my databases like Aurora clusters or RDS. You cannot put a network load balance in front of an Aurora cluster. So for that we added this resource configurations behind a resource gateway. So now you deploy a resource gateway and you can uh enable access to multiple resource configurations behind it. Resource configurations can be through uh Amazon RN, Amazon resource name like RDS or DNS names or IP addresses. On the client side, multiple BPC endpoints are created, one for each resource configuration, right? So on the server side, on the resource owner side it's just one resource gateway, but on the client side, the multiple VPC endpoints, one for each resource configuration. All right, so that was private connectivity. Now we're still talking about confidentiality and how we can authorize access. We just saw how you can create access boundaries by network isolation using routing boundaries or private connectivity. Now let's jump into our. Next section, which is traffic filtering using firewalls. Now, the concept is very clear. We want to use identities and write firewall rules saying this identity is allowed to talk to this identity, and this will be mainly through IP addresses, ports, DNS names, etc. Now, how do we approach traffic filtering in this world of isolated networks? Well, within an isolated network, you often want to restrict traffic between a particular server and maybe a database which it needs access to. In that case you would write traffic filtering rules based on IP and ports, but then when you cross this isolated boundaries, maybe this is crossing production environment into a non-production environment or between an application A to B, you want to do the packet inspection. So this is how you approach traffic filtering. So how you can do that in AWS is through various purpose-built services. So for layer 4 port and protocol based access control, you can use security groups and network ACLs. We also support DNS filtering for filtering, uh, traffic based on, uh, DNS rules. And then finally we have layer 7D packet inspection. You can use the application firewall, firewall, or just bring your own firewall using third party firewalls. We'll talk about all of this. And get a detail. Let's start by security groups and network ACLs. Now, network ACLs, I'm pretty sure you all know what that is, but it's something which is deployed on a subnet level. It's stateless and you define rules on what's allowed into your subnet and what's allowed outside out from your subnets. Versus security groups is something we should deploy on a host or an ENI and in this example we are writing outbound rules on the load balancer saying it's only allowed to send traffic to the web server and the web server is only allowed to receive traffic from the firewall and you can see here we are using security group referencing to do that as we write the rules. Now security groups obviously are stateful firewalls, and you can associate a security group with multiple BPCs in the same account and in the same ELS region. Now jumping into DNS firewall. Now DNS firewall is for blocking DNS queries to malicious domains. You can write deny lists or allow lists. We provide out of the box manage rules, which you can get started with. Now DNS firewall is enabled on on a per VPC basis, so you enable DNS firewall on a VPC, but then you get centralized management through AWS Firewall Manager. And finally, we also have an additional tier called DNS Firewall Advanced which lets you enable uh query blocking for advanced DNS threads like DNS tunneling. All right, so let's jump into the next category, which is deep packet inspection, and we have 3 options here. First is web application firewall. Now web application firewall, as the name suggests, is for protecting your web applications. It's a fully managed service and it's deployed where your application sits. So if you're using a load balancer like ALB, you can enable VA on that. If you're using API Gateway, AppSync, Cognito, Verified Access, cloud front, you just enable VAF and deploy the web application firewall as part of those managed services. Now let's talk about network firewall and third party appliances. Now both of these can be used in a similar manner for DPA inspection, and we'll talk about how all of these fit in a network from a network flow standpoint. But how do you make a decision on which one to use, especially if you're getting started? Now a firewall is a fully managed deep inspection firewall, provides you with IPS web filtering. And it can also inspect encrypted traffic. Now it's a managed service, right? So you don't have to worry about managing it, patching it, even scaling it, or have the high availability of it. Everything's managed by AWS. We also give you centralized management and visibility through AWS firewall Manager, and we also have a bunch of partner integration which I'll talk about in a bit. Now G Road Balancer allows you to bring your own firewall appliances and connect them in a highly available and redundant manner. Now, this is great where if you're already using something on prem or somewhere else, you can use the same technology in AWS. Of course, this is, this will be self-managed, so you will have to manage those firewalls, the licensing associated with it, the patching, etc. And when we talk about partner support, firewall has multiple integrations. For example, you can use CloudStrike for your host protection. It can detect domain-based indicators of compromise, let that, uh, delay the information network firewall, which can then start blocking it centrally. Or you can have uh Uh checkpoint centrally audited and manage your firewall rules in network firewall. Um, and on the right, when you're looking at Galr, these are the different vendors or partners, uh, rather, who, uh, can integrate directly with Giro Balancer and support it out of the box. All right, now we have looked at all the different options which we have for traffic filtering. But you might be thinking I'm, I'm deploying security groups in one BPC. I'm I have a BBC firewall somewhere else. I have DNS firewalls. I have like so many firewall products. How do I manage them? Well, Airbus firewall manager is the answer, which can help you centrally configure and manage firewall policies. It can help you deploy your firewall roles across multiple Airbus accounts. Uh, a common strategy which I see is with the application firewall where a lot of our customers, a lot of our customers have centralized security teams, uh, which mandate a certain set of firewall rules, and those can be deployed across the organization. And in addition to that individual application owners can deploy their own firewall rules so it's like a distributed plus a centralized approach. All right, so now we have seen a different. Options you have, but how do they fit from a network inspection flow standpoint. So let's talk about different traffic flows. Let's start by internet egress. Internet egress is where you have hosts in your VPC which needs access to something sitting on the Internet. Uh, an example would be let's say you have an EC2 instance and it, it wants to update its, uh, Python package or it wants to, uh, download some patches. It'll do it through an ad gateway because you don't want to expose your LEC to instances directly to the internet, so it sits behind the N gateway and you would deploy an Airbus network firewall in the in the data path. So the traffic hits Airbus network firewall, gets inspected, gets sent to that gateway, and then out through the internet gateway, and the return traffic flows the exact same path back. Now it's decentralized, which means for every VPC you need to repeat the same architecture. So every VPC has a gateway, every PPC has a network firewall. Right, so you're deploying a network firewall in each and every VPC. Now, the good news is we do net gateway offset. So if you have a NAD gateway sitting next to a network firewall in a traffic path, we will not charge you for the NAD gateway hourly cost or the data data processing cost, right? So you get that free. And even though you might have hundreds of BPCs and you deploy hundreds of firewalls, as I just mentioned, Airbus network Airbus firewall manager can help you with that centralized policy management. Now, if you were to use gate balancer with your own third-party firewalls. The Network design looks very similar. The only difference is that you will still deploy your firewall appliances centrally in an inspection VPC behind a G load balancer, and then you will deployable load balancer end points. In each and every BPC right? So lower cost because you're not deploying your firewall appliances in each and every VPC, so you know, you don't have to wait for hundreds of licenses for hundreds of VPCs. But there is non gateway offset, so you just need to keep that in mind, uh, but you still get centralized policy management because your firewall appliances are sitting in a central location. OK, so the next is how do we convert that decentralized internet egress to centralized Internet egress? Well, you can do that by bringing an Airbus cloud one. So the idea here is that your application VPCs can send traffic to Airbus cloud van, which gets routed via the centralized inspection VPC out to the internet. This is great. The only thing is You are introducing Airbus cloudan which has its own data processing charge, so you need to keep that in mind. But you get reduced ANF hourly cost. So if you have hundreds of VPCs, you don't have to deploy hundreds of Airbus network firewall. You're just deploying it once in a centralized inspection VPC. So you're paying only for a single instance of Airbus firewall. So you, you save costs there. The next traffic inspection flow is east to west, VPC to BBC inspection. So here the traffic is not destined to the internet, but rather to another VPC. So your, uh, you know, your, your source is uh VPC and your destination is VPC, and the traffic follows a very similar path where it is centrally routed to a network firewall end point which inspects traffic and sends to the destination VPC. Now in this scenario, there's an important thing to keep in mind. What happens when there's cross AZ traffic flow. So the scenario here is that traffic originates in AZ1. And It's destined to see to instance an AZ 4. Right, so requests from EC21 to EC24. Now Cloudan by default tries to keep traffic local to an AZ. So if cloudan gets traffic from AZ1, it's gonna take it and it's gonna send it to its ENI to its end point in AZ1. That's exactly what it does. Now, when the return traffic comes, let's see what happens. Now the return traffic comes from AZ 4. Cloud one applies the same logic. I want to keep the traffic local to an AZ. I want to save cost better latency, but so it sends the return traffic to AZ2. Right, so it goes to a different power endpoint. Now, for straightful firewalls, they're going to they are going to drop this traffic, right, because uh the the request came to one endpoint, the response to another endpoint. And as long as those endpoints are not sharing state, which they don't. Um, this is gonna get dropped. So what you can do is you can enable appliance mode, which maintains the A symmetry. So you have, uh, enable that on this attachment and then when the traffic. The response traffic comes back. Cloudan is going to store state a flow hash, and it knows that this the request for this traffic was sent to AZ one, so it will send the traffic to the same AZ, right? So this is really important as you're doing VPCVPC inspection and you want to enable appliance mode. All right, so the next traffic flow is North-South hybrid, um, so no longer from a VPC to a VPC now it's from VPC to on-prem or on prem to VPC, right? Um, again, the, the overall flow is similar. It gets routed via the centralized inspection VPC where you have the firewall endpoint to inspect it. All right, our final traffic flow here is internet ingress. And let's talk about the decentralized mode. Now, this is where you have web web facing applications where uh hosts or uh like clients on the internet needs to access them. In the decentralized model you will deploy your application in different VPCs and then you will just enable protection on the resources like VAF gets enabled on your application balancers and if you have no STTP traffic, then you would deploy a network firewall. In your VPC, every VPC which has this requirement, there will be a firewall in there. Um, also, if you're using, uh, Amazon cloud front, we added support for private VPC origins, which means you can keep your VPCs completely private and expose them via Amazon Cloud front, right? So this, uh, is, is really cool because, uh, prior to that you had to, uh, you know, have your ALBs or NLBs or whatever public for it to be, uh, you know, as added as the origin for cloud front. And of course you get centralized policy management using network firewall. I keep reiterating this because a lot of times customers are like, hey, this is all decentralized. I have like 100 VPCs I cannot manage it. You can manage it using network firewall pretty easily. Um, but there's another model which is centralized internet egress what where I've seen customers trying to centralize their ingress traffic as well. Um, so one instance of network firewall, one instance of VA, and then route traffic to the application VPCs, well, this doesn't really work very well. Because in order to do this, you have to put a proxy layer which has to intercept all the traffic ingress traffic, and then route it back to your application hosts uh to your applications. Now you can do this by putting a load balancer in a proxy layer and then adding other load balancer as a target, and there are multiple ways of doing it, but I, I don't recommend it. Because if you have like multiple applications, one proxy layer for all the applications is just, it's just a mess. This is not easy. So I typically, I generally don't recommend this for most use cases. All right, so let's combine all the flows, right? So you have a distributed internet ingress, traffic coming from the internet. You have North-South hybrid where traffic is from a BPC to on-prem on to BPC. We have EastWest VPC to VPC inspection where remember I mentioned you need to enable appliance mode and then we have the Internet egress where the traffic originates uh within your uh VPC is destined for a destination in the Internet, right? And you can see how you can have a centralized uh inspection VPC which can cater for all the flows so you don't really need to create multiple firewalls, multiple VPCs, etc. Uh, of course, except the distributor internet ingress, which I still recommend it to be distributed and use a web application firewall where you can. Let's talk about bandwidth, uh, because when we are combining all the flows and I'm saying, hey, just use one firewall endpoint, you must be thinking, uh, but is it highly available? What is it a single point of failure? Is it a single choke point, very valid concerns. So when you connect cloud van to a centralized inspection VPC and you deploy firewall endpoints in there. Cloudan to VPC attachment gives you 100 gigabits per second per VPC attachment per availability zone. So here we have cloud van ENI in 2 AZs, so you get 200 gigabits for this attachment. And on the firewall side you get up to 100 gigabits per second. Per AWS network fi endpoint or gate broadbandr endpoint. Here we have 2 power and points, so you get 200 gigabits per second. All right, so how do we scale this? Like 200 gigabytes, not enough. Well, you can add another AZ and another firewall endpoint. So now you have 3 AZs, 300 gigabytes for the cloud band to VPC attachment, and then you get 3 firewall endpoints, so you get up to 300 gigabytes per second, right? So, uh, you, you can see how, how the scales, uh, it's it's pretty redundant, very highly available, and pretty scalable. Obviously, um, you know, as you're adding additional attachments, firewall endpoints, especially if you have, uh, your own gate floor balancer with third party firewalls, keep the cost and licenses in mind. All right, so we So the different traffic inspection flows and how you, uh, uh, and how you can use that with a centralized inspection VPC. I want to talk about how you implement this risk cloud. Now AWS cloudan makes this really simple through a feature called Service insertion. You can single click insert AWS network firewall or third party services using just network policies. When we're talking about cloud one previously, I showed you how you write network policies and that automatically configures your global network. It's the same thing. To do this, we create a network function group. Now a network function group is very similar to a segment which we saw previously, like a production segment, non-production segment. But Net network function Group is a segment which is dedicated for hosting your inspection, VPCs and firewall appliances. This is fully managed, but you still get full visibility into the route routing behind it. And I'm gonna show you exactly how you configure the policies and what kind of routing happens behind the scenes. So here is our Sample setup, which has two segments, production and development. I have 2 BPCs in each region. One is broad, one is deaf. And I'm showing you the route table of CNE one, right? That's the regional route table in region one. It says VPC, de VPC1, and this is the dev route table. So each CNE will have its dev route table and a broad route table for each segment. Every segment has its own route table and every CNE has its own localized version of the route table. So CNE1 regional dev route table says dev BPC1 is directly attached, while dev BPC2 is 1 hop away via CNE2, right, very straightforward. And then CNE2 has a similar route table saying dev BPC2 is directly attached, but de BPC 1 is 1 hop away via CNE1 because it's cross region. Awesome. Now in now my goal here is to inspect traffic between production and development, right? As I said, if you're crossing trust boundaries, then you want to do the packet inspection, and that's that's the logic I'm applying here. So I'm, I'm routing traffic between production and development, and I want to inspect it. So I create a network function group, and I attach my inspection VPCs to cloudan and associated with the network function group. Next, I need to write a policy which tells cloud when inspect traffic between prod and dev. So this is how the policy goes, any traffic exiting segment development send to network function group one. Uh, now just a correction, um, in this I'm actually writing a policy to inspect Internet egress traffic, not the VPC to VPC inspection, not cross segment inspection. Uh, this is more for the Internet egress traffic flow which I, which I talked about. So traffic originating inside your VPC and it wants to download some Python packages or some patches, etc. from some host on the internet. So here I'm writing a policy saying any traffic exiting segment development send to network function group one, and this is how my policy looks segment development. Send to Via network function groups network function group one, I think it's very intuitive, very straightforward. So what when I do that, what cloudan does behind the scenes is it inserts a default route saying 0000 next top inspection VPC. And it populates network function group with all the deb BPC routes. So let's see an example. So the traffic originates in a deb BPC and is destined to the web. It goes to the development segment. The development segment route table says, OK, this is to the web, so it hits the default route and it's sent to VPC inspection one. The return traffic comes back, uh, the, the traffic goes to the internet. The return traffic comes back to the network function group. Net network function group is populated with all the de BPC routes, so it knows how to route the traffic back and the route and the traffic goes back, right? So everything works great. Now you must be thinking, I write all of these policies and all of that just for a default route to be added. I mean, I can just go and add a default route myself, which is fair. So let's talk about another scenario where you'll see this really is how powerful this uh policy writing can be. So I bring in a new region which is very common like uh customers like yourselves are expanding and launching new regions but as you do that you don't want to replicate your firewall infrastructure in this new region just yet because you just have, you know, very limited infrastructure in there you don't want to bear the cost of additional licenses or whatever it might be. But you still want to inspect traffic. So now the dev round table in region 2 says. WPC 2 directly attached. But to reach the other two BPCs I need to go by CN1 right now. I write the same policy. I say any traffic exiting development sent to network function group and the same automation applies, but now this region has two options, uh, the, the dev route table. It can either send traffic via Region 1, US East one, or it can send traffic via Region 3, which is US West 2. Right? So which region do you think it will send? It's sending traffic from US West to one. It makes sense that it should send traffic to US West too. That's the most that's the nearest region, lower latency, but that's. Not always the case. Right. It can actually choose US East one to send the traffic as well, because the, the traffic selection is based on a predetermined algorithm and you need to verify and make sure that it meets your requirements. Now, if you don't want that, you can actually add an edge over ride stool. Where you can say, for US West one. We always use edge location US West too, right? So you're deterministically adding in the policy how you want the traffic to be routed and this is like really powerful because if you were to implement this yourself using some static routes, it's very difficult. So here we're writing a policy saying for development egress traffic in US West one always use US West to inspection VPC. All right, see you again See something happens there. I have some of the regions, um, misspelled in in the in the slide, but do you get the point? Um, let's talk about another scenario. Here we write a policy, same policy, but for the production segment. But instead of the traffic being sent to the web, I want, what if I send the traffic to my development segment? Let's see what happens. So I send the traffic to my production segment. The production segment has a default route, which gets matched. And the traffic is sent to the inspection BPC. The inspection VPC routes the traffic back to Group. And the FO function group basically drops the traffic. Why? Because the function group does not have any other dev routes. It only has broad routes as per our cloud and automation in the in the slide. But what if I add another policy for the development and now the function group has the dev routes as well. So if I have the same packet, now it gets. Routed Back to NetA function group, and now the NFA function group has the dev as well as the prod routes, so it sends the traffic back, right? So the summary here is if you write the send to policy for two segments, you can enable traffic flow between them. Now If you're trying to do that across regions. There can be a problem. Let's look at that example. Let's, let's finish this, uh, traffic flow, so the return traffic also flows back. And then now you have the production and development talking to each other. So if you look at the same scenario but a cross region routing. The traffic originates from rod. It's destined to the dev segment. Default route matches, it sends to the inspection VPC comes back, and it sends to the development segment. Now the return traffic comes back to development segment, matches the default route. It's sent to its inspection VPC. And then the return traffic gets sent back. Now you saw what happened. The request went to one inspection VPC and the response went to a different inspection VPC. Now any Stateful firewall is gonna block that. Now if that's what you wanted, great. But if you really wanted to inspect traffic between, um, dev and prod and you wanted to do it with symmetry so that stateful firewalls don't block the traffic. Then you can set up a different kind of a policy. Where you can say broad segment when sent to development, send via network function group. That's it. It's that's that simple. So the previous one was sent to, and this is send wire, right? So that's that's sort of the main, main difference there. And obviously in here you're specifying the two segments between which you want the uh the inspection to happen. Uh, for cross region symmetry we have two options single hop and dual hop. A single hop is default, where traffic will be inspected by one inspection VPC, both the response and request, and in dual hop, the request and response will be inspected by both the inspection VPCs. So this is how the policy looks. Here I'm looking at the example of dual hop. So you can see Um, I'm writing the policy saying production when center development send via network function group with the more dual hop again, quite straightforward, quite simple. Uh, let's look at our, uh, broad route table in in region one and dev route table in region 2 because I'm doing prod to dev routings. I wanna show you exactly how, uh, these routes are populated. So when I write this policy, cloud when automation kicks in. And what it does is for development and broad route tables. It says cross segment routes. Next top is in region inspection VPC, right? So you can see the routes are getting populated in the production route table for my dev. VPC's next stop is VPC inspection one. In the same region, and then you can see in CNE2 de route table the same thing for my production VPC's Next up is VPC Inspect 1, which is the inspection VPC in the same region. But the network function group says cross region routes next stop is cross region inspection VPC. So let's see why this makes sense. So, traffic originates in the production VPC. The destination is a dev VPC in a different region. Traffic comes to production, it, uh, it says, OK, this is Dev, so send it to in region inspection VPC. The traffic comes to a function group. It says, oh, it's a cross region route. So the next stop is a cross region inspection VPC, right? So this is how the traffic gets sent to the inspection VPC in a different region. And then the return traffic comes in. It gets sent It gets sent to uh development to the inspection VPC to the function group which says, OK, it's a cross region route so it goes to cross region inspection VPC. So they see now this is how the traffic gets inspected in both the regions by both the inspection VPCs, both the request and response. Um, now, all of these routes, uh, is automatically populated by cloud one. You, you, you don't have to write any routes. You just have to write this policy, right? So that's, uh, that's really powerful. So the next is the single hop. Now, when you change the mode from dual hop to single hop, the automation behind the scenes changes. So now the automation says. In the prod and depth segment, local region, cross segment route, send it to local inspection VPC. Right. So that gets populated in both the routes. But cross region, cross segment routes. Send it to a chosen inspection VPC. So what cloudan does is for symmetry, it chooses one inspection VPC and says, OK, this is going to be the single hop inspection VPC. Right now, again, it makes that decision based on a period in mind rule. Uh, it's, it's well documented in our documentation. I'm not going to go into those details today. But there's one inspection VPC which gets chosen. And you can see uh I have chosen my inspection VPC here. And those rough gets populated as well. And NFG basically learns all the dev and VPC routes, dev and production VPC routes, nothing special there. So let's see how the traffic flow happens. Now traffic originates in Deb BPC distant to prod in a remote region. It comes to development. It says, OK, this is a cross region cross segment route, so routed to the inspection, chosen inspection VPC. So instead of sending traffic to the in region inspection VPC, it sends it to the chosen inspection VPC in a different region. Now the return traffic comes to production. Right? That again gets sent to the chosen inspection VPC. And that gets routed back, so this is how Single hop cross region symmetry is done. Now, if you don't like what Cloudan chooses as the chosen inspection VPC. You can override that. So if we have an edge overrides feature we can say. Between two regions here it's called ESETS, US East one and US West 2. Use edge location US West 2, so I'm forcing Cloudan to choose US West 2 as my inspection VPC destination when routing between these two regions. By default, Cloud one actually chooses US Eastone because that's the highest priority. Um, so here you can force it to choose US West, so we have a lot of control, right? So again, as I mentioned, the policies, the only thing which you write, um, everything else, all the all the automation which I'm talking about, all the routing I'm talking about is just for your, um, for your visibility into on what's going on behind the scenes, uh, but, but you know you don't have to care about that. Uh, you just have to write these policies. It's a really powerful, uh, way of configuring your, your global service insertion architectures. And then as you can see with this edge overrides, US West to becomes the inspection VPC. And the routes changes and then that's reflected in the in the traffic flow here where you can see now the traffic starts routing via this inspection VPC for both request and response. And then you can see the region in one inspection VP say is all sad, has nothing to do. OK. Now, uh, many of you might be, that's great, but I, I'm still like finding these policies a bit difficult to write and like send to send via whatnot. Well, the good news is we are in the world of, um, agenttic AI so I'm gonna show I have a I have a demo here on how you can use Amazon Q developer to actually configure your cloud ones, uh, policy creation and service insertion. Um, how many of you have, uh, have heard the word uh by coding? Show of hands, yeah, a lot of you, right? So what I did here was I, I'm by coding and creating cloud one configuration um on the fly. Um, again, what I'm gonna show you here, I recommend for your development and sandbox accounts just to get started and configure cloud one, but as you're doing it in production environments, I don't by code, uh, you know, maybe just use cloud formation templates which you generate out of, uh, out of this bytecoding. So, so let's look at this. So I open my command line and I go uh type Q chat. This brings up my Q do per CLI. I use slash model to change my model to cloud for Sonic, and I put a prompt saying using send profile, analyze my account. And provide me a comprehensive overview of my cloud one configuration. What Q developer does, it starts making a bunch of CLI calls, describes global networks, list core networks, as you can see, I'm gonna speed this up, get core network policy list attachments. A bunch of like it implemented like almost 10 CLI commands and it generated all the information and you can see it gives me a summary. I have 2 production uh two segments, production dev. I have attachment policy configuration using tags. Uh, I have, uh, 15 attachments. You can see I have 9 VPC attachments for production development. I have inspection VPCs that I attached but not associated yet. I also have, uh, a bunch of transit gateway attachments. It also gives me strength and observations and also give me a summary. So my next prompt here. Implement service insertion for traffic inspection. 1, research area-based documentation. 2, summarize the key concepts and give me a plan. And 3, provide a step by step implementation plan. Include any necessary cloud formation templates. So what it does is it first goes and reads the documentation. You can see it requests permission here. I give it yes and you can see it's going. And extracting a bunch of documentation. From there, it tells me, OK, now I've understood the key concepts of service insertion. I've done the current environment analysis, #3. I am going to look at the implementation requirements, and number 4, it's building a step by step implementation plan so you can see, uh, step 4B is tag VPC attachment so it's tagging going into my account and tagging the VPC attachments so that it can automatically associate them with the group. Step 4C it's creating a new network policy so you can see a network policy has been created and it's writing it to my local desk. And then step 4D is it's going to create and deploy the new policy version. Well, you can see it makes an error. It goes and creates a command that says create core network policy version. It reads the error. It says, oh, I need to fix this. I'm using incorrect command, and then it executes it's a correct command but now it's putting a core network policy. So it's it's really nice where it makes mistakes and then corrects itself. It's really cool to see. And now it's executing the core network chain set where it's executing the policy. So it says the policy executing. Let me check so it can so it's now doing some verifications. The policy is live. So you can see here the policy is still executing. This is normal. It takes a couple of minutes. Let me create a cloud formation template for future deployments and provide an implementation summary, right? So now it's going to go ahead. And take all of that and build a cloud formation template for me so I can use it for the actual production deployments. It's also creating a test and validation script here so I can validate that everything is working so you can see the validation script has been created, um, it's making the validation script executable. So now it has uh it it has completed the entire process. It's giving me a summary. It's giving me what the key concept summary are, uh, the configuration changes it made, uh, it added tags to 3 inspection attachments. It updated the core network policy. This is the policy you can see it added send via clauses for production to, uh, development, single hop traffic inspection. I didn't ask it to do a single hop. That's what it chose. Um, then it created a cloud formation template, validation templates. Um, it's also giving me testing and validation strategies, uh, with different phases, connectivity testing, traffic analysis, uh, best practices implementation. It it's giving me next steps. And then it finally gives me inclination to say as complete. Um, Obviously I sped this up because I wanted to, you know, not have you wait and see each and everything it's doing, so it was really fast. Um, the demo was around 44 minutes or so. The actual implementation took me around 11 to 12 minutes. So in 11 to 12 minutes, it basically looked into my account, identified my cloud one configuration, what attachments I had, my policy, my segments. And then it created a plan to implement service insertion, attached the VPCs, did everything, followed the best practices, gave me a validation script, confirmation script, and I did validate a lot of this, and it was all correct, right? Um, the only thing I'll tell you is, as you start doing this, it was a very important thing where I asked you to read the AWS documentation. So I, I was actually using an MCP server, AWS Labs documentation MCP server, which lets uh, uh, AQ developer go and read Airbus documentation. Um, I, I didn't want it to rely on its memory. I don't know when it was trained, whether it knows all the latest and greatest. So by reading the documentation in real time, it was getting all the best practices, all the policy examples, etc. and then using it, uh, to do a bunch of this. Uh, here I also Queer also has CL full CLI access into my account, so that's already preconfigured. Uh, but once you have some of these tools and these uh CRI access configured, you can really dig into your account and, you know, really help you make a lot of this work. Uh, so this is the future. So I thought I'll give you an example of how powerful uh Q developer and AI can be helping you, uh, configure networks, uh, on the fly. All right, so, uh, you know, in the grand scheme of things, uh, we were talking about confidentiality and this sort of wraps up the traffic filtering using firewall section. Uh, this brings us to the end of our session. Uh, just to recap, we, uh, you know, started talking about the AWS, uh, network security pillars which were mapped to the CIA triad confidentiality, integrity, availability. Uh, this is how you can get a comprehensive picture of network security for your accounts. Obviously we focused a lot on confidentiality on how you measure identity and enable authentication. And uh authorization, but you know as you go back, start digging a little deeper into making sure that you also have integrity and availability uh figure out well, um, and that's how you can build uh a complete defense uh for your networks end to end. All right, thank you so much and please fill the session survey that really helps us, uh, enhance our content for next year. Thank you.
