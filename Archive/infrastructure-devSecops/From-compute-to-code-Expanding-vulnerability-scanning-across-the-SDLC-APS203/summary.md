# AWS re:Inforce 2025 -From compute to code: Expanding vulnerability scanning across the SDLC (APS203)

**Video Link:** [Watch on YouTube](https://www.youtube.com/watch?v=2SSWyuWivIs)

## Video Information
- **Author:** Unknown
- **Duration:** 48.0 minutes
- **Word Count:** 7,324 words
- **Publish Date:** None
- **Video ID:** 2SSWyuWivIs

## Summary
This session introduces **Amazon Inspector Code Security**, a new capability that extends vulnerability scanning to the source code and developer workflow. It emphasizes shifting security "left" in the software development lifecycle—starting at the code, infrastructure as code (IaC), and dependency level—to detect risks early and reduce remediation cost. The presenters walk through how Inspector now supports scanning GitHub and GitLab repositories for third-party and proprietary vulnerabilities, integrates seamlessly into developer workflows via pull requests and IDEs, and enhances visibility for security teams across the full SDLC—from code to cloud. A live demo showcases real-time findings, risk scoring, and automated code remediation suggestions.

## Key Points
- **Iceberg Metaphor**: Surface issues are visible in production, but most risks lie hidden in code, dependencies, and configuration.
- **Amazon Inspector Evolution**:
  - Started with EC2 scanning (2021)
  - Added ECR, Lambda, and deep inspection (OS + app-level packages)
  - Hybrid scanning introduced for non-SSM managed instances
  - CICD integrations via GitHub Actions, Jenkins, TeamCity
- **Code Security Capabilities Introduced**:
  - **SCA (Software Composition Analysis)** for third-party package vulnerabilities
  - **SAST (Static Application Security Testing)** for proprietary code flaws like hardcoded secrets
  - **IaC Scanning** to detect misconfigurations in Terraform, CloudFormation, CDK
- **Risk Scoring**:
  - Uses over 50 data feeds
  - Considers exploitability, internet exposure, and attack intelligence
  - Ties into Inspector’s composite risk score
- **Security Shift Left**:
  - Catch issues during planning, design, and development—before reaching production
  - Fixes earlier = cheaper and more efficient
- **Developer-Friendly Integration**:
  - GitHub/GitLab two-way integration
  - Findings surfaced in pull requests
  - Automated remediation suggestions with code snippets
- **Security and Developer Harmony**:
  - Empower devs with security guardrails, not gates
  - Security teams gain repository-wide visibility
  - Alerting via EventBridge, integration into existing workflows
- **Live Demo Highlights**:
  - Default and custom scan policies per repo
  - Scans triggered by commits, PRs, or schedules
  - Findings include exact file, line, vulnerability type, and fix suggestions

## Technical Details
- **Inspector Code Security Components**:
  - **SCA**: Identifies outdated/vulnerable libraries in source repos
  - **SAST**: Detects logic bugs, injection flaws, hardcoded credentials
  - **IaC Scan**: Flags misconfigured AWS resources in code
- **Platform Support**:
  - GitHub and GitLab source control integrations
  - IDE and pull request feedback loop
- **Scanning Triggers**:
  - Manual (on-demand)
  - Scheduled (e.g., weekly, monthly)
  - Event-based (push to main, pull request opened)
- **Output Channels**:
  - Amazon Inspector console
  - Amazon EventBridge for automation/alerts
  - Amazon Security Hub aggregation
- **Languages and Templates Supported**:
  - Multiple IaC formats (Terraform, CDK, CloudFormation)
  - Application code (Python, JavaScript, etc.)
  - Dependency scanners for common package ecosystems (npm, pip, etc.)
- **Compliance Frameworks Supported**:
  - NIST CSF
  - PCI DSS
  - CIS Benchmarks
- **Free Trial**: 15-day Amazon Inspector trial available for users to test Code Security in their environments

## Full Transcript

OK, welcome, this is APS 203. So I'm gonna start with the iceberg analogy, right? I love using this iceberg analogy for lots of different things. It's a really, really powerful metaphor, a great metaphor for not being able to easily see the bigger picture or not being able to see the things that remain hidden until too late. So we're gonna talk about it today in the context of vulnerability management. So the tip, everything above the uh the the water line, that is what we see running in production. Those are our servers, those are the things that are customer facing, those are our running workloads, and beneath the surface, that's where the real challenge is. That is everything that makes up the applications that run, makes up the servers, makes up the infrastructure, it's our code repositories. It's the dependencies that our developers are using every day. It's a number of rapid changes that are going through our release cycles that have to happen in order to be able to see the the tip of the iceberg. But also within that, those are the hidden risks that we often have and or we often miss until they become major problems. So think about this, and this may be familiar to you, right, it's Monday morning. You, your development team is just about to push a major update. The business is super excited, it's something that's been in the works for a number of weeks, your customers are waiting for it and you're just about to hit that big red deploy button into production. But all of a sudden, you get a notification about a critical vulnerability. And you have a decision to make. Do you delay? Do you push that big that big go button into production, do you accept the risk and figure it out later? And that's the constant tug of war that the business and security are constantly going through. Right, the business wants the development teams to speed up, they want to be agile, they want to allow for innovation, and the security teams are there to protect the organization from undue risk and from undue exposure. They're trying to help the development teams do the right thing, but there's there's always kind of that friction. And really what we want to be able to do is we want to be able to allow our developers some freedom, allow them to do the right things, but do it in the easy way, we want to empower our developers and we wanna give security teams the visibility that they need to make the right decisions and to help the business move fast and to stay agile. So I'm Danny, I'm a senior security specialist with AW Industries. What I do on a day to day basis is work with our customers, figure out what their problems are, what their blockers are, but also take their feedback, and we'll talk a little bit more about what that looks like on a regular basis a little bit later. And I'm joined here today with Norai. I'm going to introduce yourself. Norali Desai. I'm the product manager here for Amazon Inspector. And I am actually responsible for making sure that we build what our customers need in order to maintain their security of the environments. We'll actually between Danny and I will actually take you on how do you expand your vulnerability scanning across your software development life cycle all the way from compute to cloud. Quick thing about Amazon Inspector before we get into the details, it is one of the security services with AWS or Amazon. We are an automated vulnerability management service that continuously scans your workloads on AWS for software vulnerabilities and any unintended network exposure. We actually continuously scan all the resources that you may have such as EC2 instances, the images stored in ECR, elastic container registries, or your lambda functions, and clearly we are here to talk about what's new. Let's do the journey so far just so that we can anchor ourselves on what's been happening with Inspector at scale. When we launched in 2021, we started our journey with protecting all your EC2 instances that needs continuous monitoring and management for vulnerability detection. We added the images to be scanned to detect these vulnerabilities in ECR as well. After that in 22, we actually expanded the coverage by protecting the lambda functions as and when they are detected, you can go ahead and scan for third party repositories uh third party dependencies and understand where the vulnerabilities lie. We realize that just third party software is not enough for your lambda functions we expanded to go deeper to add scanning the first party code. That you're running on your functions as well. In addition to that, for your Linux-based EC2 instances, we went deeper by introducing deep inspection. What that means is so far we were looking at operating system level packages to detect vulnerabilities. With deep inspection on your Linux based EC2 instances, we also added. Application programming level packages and understanding the vulnerabilities associated with that. Deep inspection actually is enabled by default on all the new accounts that you may have starting 2023. In addition to that, So far for EC2 we were leveraging SSM agents that were managed by systems manager. We were leveraging SSM to extract the metadata, map it to our vulnerability database, and then generate findings based on your environment. We learned that not all instances can be managed by SSM or you may be in the process of actually migrating into AWS to have SSM installed so we introduced a hybrid scan capability which is again turned on by default and is recommended. What does that do is wherever possible if SSM is installed, we will go ahead and scan your instances using that and we're not deployed, we will just go ahead and scan fall back to agent less scanning. The deep inspection capability is available on both of them, and you'll be able to generate findings across the board. Clearly that was not enough. We needed to start early. We heard from our customers that they needed an ability to actually scan these images in their build before they hit production, before they actually pushed into ECR. So we actually deployed plug-ins and made them available in the third party marketplace, such as GitHub Actions, Jenkins, Team City pipelines, so and so forth for your developers and you to use in your build pipeline scan. And generate findings, understand what the vulnerabilities lie. All of this actually comes together to generate. And understanding of how vulnerable your instances are. Through a vulnerability database that is managed and maintained by Amazon Inspector. We have Mitter attack TDPSIA's known exploit databases. We also have our intelligence, internal aid of US intelligence, security research, security best practices, all of that combined with 50+ feeds, vendor feeds, CBE feeds, etc. combined that actually powers the vulnerability database to generate. And composite inspector risk score that's not just a CBE score but a composite inspector risk score that tells you how critical that vulnerability is tying that with network reachability for EC2 instances, let's say we verify if your instance is vulnerable, is it even reachable from the Internet? Has there been an active exploit? Outside in the world, is it exploitable and all of that puts together as an inspector's score. We'll continuously discover as and when new instances are brought up your EC2 instances, new images are pushed or lambda functions are initiated and would also scan when a new vulnerability is detected in our database that may impact your specific resource to generate a finding automatically without you taking action. These findings certainly can be consumed on Amazon Inspector for you or you could send it out to Security hub for further processing where you ingest all other findings or event bridge and other northbound connections for you to automate your work flows. Let's look at the top use cases. We'll quickly discover these zero day vulnerabilities without any action driven by you for all the compute workloads. Therefore, providing you the vulnerability information in real time without any manual overload. Prioritizing your patromediation. Now imagine if you actually just had the CDE database giving you. The severity level, you don't know if this is exploitable. You don't know if it's actually reachable. How do you prioritize all these findings? So the way we actually compute this with 50+ vulnerability feeds, mapping that to the heuristics that we use to verify whether these are reachable or not over the internet, mapping that to exploitability kits, malware exploit kits available for these vulnerabilities. Improves or adjust the risk scores for these vulnerabilities, allowing you to prioritize the patch remediation for these vulnerabilities. Our customers have evolving compliance requirements as they are expanding globally into various different geographies or various different industry verticals. And the compliance needs are changing. We offer them an ability to actually meet the audit and compliance requirements as well, things such as cybersecurity frameworks, with NS CSF standards like PCI DSS, the CIS benchmarks, all of these assessments are available through inspector scans. And last but not least, our customers use us today to actually shift left earlier in the development life cycle. They embed the scan vulnerability scanning that is available or export the S-bomb, which is a software bill of material. It's no different than a nested tree of what the dependencies look like for all my resources for their monitored purposes. Having said that, it's not enough, so let's hear from Danny what else is our customer telling us. So this is the favorite part of the best part of my day, right? We talk a lot about working backwards. If you were at the keynote on Tuesday, Amy spoke about customer obsession, right, and this kind of really is a theme that is so prominent throughout my day job as as a solutions architect with customers that it's, it's worth talking about for a little bit. And so here at AWS we're obsessed with working backwards from our customers, right? What I do is I work with them to help them define and get through architectural blockers, understand regulatory environment, how that may change some of the decisions they they have to make from an architectural perspective, but also helping them decide what are the right tools that they can be using in order to accelerate both their development teams, their security teams, their GRC teams and so on. And so, you know, this customer obsession, you may have heard of it, it's one of our leadership principles, and there's a specific requirement that we keep hearing from our customers. And it really helped to influence why we started to build some of the functionality that we're gonna be talking about. So we're gonna talk a little bit about what that was. At a high level, This is the requirement. You want to be able to build the applications that are secure, that are compliant, that you can deliver at speed with low friction. But also maintaining high confidence and making sure that the application and all that makes up the application meets your security bar. Sounds fairly straightforward, but there are some complexities to this, so we're gonna break it down. First we have to define what application means. A lot of modern cloud applications these days are more than just your application code, it's made up of infrastructure, it's made up of networking that connects all the things together. Really importantly, your identity and access management policies within your applications, how you're managing your role based access control both in the application, but also connecting to other applications, a lot of that connective tissue that's made up of that. How do we define secure, how do we how do we define compliant? These can mean very different things to lots of different customers, but whatever the meaning is, typically it starts with the code, that's where we wanna start, that's our root of all of these things. And the more that we can improve the security health of the code that gets written, the more likely we are to help meet this requirement, regardless of which framework, regardless of which regulatory compliance needs you may have. And really we want to answer is the code that's being written by the developers aligning to these security best practices, how can you validate that, how can you attest to that, how can you assure you that you're following that as well for when it comes to audit time? Deliberate speed, how many times in a day do you think development teams are getting told by the business that they need to move faster? That they're under time pressures, that they want to be more agile, be quicker, more of these cycles, no more delays. This translates to a very high number of sprint cycles, a very high number of releases, much shorter time in between those releases, all while trying to balance the secure and the compliant requirements from before. We add on top of that low effort. We want the application, again which is made up of all of all of those things, that's, we want it to be secure, we want it to be compliant, we want it faster, and we want it with low effort. Sounds like automation. Oh. But then, on top of that, and finally, we want the whole thing to be able to be done with high confidence throughout. Maybe it's for audit purposes, maybe it's for risk, maybe it's for repeatability. But either way, you want to make sure that what you have can be repeated and there's a high confidence in the security bar for the application and that you're not slowing down the business. So not asking for too much. So we talk about the business requirement, right? The need to build secure and compliant applications while maintaining speed and confidence, which is great. But what we want to do is we want to zoom in on where this actually happens, which is the developer's workflow. We know that the cost of fixes happen or gets exponentially higher the further right this line that we go. If you're identifying patches in your running workloads, it's gonna be much more expensive to fix than if you identify good mitigations or good controls early in the planning and design phases. So ideally, as early as in planning and design, we're doing things like threat modeling. We're working with our security teams to define secure patterns, secure constructs, baseline controls that development teams that that can easily consume, and so they're they're already starting on the right foundation. And as Norai's spoken about, Amazon Inspector has been moving left over the years, right, at the beginning we started very far right with the monitor and respond with things that are running in in production on your EC2 instances. But now we have these integrations into our CICD pipelines with things like native integration with code pipeline, but also additional plug-ins for other providers like Team City and Jenkins. But here's the thing, it's still not enough. You're asking us to do more and the earlier we can catch these issues, the better it's going to be. We want to get as far left as possible, right where the code is being written. Who remembers Log for Jay and Log for Shell? Lots of people, and I want to highlight this just as a way to, to talk about why shifting left is so critical. This graph shows the monthly downloads since January 2022 of vulnerable log for J packages. If anyone remembers their history, this came out in December 2021, so even knowing about this, the number of downloads continues to go up. We might think it's old news, we might think Log for Jay is in the past, but actually, you know, the data is telling us otherwise. About 30% of Log for J downloads today are still vulnerable versions. And so it's really hard to understand that, right, organizations are still unknowingly pulling in these dependencies. Without truly understanding that, and again, if we identify a vulnerable log for J package in production, that becomes much more expensive to fix than if we identify it early. But we know also that this can get more complicated. You may be relying on a third party package that and that third party package also relies on on a vulnerable log for J. How do you know that? We need to be able to identify that and we need to get visibility into our code and dependencies early in the development process in order to catch these issues before they become a bigger problem in production. And that is why we're introducing Amazon inspector Code Security. Build your applications faster and securely all the way from code to cloud. Today, we're thrilled to share this new capability. That allows you to expand the continuous vulnerability management from your AWS compute resources. To now scanning code repositories. In GitHub or Gitlab platforms. Let's see what the core capabilities of code security means. First, software composition analysis. This is something that we've actually fundamentally done for your compute resources on lambda functions, images in ECR or EC2. It helps you scan and identify vulnerabilities in third party dependencies, libraries, open source packages that you may be using in your code. The same capability now expands to your code in the code repositories and Git up or get lab. We also know that not all your code is just open source. Your developers write your own proprietary code. And protecting that and identifying the vulnerabilities in those early is also equally important, so with static application security testing scan or SAT scans that we all know. You're able to get visibility into the security of the code that you write or your developers write. To identify issues such as hard coded secrets, injection flaws, weak cryptography, so and so forth. Further, we know that you actually use code to deploy your infrastructure and scale. You you've told us that you use CDK terraform cloud formation to actually scale all the infrastructure on AWS and beyond. How do you proactively identify any misconfigurations in your infrastructure as code? If you didn't scan them early. So adding infrastructure as code or IAC scan as part of one of the code capabilities in code security. This will allow you to identify any of the risks early on, misconfigurations early on in your ISC templates. And significantly reduce your risk as you scale your infrastructure. And with that, We now move further left. Into your development life cycle starting where your developers are editing the code in your source code management. And identify these issues earlier reducing the risk. Reducing the meantime to resolve making these issues cheaper to fix early on before they actually make it to production. But I often wonder when we do these as security personas, what does the developer think? Do they come along in that journey? Danny, what do you think? This is the issue, right? Typically no. Most organizations at the moment still have a pretty Distinct governance model and detached governance model between their developers and between their security teams, right, we talk a lot about dev setups and we talk a lot more about alignment between these two. But at the moment, developers still have a lot of, let's call it unfettered freedom in the sprints. What they then get at the end of that sprint normally is a very long list of vulnerabilities and things that they need to go do from security organization, usually happens at the very end of that sprint before they're about to hit go and, They then need to go and spend a lot more time to go and fix those things, security tests come back, they need to go do some more patches, some more updates and so on, right, and there there's a lot of this back and forth that takes time. Where we want to get to is the developers having a lot more freedom, but within set defined guard rails that the security teams can start to define. But also giving our security teams a lot more visibility, a lot more visibility across all the repositories, being able to identify which of my repositories are running production workloads, which of them have potentially sensitive data running in those applications, which ones are important to me, so then I can understand as a security person where my risks are and be able to prioritize those a lot more effectively. So what we want to do is we want to move the security team away from this traditional culture of no. Into a culture of yes, but within more defined guard rails. And fundamentally, this is a step that you can take to start allowing for enough of that flexibility to move fast, to adopt, uh, to adopt new technologies, whilst making sure you're giving enough and sufficient visibility to do that within risk appetite. And because we know how important this is for the developers, and we know that developers don't really want to have to get out of their traditional workflows, their GitHubb environments, their git lab environments, their IDEs, in order to go and fix security things, we are creating a meet you where you work approach. We want to be friendly to both the developers and to the security organizations. So if you're an inspector customer already, then you'll have a very similar experience to what you're used to. You'll go into an inspector, you'll you'll see the new code security capability there on the left-hand side, and you'll see when it starts to scan your repositories, you'll see your findings appear in the the traditional inspector way. From the developer side, we now have this two-way integration with GitHub and Gitlab. And that two-way integration is really the thing that allows us to get closer to the developer workflow, and it provides non-intrusive feedback directly in pull requests. So again, this allows for our developers to not have to move around, lots of different consoles, lots of different ways and screens that they have to go and navigate to in order to go and see what's important to them. We can inject that directly into their workflows. This is gonna allow us for fast and actionable insights directly in those development cycles that again are happening on a pretty regular basis. So, let's take a look at what this looks like in action. OK. load this up, let's see if it starts. OK, so I'm in my Visual Studio code IDE. I have a number of, I've got infrastructure of code, I've got a number of application files that are mostly Python, and I'm gonna commit this up into my GitHub repository. We're then gonna take a look at that GitHub repository in a little bit more detail. So this is my GitHub repository, it's a fairly basic flask application, it's got a whole bunch of application type vulnerabilities, a whole number of infrastructure vulnerabilities, a lot of very good developers, so this is why everything is so is so insecure. And so what we're going to do. I just pause this for a minute. Is we're gonna navigate over to Inspector. As you can see on the left-hand side, we have the new code security capabilities, so I'll let Narai talk us through a little bit of that in more detail. Yep, if you're familiar with Inspector, we've introduced a new page for code security where you can come in and establish a connection to the source code management platform of choice. Why don't we actually walk down the lane of integrating into GitHub? In this case, I'll go ahead and connect to my GitHub repository. Go ahead and see there has no integrations that exist today. In terms of configuration, nothing exists. I'll go ahead and connect. Into GitHub. We also understand that in your workflow it is important to highlight what's recommended. So as you establish your connection, we'll give you a default configuration that we would recommend. Allowing you to scan. Once a week or once a month you have an option to change it. Every time your developers may be changing code, pull request, merge request, or push to main. Across each of the scan types. ICAS or SCA. So really importantly here as well, um this is our default scan configuration, right, so this is the thing that gets created when you start the the initial connection with a GitHub or a Gitlab. You can choose to just skip this, right, but what this does is this means that this configuration gets applied to all repositories that are already existing in your in your GitHub repository, so immediately pull those in and take that as part of the the scan configuration. It also means that any new repositories that get created in your in in that or any new projects that get created in that repository also start to get looped into this. This is our kind of recommended default setup. You can also go ahead and and edit this to make it more of a more relevant to you. So examples could be inclusion tags where you may only want to say actually I only want my default scan configuration to be applied for my production or any repositories that are tagged as a production repository. For everything else, we can choose, maybe we create another scan configuration, so there are, there is flexibility there as you go and do this, but that's why we try and do this in our setup flow to make sure you at least have something as a catch-all for all of your repositories. Moving on, once you create these scan configurations, whether default, edit them at this stage, choose to skip them, you're able to proceed with your integration workflow. Come and give it a name. There is also an application that you need to go and either download and install first in the GitHub marketplace. If you've already done that, we can port that over or real quick, just go ahead and install the new application in under the hood you're actually giving it authorization, authenticating to the platform, giving it authorization to actually connect and get your code repositories. So again, this piece is really important, right? You can go ahead and do this setup directly from within your GitHub account where you can go to the uh the marketplace and download the Amazon Inspector extension directly through there or we can do this as part of the integration flow. You also have a choice here. You can use, you can have the application connect or have the ability to read and write or read all the all the repositories within within your account or only select ones. That's a decision that you as customers can make, we would probably suggest choosing all, at least that way inspector has all the visibility. You don't necessarily have to scan them all from the inspector's side, but at least making sure that inspector has that visibility, and then with the scan configurations, that's where you can choose which ones you really want to be scanning on a more regular basis. And again, permissions wise, you'll need, you'll need the ability to set something up that has read to all the repositories as well as write permissions only to pull requests. OK, we've finished the installation of the app and you will be redirected back to Amazon Inspector to come back and verify. I have a few code repositories. It'll automatically start to discover these repositories based on your settings, and they will all show up in this list within this page, so you know how many are there and what is the scan status. If you remember in the previous setting I actually did a weekly scan as default. Monday was the day. Today is, I think Wednesday, um, so it's gonna scan as my upcoming schedule or when your developer makes the change. But why don't we just go ahead and try to scan one right now to see what the findings look like because you've just discovered these applications, uh, these depositories, the scan status is inactive. We'll pick one of them. We already know that the web app that we have installed is actually vulnerable. We'll go ahead and do a quick scan on them. Uh, we're verifying there's been no scan done on it. Here's the particular project ID. It's coming from GitHub in my case, and what is the integration are associated with it. I'll go back, select that particular repository. And go ahead and scan it on demand. So in addition to setting up a scan cadence which is periodic on a weekly or a monthly basis or a change based triggers, you certainly can go ahead and scan them at an instant. We run the scan and we see all the findings being generated. I have 6 critical findings in this particular repository of my project. What do they look like? Let's go ahead and dive into the details of one of them. First, let's verify. I actually ran the scan, yes. It was through an on demand scan, the difference being if it was actually triggered through something that was set up, it'll show up in a different field. It was an on demand scan, um, and we'll now go check on the details of the vulnerabilities. If you notice, the details of one of the vulnerability has a public reed bucket acle. It's actually have over permissive. Settings, which is a vulnerability. The findings look no different than what a typical Amazon inspector finding has. The details and the overview are all showing up. What are the rules associated with it? When was the finding created? What is vulnerable in that particular finding will even highlight the finding of the line in the code that we detected as vulnerable with access control and give you an automated. Generate a code fix recommendation we think you have a public read access go ahead. And make a change with these recommendations provided to you in the findings. With our code fix recommendations, you're welcome to just take it, give it to your developers, add it, iterate it based on that and check the code back in. Now looking at another vulnerability as well in this case, just a sample of how that looks like there's improper parsing of HDP requests um it is a package of vulnerability details on when it was created a package vulnerability will have remediation recommendations. It may not have a code fixed recommendation. It may require it may suggest that you upgrade to the latest and greatest version available. So really importantly to mention as well as Narai started to hint earlier. All of these findings when they come through, they hit event bridge, right, so if you want, you can get all of your critical findings going straight into uh into eventbridge and then into potentially a seam or to some alerting notification. Again, the, the beauty of EventBridge is you can be very specific about what kind of alerts you want and where. And so again, you can choose a code repository that is critical to you and you can say every time there is a critical regardless of where, what, how it's been triggered, whether it's an on-demand scan, whether it's a pull request, whether it's a push to main or whether it's a weekly cadence scan, you want to be alerted of any critical vulnerabilities that come through. Of your specific important code repositories, and that way again you've got that flexibility to be alerted very quickly, and you can send alerts both to your security teams and to your and to your development teams as well. OK. Moving on, I think we'll walk you through an example. Of the scan triggers when the developer changes it adds features. So what I'm gonna do here, I'm gonna continue on some very bad development practices, and I'm going to add some vulnerable, some additional vulnerable code here, so in this case I'm adding an estuary bucket that gets created through infrastructure as code, but that S3 bucket allows access from from any principle, right, which essentially means it's a public estuary bucket. To add to that, I'm going to push this directly to a main branch, so. When we start to see this, we can see that our vulnerable code uh is there at the top. I'm just gonna go ahead and push this directly into my main branch. I'm gonna hope that this isn't a production workload cos that's very bad practice. What we then see here is we now see that one of our, Repository has now become active. Why has it become active? Because one of our triggers in our default scan configuration was a git-based trigger, which is a push to a push to the main branch. So every time I'm doing some bad development practices and I'm pushing to the main branch, this is gonna pick that up and it's gonna run a scan for us. So we can see here now that our scan status has changed for our vulnerable web app and we can see that it's active. And we can see more details around the last scan. So we can see here really important metadata as well. Last main scan was about 3 minutes ago, the last on-demand scan that I had triggered before was 23 minutes ago. Again, importantly, extra additional detail here is around the commit ID. So I now get the exact specific commit ID that was scanned, so then I can map specific findings that has come from the scan to my commit. And again, what I can do now is I can just sort this by age and what we'll see in here. Is we've got a new finding, which is the restrict actions with any principle for S3 buckets. We can go in here, we can see it's a code vulnerability, we have some specific detector tags as well, and what that means is where we are, Where we are pulling this in, let me just rewind for a second. Our detector tags are really important because we are using a set of of rule-based detectors and you can actually go ahead and look at the detector, the different detectors that we have on, on, on our web page and you can see exactly what's being pulled out from that. So you can see that in this case it's a specific AWS terraform tag and a and a security tag as well. We have different types of detectors around code quality as well for for some other things, but in this case, this one's a specific security one for terraform. We can see again the vulnerability location, so this is the vulnerable 15 lines of code that I've created, and then it will also give us some additional code uh some some code suggestions. And then the final flow that we will talk about is a pull request. So again, I've got some application code here, some Python code that we're gonna load that up. What that means is it's going to give us some some essentially remote code execution privileges if that gets, if that gets abused. I'm also adding access keys, I'm hard coding access keys, again, big no no, I should definitely go on some developer training on secure best practices. I've now raised the pull request at least into my development branch. I can go into my workflow, go into GitHub, I can take a look at that. I'll just say, yeah, this looks good, I'm happy with all of this pretty insecure code and create that pull request. Now what we'll see here very quickly is our integration now with the Amazon. Inspect the app in GitHub. So within a few minutes it will, it will start to add some not some comments into our pull request. I'm reviewing the pull request for for specific vulnerabilities. I'll get up, I'll get back to you when I'm done and then it will start to add a nest additional comments in there for the specific lines of code that is picked up as part of that portal request that are that are vulnerable. So in this case we see my hard coded credentials and then we see further down. Uh, that we have the vulnerable Python application that I've also written, which is giving us some specific kind of very, Potentially high. Permissions to to all system users again that could potentially be used as part of a remote code execution type attack. And so that's it, right, so we can see here the difference between kind of the security flow, where the security teams, we expect them to be in the inspector console. And also the development flow. Thanks. Great, so we've seen the demo in action. Let's recap some of the key capabilities of Amazon Inspector code security. We can help you scan the code across the entire stack, right, we know again that our our application is made up of infrastructure, it's made up of application code, it's made up of IA policies, it's made up of networking stacks. So being able to scan that entire code is super important, so giving you complete visibility into the security issues across that. We're also flagging vulnerable vulnerable dependencies as we saw again in the demo we can flag package vulnerabilities across, you know, different types of packages, across MPM packages, Piy packages and more, in order to look at where you are getting or exposing yourself through your dependencies. Again, we saw earlier the Log for J example, understanding your dependencies and and their security implications is really important in today's development environment. And then last, we help generate those code fixes. Those code fixes are aligned to security best practices and it's about making sure that that can be easily consumed by the developers. So again, if you're in the security con if you're in the secure the inspector console as a security person, you can download that code snippet and you can send it over. To your development teams or if you in your in your pull request, there will be a new set of code that can get created and you'll see the diff in directly in GitHub, and you can choose whether to add that directly into your um into your into that file and then use that as part of the port request. And so these capabilities are really working together to help you build your applications faster, help them build more securely from code to cloud, right? Remember, faster, more securely, compliant, uh, low friction, high confidence, those are all the things that the business is telling us that that or that you as customers are telling us that you need to be able to do. And obviously each and every one of you are different, every customer's needs are different and they need flexibility. I may wanna run a weekly scan. I may wanna run a monthly scan. I don't wanna run a scan every time somebody edits the code, but I wanna actually scan it when they check back into the main. So we've given you the flexibility with our code security as we saw through the demo you have a way to set up the schedules as your needs are. As you need so as well, you certainly can do these on demand if you needed to one at a time or based on events. Gain visibility across your entire code base. Not on a repo for a particular developer, not on a subset of of repositories either. With flexible scan policies and aggregate all your findings in inspector all the way from code to cloud. Coverage is also equally important. So we're giving you the flexibility of the languages we actually support through SAST, SCA and ISC. So we've seen the capabilities built out on screen, right, from scanning our code across the stack to flagging vulnerable dependencies to generating those code fixes, but also being able to see that from a, as a security perspective across all of our repositories. But it all comes down to this fundamental belief, right, whenever I talk to customers about application security and how to help the developers improve the output of their code and the security health of their code without additional friction, what we want to do is we want to make the secure thing the easy thing. And we truly believe that organizations can and should build secure software at the speed required to build in the cloud. We don't think this is just a nice to have anymore. It can be done with clear security objectives, early risk identification, and the right tools to support your teams. Which is gonna help you launch on schedule and maintain an appropriately high security bar. Inspector code security is going to help make this possible. It's gonna help make the secure, the secure thing the easy thing, providing the right insights at the right time to the right people in your organization. And we don't want security to be a bottleneck. It should be an enabler for faster and more confident software delivery. So we're back to our iceberg, the metaphor that we started with, and we found for too long that organizations are focused only on what's above the water. The visible vulnerabilities that are running in those workloads. We know that the real risk is underneath that, supporting everything that's running in production. Amy at the keynote spoke about not wanting to slow down innovation. That's something that we hold ourselves to when we are thinking about what do customers need, what are the features, capabilities and services that customers need in order to continue to be able to deliver at the speed of cloud. And so with Inspector, we're trying to shine a light underneath the surface. We're trying to give you the right tools to see the full iceberg from code and to compute like so that you can navigate safely more quickly and avoid any costly collisions. But this isn't just about finding vulnerabilities, right, we don't want to make this a numbers game. It's about bridging the gap between the development organizations, the development teams, the engine of our business and the security to help you innovate confidently, innovate at low risk, and take the right risks. And giving security leaders the visibility and they need in order to help with those risk-based decisions. So we want to turn vulnerability management from a typically reactive numbers game or numbers driven process into a more proactive, seamless part of the software life cycle. What next? Go ahead and take advantage of the 15 day free trial that's available for Amazon Inspector. Connect your repositories, and go ahead and understand where your vulnerabilities are. Work with your developers to actually raise your security bar. And start scanning your code today with us. Here are some of the useful resources that you can actually start leveraging now. Documentation, our blog, as well as the demo video are all available here. Alright, thank you very much. It's APS 203. Thank you for coming, enjoy the rest of Rainforce. Thank you.
